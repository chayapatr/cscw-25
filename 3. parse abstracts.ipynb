{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6bd3876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sources = [\"acm\", \"arxiv\", \"ieee\", \"springer\"]\n",
    "papers = []\n",
    "data = []\n",
    "\n",
    "for source in sources:\n",
    "    f = open(f'data/abstract_data/{source}.json', 'r')\n",
    "    if(source != 'ieee'):\n",
    "        papers += json.loads(f.read())\n",
    "    else:\n",
    "        papers += [ paper['data'][0] for paper in json.loads(f.read()) if paper ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "415b04aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No abstract: {'paperId': '7d5bb2354aff19238c740927fdf0879a158c6473', 'title': \"I Know You're Listening: Designing Visual Backchannels for Voice User Interfaces\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716343?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716343, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2351004370', 'name': 'Yoonvin Park'}, {'authorId': '98345379', 'name': 'Do-Hoe Kim'}, {'authorId': '2164062912', 'name': 'Hayeon Song'}]}\n",
      "No abstract: {'paperId': '0a64cb6fac050b05e79cee56315e76ee5aae82a1', 'title': 'Cognition-Inspired Interactive Frameworks for Human-AI Alignment', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716147?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716147, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2214755899', 'name': 'Simret Araya Gebreegziabher'}]}\n",
      "No abstract: {'paperId': 'b75b0246d1bd0734d1b24db1846c8e92e2b87af0', 'title': 'Evaluation Workflows for Large Language Models (LLMs) that Integrate Domain Expertise for Complex Knowledge Tasks', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716146?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716146, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2301055584', 'name': 'Annalisa Szymanski'}]}\n",
      "No abstract: {'paperId': 'd72a5039efb2bb020fa60433aa50a85a6ed0cb60', 'title': 'Slip Through the Chat: Subtle Injection of False Information in LLM Chatbot Conversations Increases False Memory Formation', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712112?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712112, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '24637418', 'name': 'Pat Pataranutaporn'}, {'authorId': '2302564306', 'name': 'Chayapatr Archiwaranguprok'}, {'authorId': '2192866870', 'name': 'Samantha W. T. Chan'}, {'authorId': '2315810439', 'name': 'Elizabeth Loftus'}, {'authorId': '2249129070', 'name': 'Pattie Maes'}]}\n",
      "No abstract: {'paperId': 'a6806dce15d1ca19321dac5fe4be845ed68a7fb5', 'title': 'TellTime: An AI-Augmented Calendar with a Voice Interface for Collecting Time-Use Data', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712116?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712116, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2052707659', 'name': 'M. Hoefer'}, {'authorId': '2351108191', 'name': 'Raegan Rychecky'}, {'authorId': '2351130191', 'name': 'Max Gong'}, {'authorId': '1804450', 'name': 'Stephen Voida'}]}\n",
      "No abstract: {'paperId': '2db00739dd98acaac5c2c8cb87566e7f9933c442', 'title': 'STEP-HAI: Strengthening Engineering Psychology for Human-Algorithm Interactions', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716156?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716156, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2211295964', 'name': 'Patricia K. Kahr'}, {'authorId': '1491708226', 'name': 'Tim Schrills'}, {'authorId': '2270527261', 'name': 'Thomas Franke'}]}\n",
      "No abstract: {'paperId': '73a571746e305f15deaa02e4aa9b6964615931c4', 'title': 'Understanding and Improving Accessibility in AI-Generated Interfaces through Interactive Prompt Engineering Methods', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716347?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716347, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '146081253', 'name': 'Alexandra E. Gurita'}]}\n",
      "No abstract: {'paperId': 'b7e1b91d62d3807d6539c0a95dc4a1d12239fe08', 'title': 'BEHAVE AI: BEst Practices and Guidelines for Human-Centric Design and EvAluation of ProactiVE AI Agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716155?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2291519335', 'name': 'Matthias Kraus'}, {'authorId': '92344344', 'name': 'Sebastian Zepf'}, {'authorId': '2350879510', 'name': 'Rebecca Westhäußer'}, {'authorId': '2350961761', 'name': 'Isabel Feustel'}, {'authorId': '1380223843', 'name': 'Nima Zargham'}, {'authorId': '1723169', 'name': 'Ilhan Aslan'}, {'authorId': '2200010253', 'name': 'Justin Edwards'}, {'authorId': '2264242701', 'name': 'Sven Mayer'}, {'authorId': '2150503', 'name': 'Dimosthenis Kontogiorgos'}, {'authorId': '1811473941', 'name': 'Nicolas Wagner'}, {'authorId': '2190753204', 'name': 'Elisabeth André'}]}\n",
      "No abstract: {'paperId': '10cc0816b50a067e14682c310f94e505f478bb7e', 'title': 'Designing AI Interfaces for Transparent Decision-Making and Ethical Reflection', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716150?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716150, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2307598935', 'name': 'Maalvika Bhat'}]}\n",
      "No abstract: {'paperId': '1944f2f461b6cc7414cc4bd7c955fb18ad8b318f', 'title': 'How Dynamic vs. Static Presentation Shapes User Perception and Emotional Connection to Text-Based AI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712131?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712131, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2307598935', 'name': 'Maalvika Bhat'}]}\n",
      "No abstract: {'paperId': '4aa011bd05d87b3aef12e9c9e73aab158a644987', 'title': 'Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning', 'abstract': None, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2410.08922', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712104?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712104, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2351191864', 'name': 'Majeed Kazemitabaar'}, {'authorId': '2325730952', 'name': 'Oliver Huang'}, {'authorId': '2325731524', 'name': 'Sangho Suh'}, {'authorId': '2280145055', 'name': 'Austin Z Henley'}, {'authorId': '2280146888', 'name': 'Tovi Grossman'}]}\n",
      "No abstract: {'paperId': 'a7ae2aec7b3694b3857ac0f9852bee0f45cdf4eb', 'title': 'From Oracular to Judicial: Enhancing Clinical Decision Making through Contrasting Explanations and a Novel Interaction Protocol', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712157?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712157, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2265739666', 'name': 'Federico Cabitza'}, {'authorId': '2224148853', 'name': 'Lorenzo Famiglini'}, {'authorId': '2326950425', 'name': 'Caterina Fregosi'}, {'authorId': '2322053722', 'name': 'Samuele Pe'}, {'authorId': '2135731778', 'name': 'Enea Parimbelli'}, {'authorId': '40195164', 'name': 'G. A. La Maida'}, {'authorId': '2263063735', 'name': 'Enrico Gallazzi'}]}\n",
      "No abstract: {'paperId': 'e9d3870077dc5fb3119b19792898f0b6b319e0a0', 'title': 'Evaluating the Impact of AI-Generated Visual Explanations on Decision-Making for Image Matching', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712121?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712121, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2149969168', 'name': 'Albatool Wazzan'}, {'authorId': '2351075968', 'name': 'Marcus Wright'}, {'authorId': '2279833262', 'name': 'Stephen MacNeil'}, {'authorId': '2305414360', 'name': 'Richard Souvenir'}]}\n",
      "No abstract: {'paperId': '94d7f5efcd84a302e1ade890c31c4cc718359d44', 'title': 'AiModerator: A Co-Pilot for Hyper-Contextualization in Political Debate Video', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712148?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712148, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2295461497', 'name': 'Peter Andrews'}, {'authorId': '2295460789', 'name': 'Njål Borch'}, {'authorId': '2271698001', 'name': 'Morten Fjeld'}]}\n",
      "No abstract: {'paperId': '366c6fcfd7c8609ba8ad03a3e0b4707064840a81', 'title': 'The Influence of Curiosity Traits and On-Demand Explanations in AI-Assisted Decision-Making', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '34532042', 'name': 'Federico Maria Cau'}, {'authorId': '2598389', 'name': 'L. D. Spano'}]}\n",
      "No abstract: {'paperId': '217b22a3fe4b7593e8795f93ed22d8b48a6c5add', 'title': 'Can LLMs Recommend More Responsible Prompts?', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712137?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712137, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2301078609', 'name': 'Vagner Figueredo de Santana'}, {'authorId': '34376356', 'name': 'Sara E. Berger'}, {'authorId': '2351141699', 'name': 'Tiago Machado'}, {'authorId': '1505777245', 'name': 'Maysa Malfiza Garcia de Macedo'}, {'authorId': '2176421802', 'name': 'C. S. Sanctos'}, {'authorId': '2351823199', 'name': 'Lemara Williams'}, {'authorId': '2351101517', 'name': 'Zhaoqing Wu'}]}\n",
      "No abstract: {'paperId': '88406be8fc085fc268fdb951997cf87e9e437b09', 'title': 'CoPrompter: User-Centric Evaluation of LLM Instruction Alignment for Improved Prompt Engineering', 'abstract': None, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2411.06099', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712102?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2299069205', 'name': 'Ishika Joshi'}, {'authorId': '49260478', 'name': 'Simra Shahid'}, {'authorId': '2330189329', 'name': 'S. Venneti'}, {'authorId': '2273082180', 'name': 'Manushree Vasu'}, {'authorId': '2330483398', 'name': 'Yantao Zheng'}, {'authorId': '2330299769', 'name': 'Yunyao Li'}, {'authorId': '2265756284', 'name': 'Balaji Krishnamurthy'}, {'authorId': '51192588', 'name': 'G. Chan'}]}\n",
      "No abstract: {'paperId': '2cb76968d296c298d41ddf5886f09aa2d9b1c406', 'title': 'Benefits of Machine Learning Explanations: Improved Learning in an AI-assisted Sequence Prediction Task', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712155?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-24', 'authors': [{'authorId': '2333305303', 'name': 'Yu Liang'}, {'authorId': '50996831', 'name': 'Dennis Collaris'}, {'authorId': '1918235', 'name': 'M. Willemsen'}, {'authorId': '39433303', 'name': 'J. van Wijk'}]}\n",
      "No abstract: {'paperId': 'a311b7bef8db910aaf7fc5dbeed3832f82efca71', 'title': 'Pattern analysis of ambitious science talk between preservice teachers and AI-powered student agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3706468.3706570?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3706468.3706570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-03-03', 'authors': [{'authorId': '2291670746', 'name': 'Alex Barrett'}, {'authorId': '2261866996', 'name': 'Fengfeng Ke'}, {'authorId': '2180262774', 'name': 'Nuodi Zhang'}, {'authorId': '1864090606', 'name': 'Chih-Pu Dai'}, {'authorId': '29916274', 'name': 'Saptarshi Bhowmik'}, {'authorId': '2305309745', 'name': 'Xin Yuan'}]}\n",
      "No abstract: {'paperId': '35fae3807b48042ab32a941470d0654112e003a4', 'title': 'HCI for AGI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708815?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708815, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-02-25', 'authors': [{'authorId': '2347525196', 'name': 'Meredith Ringel Morris'}]}\n",
      "No abstract: {'paperId': '7f2cdc54ffbf02bfa3e7974b1f5f1c96b1620896', 'title': \"Artificial Intelligence Psychological Empowerment Among Asian Australian Immigrant Workers: Navigating Marginalization and Harnessing Artificial Intelligence's Power for Enhanced Workplace Agency\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3709026.3709100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3709026.3709100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-12-06', 'authors': [{'authorId': '2330165817', 'name': 'Yingnan Shi'}]}\n",
      "No abstract: {'paperId': 'bc16fbba415ba9e208535e8a264385d60c391e95', 'title': 'Interdisciplinary Perspectives on Generative Artificial Intelligence Adoption in Higher Education: A Theoretical Framework Review', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3704289.3704293?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3704289.3704293, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-24', 'authors': [{'authorId': '2284544369', 'name': 'James Ewert Duah'}, {'authorId': '2342523753', 'name': 'Xin Lu'}, {'authorId': '2284545241', 'name': 'Paul McGivern'}, {'authorId': '2336039080', 'name': 'Yanguo Jing'}]}\n",
      "No abstract: {'paperId': '07cccf61c0d86d2bdb9978d3afd773c41644e71b', 'title': 'Roles emerging during the knowledge construction process in collaborative learning: Does a generative AI-support chatbot matter?', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702163.3702165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702163.3702165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-18', 'authors': [{'authorId': '2341556863', 'name': 'Rushi Gong'}, {'authorId': '2342081688', 'name': 'Rui Jiang'}, {'authorId': '2344801665', 'name': 'Chuanlei Guo'}, {'authorId': '2109745865', 'name': 'Wanqing Hu'}, {'authorId': '2110508005', 'name': 'Yanyan Li'}]}\n",
      "No abstract: {'paperId': '7affa1ba1cd9bfc7f16b53f80370ce8da01f86d7', 'title': 'Pre-AI and post-AI design: balancing human Creativity and AI Tools in the Industrial\\xa0Design\\xa0Process', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708394.3708413?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708394.3708413, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-01', 'authors': [{'authorId': '2340368278', 'name': 'Xilin Tang'}, {'authorId': '50246958', 'name': 'Jerrod Windham'}, {'authorId': '2340310211', 'name': 'Benjamin Bush'}]}\n",
      "No abstract: {'paperId': 'f88cac3943d09d157959e6f2c9039a1f9252ed24', 'title': 'A Research Through Design Study on AI Explanations for Collaborative Everyday Tasks for Older Adults Aging in Place', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3688828.3699640?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3688828.3699640, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2025-01-12', 'authors': [{'authorId': '1576648977', 'name': 'N. Mathur'}, {'authorId': '73769177', 'name': 'Tamara Zubatiy'}, {'authorId': '1752751', 'name': 'Elizabeth D. Mynatt'}]}\n",
      "No abstract: {'paperId': '83f9f3116db66467b60b675a3b89644443a927b7', 'title': 'Multimodal Mamba: A Versatile Multimodal Model for Seamless Integration into Diverse Downstream Tasks', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3704323.3704364?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3704323.3704364, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-25', 'authors': [{'authorId': '2339240186', 'name': 'Zongshu Li'}, {'authorId': '2894321', 'name': 'Guibo Zhu'}, {'authorId': '2339050076', 'name': 'Dongyi Yi'}, {'authorId': '2241943585', 'name': 'Jinqiao Wang'}]}\n",
      "No abstract: {'paperId': '2ed4dcdabf15f511466466368b3d49a484a7c181', 'title': 'Human-AI Interactions in Teacher Education: Examining Social Presence and Friendship', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702399?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702399, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-12', 'authors': [{'authorId': '2248739797', 'name': 'Hui-Wen Huang'}, {'authorId': '2338648303', 'name': 'Jessica (Chieh-Yu) Chang'}]}\n",
      "No abstract: {'paperId': 'ba4699310050afd354f9bc4bb58633fd831e1e34', 'title': 'Leveraging Multimodal GenAI Chatbots in EFL Learning: Learning Attitudes and User Experiences', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702406?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702406, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-12', 'authors': [{'authorId': '2248739797', 'name': 'Hui-Wen Huang'}, {'authorId': '2338667730', 'name': 'Xiyu Chen'}, {'authorId': '2338612331', 'name': 'Andrew Sankey'}]}\n",
      "No abstract: {'paperId': '453830406678fe3f72d7be4ebb91be7fa1a6747b', 'title': 'Can AI Be Environmentally Responsible? A Comparative Study on the Pro-Environmental Portrait of ChatGPT and Chinese Respondents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702394?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702394, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-12', 'authors': [{'authorId': '2261692294', 'name': 'Yu-Feng Qi'}, {'authorId': '2338647201', 'name': 'Fangxiang Fu'}, {'authorId': '2334200109', 'name': 'J. Tian'}, {'authorId': '2244778572', 'name': 'Yan Sun'}]}\n",
      "No abstract: {'paperId': 'ac0ad5572fd7f35f98ddd12377ede08dead672b1', 'title': 'Review of AI-Based Mental Health Apps', 'abstract': None, 'openAccessPdf': {'url': 'https://www.scienceopen.com/document_file/6f1661e3-8f36-4a6c-80b9-36c1fa5a933c/ScienceOpen/238_Alotaibi_BCSHCI23.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14236/ewic/bcshci2023.27?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14236/ewic/bcshci2023.27, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2304469906', 'name': 'Abeer Alotaibi'}, {'authorId': '2296014237', 'name': 'Corina Sas'}]}\n",
      "No publicationDate: {'paperId': 'ac0ad5572fd7f35f98ddd12377ede08dead672b1', 'title': 'Review of AI-Based Mental Health Apps', 'abstract': None, 'openAccessPdf': {'url': 'https://www.scienceopen.com/document_file/6f1661e3-8f36-4a6c-80b9-36c1fa5a933c/ScienceOpen/238_Alotaibi_BCSHCI23.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14236/ewic/bcshci2023.27?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14236/ewic/bcshci2023.27, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2304469906', 'name': 'Abeer Alotaibi'}, {'authorId': '2296014237', 'name': 'Corina Sas'}]}\n",
      "No abstract: {'paperId': 'fce2a89184dd5f87bd89dbd336d0dccde2ef7d99', 'title': 'Integration of User-Centered Design in the Development of Big Data and Machine Learning-Based Applications: A Systematic Mapping Study', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702038.3702097?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702038.3702097, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-07', 'authors': [{'authorId': '2131878906', 'name': 'N. Raulino'}, {'authorId': '2336748406', 'name': 'Rossana M. de Castro Andrade'}, {'authorId': '2747867', 'name': 'I. Santos'}]}\n",
      "No abstract: {'paperId': 'f1d2b129f86ce9a092a7ad7c23cc79155a41a52f', 'title': 'GenAI and Prompt Engineering: A Progressive Framework for Empowering the Workforce', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3698322.3698348?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3698322.3698348, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-07-03', 'authors': [{'authorId': '2282990536', 'name': 'Adrian Schuckart'}]}\n",
      "No abstract: {'paperId': '24eee55cb67eab02061c1f1b316a49caefc0d100', 'title': \"Effect of LLM's Personality Traits on Query Generation\", 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3673791.3698433', 'status': 'HYBRID', 'license': 'public-domain', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3673791.3698433?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3673791.3698433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-12-08', 'authors': [{'authorId': '2334467150', 'name': 'Yuta Imasaka'}, {'authorId': '2334467905', 'name': 'Hideo Joho'}]}\n",
      "No abstract: {'paperId': 'ad86d55d5dd608f46b0a643edb526860bce4ec36', 'title': 'AI-Powered Service Blueprints for Enhancing Human-Centred AI Design Processes', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701268.3701280?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701268.3701280, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-12-02', 'authors': [{'authorId': '2333793931', 'name': 'Mehrdad Atariani'}, {'authorId': '2333795906', 'name': 'Mohamad Saeid Hoseini'}]}\n",
      "No abstract: {'paperId': 'd6e2ba4fe3ba07bf3f3dc9af3d8259c767c3d794', 'title': 'Human-centered AI Technologies in Human-robot Interaction for Social Settings', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3701571.3701610', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701571.3701610?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701571.3701610, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-12-01', 'authors': [{'authorId': '2287737348', 'name': 'Yuchong Zhang'}, {'authorId': '2333609410', 'name': 'Khaled Kassem'}, {'authorId': '2334693129', 'name': 'Zhengya Gong'}, {'authorId': '2333601766', 'name': 'Fan Mo'}, {'authorId': '2333743103', 'name': 'Yong Ma'}, {'authorId': '118873121', 'name': 'E. Kirjavainen'}, {'authorId': '2265111029', 'name': 'Jonna Häkkilä'}]}\n",
      "No abstract: {'paperId': 'f8aa87466ef9227adc32dbf5aedb4e3b5414cf15', 'title': 'Crafting Human-AI Interaction: A Rhetorical Approach to Adaptive Interaction in Conversational Agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3688297?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3688297, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-24', 'authors': [{'authorId': '2280742122', 'name': 'Rutuja Joshi'}, {'authorId': '2244312232', 'name': 'Klaus Bengler'}]}\n",
      "No abstract: {'paperId': '2a71dc5b28a8addf3d34a850a6f96e6f311813b3', 'title': 'Algorithmic Authority & AI Influence in Decision Settings: Theories and Implications for Design', 'abstract': None, 'openAccessPdf': {'url': 'https://orca.cardiff.ac.uk/id/eprint/172095/1/2024_HAI_Workshop.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3691363?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3691363, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-24', 'authors': [{'authorId': '2295670746', 'name': 'Alessandro Facchini'}, {'authorId': '2326950425', 'name': 'Caterina Fregosi'}, {'authorId': '2059240949', 'name': 'Chiara Natali'}, {'authorId': '2052098721', 'name': 'Alberto Termine'}, {'authorId': '2331736004', 'name': 'Ben Wilson'}]}\n",
      "No abstract: {'paperId': '23fe409d9f21f2c53b1da0247ce493d944bbe876', 'title': 'TheoriseHAI: Shaping Human-Agent Interactions Through Interdisciplinary Theories', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3691358?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3691358, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-24', 'authors': [{'authorId': '82791880', 'name': 'Maitreyee Tewari'}, {'authorId': '11708658', 'name': 'Michele Persiani'}, {'authorId': '2331835180', 'name': 'Roland Chen'}, {'authorId': '2331759870', 'name': 'Linda Li'}]}\n",
      "No abstract: {'paperId': '0e15f92f8ac2de9a5cfd8427f3ad069b32ec876a', 'title': \"Designing Bias Suppressing Robots for 'fair' Robot moderated Human-Human Interactions\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3690877?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3690877, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-24', 'authors': [{'authorId': '2306952414', 'name': 'Peter Daish'}, {'authorId': '2271611527', 'name': 'Takayuki Kanda'}, {'authorId': '2331734456', 'name': 'Matt Roach'}, {'authorId': '2331763946', 'name': 'Muneeb Ahmad'}]}\n",
      "No abstract: {'paperId': '1ff243f3326e8a0474a1bce03322480ecb6b3684', 'title': 'Exploring How Users Attribute Responsibilities Across Different Stakeholders in Human-AI Interaction', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681852', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681852?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-11', 'authors': [{'authorId': '2312411766', 'name': 'Yu-Ting Chen'}, {'authorId': '2312475776', 'name': 'Hsin-yi Sandy Tsai'}, {'authorId': '2331315716', 'name': 'Tina Chien-Wen Yuan'}]}\n",
      "No abstract: {'paperId': '996be97576fa73be20763bb80610b517d84d0319', 'title': 'Uncovering Contradictions in Human-AI Interactions: Lessons Learned from User Reviews of Replika', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681909', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681909?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681909, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-11', 'authors': [{'authorId': '2295729530', 'name': 'M. Namvarpour'}, {'authorId': '47351197', 'name': 'Afsaneh Razi'}]}\n",
      "No abstract: {'paperId': '9228d7545053261993024a70f610ced57330c28b', 'title': 'Opportunities and Challenges of Emerging Human-AI Interactions to Support Healthcare in the Global South', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681834', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681834?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681834, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-11', 'authors': [{'authorId': '144027898', 'name': 'Carolina Fuentes'}, {'authorId': '2722396', 'name': 'Iyubanit Rodríguez'}, {'authorId': '47204934', 'name': 'Gabriela Cajamarca'}, {'authorId': '1403933980', 'name': 'Laura Cabrera-Quiros'}, {'authorId': '2308852069', 'name': 'Andrés Lucero'}, {'authorId': '2240541974', 'name': 'Valeria Herskovic'}, {'authorId': '2058908494', 'name': \"Kenton O'hara\"}]}\n",
      "No abstract: {'paperId': '0c57890908b83308858097d81cc2afb1820d1532', 'title': '\"What is Safety?\": Building Bridges Across Approaches to Digital Risks and Harms', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681824', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681824?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681824, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-11', 'authors': [{'authorId': '2244445242', 'name': 'A. Walker'}, {'authorId': '32861190', 'name': 'M. A. Devito'}, {'authorId': '1402258829', 'name': 'Karla A. Badillo-Urquiola'}, {'authorId': '2237799784', 'name': 'Rosanna Bellini'}, {'authorId': '2510840', 'name': 'Stevie Chancellor'}, {'authorId': '2146189', 'name': 'Jessica L. Feuston'}, {'authorId': '2261593676', 'name': 'Kathryn Henne'}, {'authorId': '2256999087', 'name': 'Patrick Gage Kelley'}, {'authorId': '7389108', 'name': 'Shalaleh Rismani'}, {'authorId': '2256999906', 'name': 'Renee Shelby'}, {'authorId': '2257859674', 'name': 'Renwen Zhang'}]}\n",
      "No abstract: {'paperId': 'e4f78b672f6ad3d5ff66bf4c0e4e0613bcb8f873', 'title': 'Design Digital Multisensory Textile Experiences', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678957.3688621?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678957.3688621, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-04', 'authors': [{'authorId': '2147241341', 'name': 'Shu Zhong'}]}\n",
      "No abstract: {'paperId': '707304ef5a888a3d53dcfc32081bf0261b94ec9c', 'title': 'Envisioning Futures: How the Modality of AI Recommendations Impacts Conversation Flow in AR-enhanced Dialogue', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678957.3685731?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678957.3685731, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-04', 'authors': [{'authorId': '51179828', 'name': 'Steeven Villa'}, {'authorId': '2292196104', 'name': 'Yannick Weiss'}, {'authorId': '2342255781', 'name': 'Mei-Yi Lu'}, {'authorId': '2268866324', 'name': 'Moritz Ziarko'}, {'authorId': '2163466011', 'name': 'Albrecht Schmidt'}, {'authorId': '1999052', 'name': 'Jasmin Niess'}]}\n",
      "No abstract: {'paperId': '15b5b32bfb29298b8b94b50b6b31792832bb1045', 'title': 'Levels of Multimodal Interaction', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686215.3690153?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686215.3690153, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-04', 'authors': [{'authorId': '47270594', 'name': 'A. K. Sinha'}, {'authorId': '2214547658', 'name': 'Chinmay Kulkarni'}, {'authorId': '2328540890', 'name': 'Alex Olwal'}]}\n",
      "No abstract: {'paperId': 'b9b090a88b058921b700b57e2abf0b3f647969b7', 'title': 'Detecting when Users Disagree with Generated Captions', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686215.3688382?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686215.3688382, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-11-04', 'authors': [{'authorId': '2105468553', 'name': 'Omair Shahzad Bhatti'}, {'authorId': '2085411586', 'name': 'Harshinee Sriram'}, {'authorId': '2310451859', 'name': 'Abdulrahman Mohamed Selim'}, {'authorId': '2265385911', 'name': 'Cristina Conati'}, {'authorId': '39739949', 'name': 'Michael Barz'}, {'authorId': '2243244763', 'name': 'Daniel Sonntag'}]}\n",
      "No abstract: {'paperId': 'eeb407183e6620b69ea9b324de612fdcaf331b72', 'title': 'AI Assisted Domain Modeling Explainability and Traceability', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3652620.3688197?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3652620.3688197, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-22', 'authors': [{'authorId': '2329087161', 'name': 'Jonathan Silva Mercado'}]}\n",
      "No abstract: {'paperId': '6f474f80bff86bba5cf275a0aa77081b9f7a8a1c', 'title': 'Alternative Routing based on Road Popularity', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3681779.3696836?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3681779.3696836, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-29', 'authors': [{'authorId': '1796264540', 'name': 'Giuliano Cornacchia'}, {'authorId': '2305615785', 'name': 'Ludovico Lemma'}, {'authorId': '2276443419', 'name': 'Luca Pappalardo'}]}\n",
      "No abstract: {'paperId': '284fe5082170c4bf753bed91ad9905c19b9928e0', 'title': 'Accessibility in AI-Assisted Web Development', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3677846.3679054?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3677846.3679054, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-05-13', 'authors': [{'authorId': '2080054475', 'name': 'Peya Mowar'}]}\n",
      "No abstract: {'paperId': 'f2d61923e07cd30680121745621daf74682c3259', 'title': 'EverForest: A More-Than-AI Sustainability Manifesto from an On-Chain Artificial Life', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686169.3686209?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686169.3686209, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-21', 'authors': [{'authorId': '2271017262', 'name': 'B. Hu'}, {'authorId': '2326712918', 'name': 'Fang Ting'}]}\n",
      "No abstract: {'paperId': '597cc823459af7b75287a9c63be3d43f6b351af0', 'title': 'PingPonGPT: Write Your Next Paper while Playing Table Tennis with the Help of AI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3665463.3678864?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3665463.3678864, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-14', 'authors': [{'authorId': '2214745676', 'name': 'O. Buruk'}, {'authorId': '2343948', 'name': 'Ahmet Börütecene'}]}\n",
      "No abstract: {'paperId': 'e93fa058471e1ddfced641a96e7a6bf64dbda9d8', 'title': 'Ethics and Transparency in Game Data', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3665463.3678859?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3665463.3678859, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-14', 'authors': [{'authorId': '2295990682', 'name': 'Erica Kleinman'}, {'authorId': '1381933697', 'name': 'M. S. El-Nasr'}, {'authorId': '2317107653', 'name': 'Johannes Pfau'}, {'authorId': '2214048085', 'name': 'Simone Kriglstein'}, {'authorId': '2253705215', 'name': 'Günter Wallner'}, {'authorId': '66017885', 'name': 'Dávid Melhárt'}, {'authorId': '1686193', 'name': 'Georgios N. Yannakakis'}, {'authorId': '2213910126', 'name': 'Jichen Zhu'}, {'authorId': '2301717458', 'name': 'Benjamin Watson'}, {'authorId': '2291266497', 'name': 'Casper Harteveld'}]}\n",
      "No abstract: {'paperId': 'a67af80cd62005e246b552c49e927c446df81150', 'title': 'HAID: Human-AI Interaction for Dementia Care', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3677045.3685469?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3677045.3685469, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2290856580', 'name': 'Yong Ma'}, {'authorId': '2287737348', 'name': 'Yuchong Zhang'}, {'authorId': '2321457601', 'name': 'Di Fu'}, {'authorId': '2323564921', 'name': 'Mahya Jahanshahikhabisi'}, {'authorId': '2290788944', 'name': 'Andrii Matviienko'}, {'authorId': '2025029725', 'name': 'Miroslav Bachinski'}, {'authorId': '2271698001', 'name': 'Morten Fjeld'}, {'authorId': '2153721470', 'name': 'Danica Kragic'}]}\n",
      "No abstract: {'paperId': '5b623d7d99ec8d0196bdbf864f2bff96ffadfde1', 'title': 'Intelligence as Agency', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3672539.3695751?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3672539.3695751, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '51109836', 'name': 'Arvindmani Satyanarayan'}]}\n",
      "No abstract: {'paperId': 'd29c34e890e7dd5a745daea78274f7c5b38732cd', 'title': 'In a Quasi-Social Relationship With ChatGPT. An Autoethnography on Engaging With Prompt-Engineered LLM Personas', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3679318.3685501?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3679318.3685501, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2323696415', 'name': 'Eva Krapp'}, {'authorId': '1666245911', 'name': 'Robin Neuhaus'}, {'authorId': '2237241025', 'name': 'Marc Hassenzahl'}, {'authorId': '49795916', 'name': 'Matthias Laschke'}]}\n",
      "No abstract: {'paperId': 'a6c94651ee73d9f56ad8e03f371a899ba467f251', 'title': 'Granting Non-AI Experts Creative Control Over AI Systems', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3672539.3686714?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3672539.3686714, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2257816218', 'name': 'Michelle S. Lam'}]}\n",
      "No abstract: {'paperId': '65319931eb2af60a8b922bb5f9ce1194f300e6df', 'title': '\"We Are Visual Thinkers, Not Verbal Thinkers!\": A Thematic Analysis of How Professional Designers Use Generative AI Image Generation Tools', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3679318.3685370?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3679318.3685370, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2264963307', 'name': 'Hyerim Park'}, {'authorId': '29415466', 'name': 'Joscha Eirich'}, {'authorId': '2292312388', 'name': 'André Luckow'}, {'authorId': '2243254992', 'name': 'Michael Sedlmair'}]}\n",
      "No abstract: {'paperId': '37867df639f1646d4a0245ed8500b3bd66e938d7', 'title': 'Workshop: Designing with AI-based tools', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3677045.3685449?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3677045.3685449, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '1419500850', 'name': 'Pavel Okopnyi'}, {'authorId': '3197887', 'name': 'Frode Guribye'}, {'authorId': '2323565381', 'name': 'Miroslav Bachinski'}, {'authorId': '2271698001', 'name': 'Morten Fjeld'}, {'authorId': '2289059032', 'name': 'Daniel Buschek'}, {'authorId': '1666472459', 'name': 'Tim Zindulka'}, {'authorId': '153451802', 'name': 'Florian Lehmann'}, {'authorId': '2323565696', 'name': 'Paulina Becerril Palma'}]}\n",
      "No abstract: {'paperId': '679d972e5efe97e828d5c32f01fa5c5e460369f8', 'title': 'Generative AI Tools in Design Fields: Opportunities and Challenges in the Ideation Process', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3677045.3685445?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3677045.3685445, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2323565158', 'name': 'Cansu Akverdi'}, {'authorId': '3440045', 'name': 'Gökçe Elif Baykal'}]}\n",
      "No abstract: {'paperId': '7208d909b2b3e4455e7e0a0b0f8301bd8f98de88', 'title': 'The X Factor: On the Relationship between User eXperience and eXplainability', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3679318.3685352?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3679318.3685352, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2219244000', 'name': 'Hannah Deters'}, {'authorId': '2219246643', 'name': 'Jakob Droste'}, {'authorId': '2248094751', 'name': 'Anne Hess'}, {'authorId': '2248820507', 'name': 'Verena Klös'}, {'authorId': '2237201948', 'name': 'Kurt Schneider'}, {'authorId': '2323644793', 'name': 'Timo Speith'}, {'authorId': '2269313718', 'name': 'Andreas Vogelsang'}]}\n",
      "No abstract: {'paperId': '104c0b2917127c48511d5e8a9b3ce78f89e9f61e', 'title': 'Investigating How Generative AI Affects Decision-Making in Participatory Design: Shifting the space to make design choices', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3679318.3685384?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3679318.3685384, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '1951626', 'name': 'Suhas Govind Joshi'}, {'authorId': '2323709807', 'name': 'Christopher Hagen Tolloczko'}, {'authorId': '2323712460', 'name': 'Snorre Wenaas'}, {'authorId': '2323711610', 'name': 'Ola Juul Holm'}, {'authorId': '2323714596', 'name': 'Martin Lorentz Fagersand Langved'}]}\n",
      "No abstract: {'paperId': '8c7f88b4be345e682011489860d27f0bc2062a91', 'title': \"Is a Sunny Day Bright and Cheerful or Hot and Uncomfortable? Young Children's Exploration of ChatGPT\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3679318.3685397?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3679318.3685397, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2323613885', 'name': 'Vaishnavi Shrivastava'}, {'authorId': '2247581485', 'name': 'Sumita Sharma'}, {'authorId': '2285504504', 'name': 'Dipanjan Chakraborty'}, {'authorId': '2285387798', 'name': 'Marianne Kinnula'}]}\n",
      "No abstract: {'paperId': 'b14020265c6f86d7a464f592cd99d5fb987282cb', 'title': \"What's the Game, then? Opportunities and Challenges for Runtime Behavior Generation\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3654777.3676358?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3654777.3676358, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2163707572', 'name': 'Nicholas Jennings'}, {'authorId': '2326102638', 'name': 'Han Wang'}, {'authorId': '2325590416', 'name': 'Isabel Li'}, {'authorId': '2220590743', 'name': 'James Smith'}, {'authorId': '2261891291', 'name': 'Bjoern Hartmann'}]}\n",
      "No abstract: {'paperId': '9cb96e6015899aafb91965fb64f7c15a57a97ad5', 'title': 'ProtoDreamer: A Mixed-prototype Tool Combining Physical Model and Generative AI to Support Conceptual Design', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3654777.3676399?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3654777.3676399, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2216092017', 'name': 'Hongbo Zhang'}, {'authorId': '2269609431', 'name': 'Pei Chen'}, {'authorId': '2269696852', 'name': 'Xuelong Xie'}, {'authorId': '2325711381', 'name': 'Chaoyi Lin'}, {'authorId': '2325706601', 'name': 'Lianyan Liu'}, {'authorId': '2325505495', 'name': 'Zhuoshu Li'}, {'authorId': '2296879609', 'name': 'Weitao You'}, {'authorId': '2110887936', 'name': 'Lingyun Sun'}]}\n",
      "No abstract: {'paperId': '4c448178e227f7bdeb178aa5830e593203941af6', 'title': 'AutoSpark: Supporting Automobile Appearance Design Ideation with Kansei Engineering and Generative AI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3654777.3676337?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3654777.3676337, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2173717316', 'name': 'Liuqing Chen'}, {'authorId': '2183355260', 'name': 'Qianzhi Jing'}, {'authorId': '2214762805', 'name': 'Yixin Tsang'}, {'authorId': '2300808028', 'name': 'Qianyi Wang'}, {'authorId': '2325688114', 'name': 'Ruocong Liu'}, {'authorId': '2301086401', 'name': 'Duowei Xia'}, {'authorId': '2118117081', 'name': 'Yunzhan Zhou'}, {'authorId': '2110887936', 'name': 'Lingyun Sun'}]}\n",
      "No abstract: {'paperId': '43e87bbe3c42c79678ac12f73833f0eb3e008a44', 'title': 'Qlarify: Recursively Expandable Abstracts for Dynamic Information Retrieval over Scientific Papers', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3654777.3676397?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3654777.3676397, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-13', 'authors': [{'authorId': '2299332766', 'name': 'Raymond Fok'}, {'authorId': '2267001904', 'name': 'Joseph Chee Chang'}, {'authorId': '50509991', 'name': 'Tal August'}, {'authorId': '144518215', 'name': 'Amy X. Zhang'}, {'authorId': '1780531', 'name': 'Daniel S. Weld'}]}\n",
      "No abstract: {'paperId': 'bc1d5bc554d3759341486166ce5de96bb2243ed7', 'title': 'AI and Future-Making: Design, Biases, and Human-Plant Interactions', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3681716.3681738', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3681716.3681738?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3681716.3681738, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-08', 'authors': [{'authorId': '2536914', 'name': 'Maliheh Ghajargar'}]}\n",
      "No abstract: {'paperId': '257a7d7dde880e67102fad94b5340aff0ba8c1af', 'title': 'Designing Tiny Robots: Engaging Stakeholders in Collaborative AI System Design', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3681716.3681722?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3681716.3681722, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-08', 'authors': [{'authorId': '2800449', 'name': 'Marigo Raftopoulos'}]}\n",
      "No abstract: {'paperId': '92dc3f4ede2e386b681faa0060b08494ec0b51ff', 'title': 'Interpretable, Inclusive, and Immersive Interaction for Ubiquitous AI-infused Physical Systems', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3675094.3677569?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3675094.3677569, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-05', 'authors': [{'authorId': '1485729680', 'name': 'Gwangbin Kim'}, {'authorId': '2214504054', 'name': 'Minwoo Seong'}, {'authorId': '1485241985', 'name': 'Dohyeon Yeo'}, {'authorId': '2238893129', 'name': 'Yumin Kang'}, {'authorId': '2301178907', 'name': 'Seungjun Kim'}]}\n",
      "No abstract: {'paperId': '18f099e8ea866173f8164ca6de5c2f9e145e58b3', 'title': 'MyListener: An AI-Mediated Journaling Mobile Application for Alleviating Depression and Loneliness Using Contextual Data', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3675094.3677601?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3675094.3677601, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-05', 'authors': [{'authorId': '2192211395', 'name': 'Gyeyoung Jung'}, {'authorId': '2322557559', 'name': 'Soyeon Choi'}, {'authorId': '2281020412', 'name': 'Yuju Kang'}, {'authorId': '2280983304', 'name': 'Jaejeung Kim'}]}\n",
      "No abstract: {'paperId': 'f2fa6382a83dedeaf920cfd1d05dd588036eb95c', 'title': 'Unified Framework for Procedural Task Assistants powered by Human Activity Recognition', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3675094.3678448?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3675094.3678448, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-10-05', 'authors': [{'authorId': '2292515576', 'name': 'Riku Arakawa'}, {'authorId': '2247946468', 'name': 'Mayank Goel'}]}\n",
      "No abstract: {'paperId': 'e5d25b10db874dbe22fc324310b01e219648b560', 'title': 'Designing Generative AI User Interfaces for Automobiles', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3641308.3677393?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3641308.3677393, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-17', 'authors': [{'authorId': '2202563847', 'name': 'Akshay Rege'}, {'authorId': '2210772152', 'name': 'Euiyoung Kim'}, {'authorId': '2239159444', 'name': 'Soyeon Kim'}, {'authorId': '1794413', 'name': 'D. Sirkin'}, {'authorId': '26326353', 'name': 'Rebecca M. Currano'}]}\n",
      "No abstract: {'paperId': '337a3892a37eed70ce325a3695b9df8455de1165', 'title': \"Is Your Prompt Detailed Enough? Exploring the Effects of Prompt Coaching on Users' Perceptions, Engagement, and Trust in Text-to-Image Generative AI Tools\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686038.3686060?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686038.3686060, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-16', 'authors': [{'authorId': '2145776803', 'name': 'Cheng Chen'}, {'authorId': '2314677613', 'name': 'Sangwook Lee'}, {'authorId': '2295513815', 'name': 'Eunchae Jang'}, {'authorId': '2246892011', 'name': 'S. S. Sundar'}]}\n",
      "No abstract: {'paperId': '471f60f026797ce458942eefb5defa0363210205', 'title': 'Authoring Educational Hypercomics assisted by Large Language Models', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3648188.3675124?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3648188.3675124, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-10', 'authors': [{'authorId': '2131064174', 'name': 'Valentin Grimm'}, {'authorId': '2107624', 'name': 'J. Rubart'}]}\n",
      "No abstract: {'paperId': '17fd018d690dc2a568dada91a584ad04eae95b9d', 'title': '(X)AI as a Teacher: Learning with Explainable Artificial Intelligence', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3670653.3677504?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3670653.3677504, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-01', 'authors': [{'authorId': '2168553327', 'name': 'Philipp Spitzer'}, {'authorId': '7930946', 'name': 'Marc Goutier'}, {'authorId': '2214406252', 'name': 'Niklas Kühl'}, {'authorId': '2121104', 'name': 'G. Satzger'}]}\n",
      "No abstract: {'paperId': 'dd39af179c9c95ce534c5fd43032cb22155391e2', 'title': 'Enhancing AI Education for Business Students through Extended Reality: An Exploratory Study', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3670653.3677506?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3670653.3677506, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-09-01', 'authors': [{'authorId': '2100852642', 'name': 'Thimo Schulz'}, {'authorId': '2316888341', 'name': 'Shi Liu'}, {'authorId': '2265050337', 'name': 'Alexander Maedche'}, {'authorId': '2285570337', 'name': 'Christof Weinhardt'}]}\n",
      "No abstract: {'paperId': '7ff1f5e1eaa255b001eacb85085afe1f54b671a8', 'title': \"Enhancing College Students' AI Literacy through Human-AI Co-Creation: A Quantitative Study\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3677892.3677913?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3677892.3677913, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-05-24', 'authors': [{'authorId': '2319454464', 'name': 'Haitao Wen'}, {'authorId': '2317717243', 'name': 'Xinyu Lin'}, {'authorId': '2317482543', 'name': 'Rongkang Liu'}, {'authorId': '2318285196', 'name': 'Chang Su'}]}\n",
      "No abstract: {'paperId': 'fa6bd291c8260bab77e6d113b3c33cfe9401d46d', 'title': 'Enhancing Travel Planning and Experiences with Multimodal ChatGPT 4.0', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3655497.3655529?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3655497.3655529, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-03-16', 'authors': [{'authorId': '2314883353', 'name': 'Jianhao Zhang'}, {'authorId': '2305969781', 'name': 'Daniel J. Mills'}, {'authorId': '2248739797', 'name': 'Hui-Wen Huang'}]}\n",
      "No abstract: {'paperId': '5ea33e30486b0f209c7263616391012cef3f958b', 'title': 'Learning with AI Assistance: A Path to Better Task Performance or Dependence?', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3643562.3672610?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3643562.3672610, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-06-27', 'authors': [{'authorId': '2281033266', 'name': 'Sheer Karny'}, {'authorId': '2281033339', 'name': 'L. Mayer'}, {'authorId': '2261819899', 'name': 'Jackie Ayoub'}, {'authorId': '2261905291', 'name': 'Miao Song'}, {'authorId': '2312176973', 'name': 'Haotian Su'}, {'authorId': '2312040884', 'name': 'Danyang Tian'}, {'authorId': '1403036177', 'name': 'Ehsan Moradi-Pari'}, {'authorId': '1804885', 'name': 'M. Steyvers'}]}\n",
      "No abstract: {'paperId': '61072f64247bc3176b58fe51f84cd6f4f318c0b2', 'title': \"A Proposed Model of Learners' Acceptance and Trust of Pedagogical Conversational AI\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3657604.3664682?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3657604.3664682, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-07-09', 'authors': [{'authorId': '2223751112', 'name': 'Griffin Pitts'}, {'authorId': '2189226832', 'name': 'Viktoria Marcus'}, {'authorId': '2305852488', 'name': 'Sanaz Motamedi'}]}\n",
      "No abstract: {'paperId': 'bbb9a6d0eb8ca0fbaf23a9293559f76ba96f5067', 'title': 'International Workshop on Algorithmic Bias in Search and Recommendation (BIAS)', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3626772.3657990?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3626772.3657990, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-07-10', 'authors': [{'authorId': '1738219', 'name': 'Alejandro Bellogín'}, {'authorId': '1824224', 'name': 'Ludovico Boratto'}, {'authorId': '2478971', 'name': 'S. Kleanthous'}, {'authorId': '2286141001', 'name': 'Elisabeth Lex'}, {'authorId': '1490679491', 'name': 'Francesca Maridina Malloci'}, {'authorId': '28922901', 'name': 'Mirko Marras'}]}\n",
      "No abstract: {'paperId': '46e49014b75b8b1981420707a928a9879bbd0ac0', 'title': 'UX Matters: The Critical Role of UX in Responsible AI', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3665504', 'status': 'HYBRID', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3665504?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3665504, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-06-26', 'authors': [{'authorId': '2257959294', 'name': 'Q. V. Liao'}, {'authorId': '3109339', 'name': 'Mihaela Vorvoreanu'}, {'authorId': '2301051721', 'name': 'Hariharan Subramonyam'}, {'authorId': '2308278431', 'name': 'Lauren Wilcox'}]}\n",
      "No abstract: {'paperId': 'dfe66446a3cee5477f04a8bed035975c1ab70743', 'title': 'Simulating the Human in HCD with ChatGPT: Redesigning Interaction Design with AI', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3637436', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3637436?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3637436, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2024-01-01', 'authors': [{'authorId': '2257009988', 'name': 'Albrecht Schmidt'}, {'authorId': '52205093', 'name': 'Passant Elagroudy'}, {'authorId': '1396850289', 'name': 'Fiona Draxler'}, {'authorId': '2278854073', 'name': 'Frauke Kreuter'}, {'authorId': '2247922398', 'name': 'Robin Welsch'}]}\n",
      "No abstract: {'paperId': '5a971f2a98e14e785d720a23043b9a89398bc2a3', 'title': 'Enjoying Wine: Opportunities and Challenges for Interaction Design', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3624697?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3624697, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2023-11-01', 'authors': [{'authorId': '2715722', 'name': 'J. Paay'}]}\n",
      "No abstract: {'paperId': 'b930ea2c91fce353b703b6274b0df9172a35ac9f', 'title': 'Introduction: toward the design, construction, and deployment of multimodal-multisensor interfaces', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3233795.3233797?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3233795.3233797, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2019-07-16', 'authors': []}\n",
      "No abstract: {'paperId': 'a6806dce15d1ca19321dac5fe4be845ed68a7fb5', 'title': 'TellTime: An AI-Augmented Calendar with a Voice Interface for Collecting Time-Use Data', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712116?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712116, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2052707659', 'name': 'M. Hoefer'}, {'authorId': '2351108191', 'name': 'Raegan Rychecky'}, {'authorId': '2351130191', 'name': 'Max Gong'}, {'authorId': '1804450', 'name': 'Stephen Voida'}]}\n",
      "No publicationDate: {'paperId': 'a6806dce15d1ca19321dac5fe4be845ed68a7fb5', 'title': 'TellTime: An AI-Augmented Calendar with a Voice Interface for Collecting Time-Use Data', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712116?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712116, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2052707659', 'name': 'M. Hoefer'}, {'authorId': '2351108191', 'name': 'Raegan Rychecky'}, {'authorId': '2351130191', 'name': 'Max Gong'}, {'authorId': '1804450', 'name': 'Stephen Voida'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '883447e932eea818684c9bd7880be3799e183c26', 'title': 'Personalising AI Assistance Based on Overreliance Rate in AI-Assisted Decision Making', 'abstract': 'Personalising decision-making assistance to diferent users and tasks can improve human-AI team performance, such as by appropriately impacting reliance on AI assistance. However, people are diferent in many ways, with many hidden qualities, and adapting AI assistance to these hidden qualities is difcult. In this work, we consider a hidden quality previously identifed as important: over-reliance on AI assistance. We would like to (i) quickly determine the value of this hidden quality, and (ii) personalise AI assistance based on this value. In our frst study, we introduce a few probe questions (where we know the true answer) to determine if a user is an overrelier or not, fnding that correctly-chosen probe questions work well. In our second study, we improve human-AI team performance, personalising AI assistance based on users’ overreliance quality. Exploratory analysis indicates that people learn diferent strategies of using AI assistance depending on what AI assistance they saw previously, indicating that we may need to take this into account when designing adaptive AI assistance. We hope that future work will continue exploring how to infer and personalise to other important hidden qualities.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712128?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712128, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '15187083', 'name': 'S. Swaroop'}, {'authorId': '2344404313', 'name': 'Zana Buçinca'}, {'authorId': '2253689875', 'name': 'Krzysztof Z. Gajos'}, {'authorId': '1388372395', 'name': 'F. Doshi-Velez'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '2db00739dd98acaac5c2c8cb87566e7f9933c442', 'title': 'STEP-HAI: Strengthening Engineering Psychology for Human-Algorithm Interactions', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716156?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716156, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2211295964', 'name': 'Patricia K. Kahr'}, {'authorId': '1491708226', 'name': 'Tim Schrills'}, {'authorId': '2270527261', 'name': 'Thomas Franke'}]}\n",
      "No publicationDate: {'paperId': '2db00739dd98acaac5c2c8cb87566e7f9933c442', 'title': 'STEP-HAI: Strengthening Engineering Psychology for Human-Algorithm Interactions', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716156?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716156, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2211295964', 'name': 'Patricia K. Kahr'}, {'authorId': '1491708226', 'name': 'Tim Schrills'}, {'authorId': '2270527261', 'name': 'Thomas Franke'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '387c12eda2049f5789327835c4c5cc8340968f45', 'title': 'Counterfactual Explanations May Not Be the Best Algorithmic Recourse Approach', 'abstract': 'Algorithmic recourse is a rapidly developing subfeld in explainable AI (XAI) concerned with providing individuals subject to adverse high-stakes algorithmic outcomes with explanations indicating how to reverse said outcomes. While XAI research in the machine learning community doesn’t confne itself to counterfactual explanations, its algorithmic recourse subfeld does, adopting the assumption that the optimal way to provide recourse is through counterfactual explanations. Though there has been extensive human-AI interaction research on explanations, translating these fndings to the algorithmic recourse setting is non-obvious due to meaningful problem setting diferences, leaving the question of whether coun-terfactuals are the most optimal explanation paradigm for recourse unanswered. While intuitively satisfying, the prescriptive nature of counterfactuals makes them vulnerable to poor outcomes when circumstances unknown to the decision-making and explanation generating algorithms afect re-application strategies. With these concerns in mind, we designed a series of experiments comparing diferent explanation methods in the recourse setting, explicitly incorporating scenarios where circumstances unknown to the decision-making and explanation algorithms afect re-application strategies. In Experiment 1, we compared counterfactuals with reason codes, a simple feature-based explanation, fnding that they both yield comparable re-application success, and that reason codes led to better user outcomes when unknown circumstances had a high impact on re-application strategies. In Experiment 2, we sought to improve on reason code outcomes, comparing them to feature attributions, a more informative feature-based explanation, but found no improvements. Finally, in Experiment 3, we aimed to improve on reason code outcomes with a multiple counterfactual explanation condition, fnding that multiple counterfactuals led to higher re-application success but still resulted in comparatively worse user outcomes in the face of high impact unknown circum-stances. Taken together, these fndings call into question whether the standard counterfactual paradigm is the best approach for the algorithmic recourse problem setting.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712095?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712095, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295262315', 'name': 'Sohini Upadhyay'}, {'authorId': '1892673', 'name': 'Himabindu Lakkaraju'}, {'authorId': '2253689875', 'name': 'Krzysztof Z. Gajos'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '843531bb7552634b79dda02668c851a337a4016e', 'title': 'HEPHA: A Mixed-Initiative Image Labeling Tool for Specialized Domains', 'abstract': 'Image labeling is an important task for training computer vision models. In specialized domains, such as healthcare, it is expensive and challenging to recruit specialists for image labeling. We propose HEPHA, a mixed-initiative image labeling tool that elicits human expertise via inductive logic learning to infer and refine labeling rules. Each rule comprises visual predicates that describe the image. HEPHA enables users to iteratively refine the rules by either direct manipulation through a visual programming interface or by labeling more images. To facilitate rule refinement, HEPHA recommends which rule to edit and which predicate to update. For users unfamiliar with visual programming, HEPHA suggests diverse and informative images to users for further labeling. We conducted a within-subjects user study with 16 participants and compared HEPHA with a variant of HEPHA and a deep learning-based approach. We found that HEPHA outperforms the two baselines in both specialized-domain and general-domain image labeling tasks. Our code is available at https://github.com/Neural-Symbolic-Image-Labeling/NSILWeb.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.03094, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2220574254', 'name': 'Shiyuan Zhou'}, {'authorId': '2209644838', 'name': 'Bingxuan Li'}, {'authorId': '2348594288', 'name': 'Xiyuan Chen'}, {'authorId': '2216713818', 'name': 'Zhi Tu'}, {'authorId': '2236470780', 'name': 'Yifeng Wang'}, {'authorId': '2349406667', 'name': 'Yiwen Xiang'}, {'authorId': '2301169511', 'name': 'Tianyi Zhang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'b5c354020be5d770c6071662984b770435e1b9a8', 'title': 'Controlling AI Agent Participation in Group Conversations: A Human-Centered Approach', 'abstract': \"Conversational AI agents are commonly applied within single-user, turn-taking scenarios. The interaction mechanics of these scenarios are trivial: when the user enters a message, the AI agent produces a response. However, the interaction dynamics are more complex within group settings. How should an agent behave in these settings? We report on two experiments aimed at uncovering users' experiences of an AI agent's participation within a group, in the context of group ideation (brainstorming). In the first study, participants benefited from and preferred having the AI agent in the group, but participants disliked when the agent seemed to dominate the conversation and they desired various controls over its interactive behaviors. In the second study, we created functional controls over the agent's behavior, operable by group members, to validate their utility and probe for additional requirements. Integrating our findings across both studies, we developed a taxonomy of controls for when, what, and where a conversational AI agent in a group should respond, who can control its behavior, and how those controls are specified and implemented. Our taxonomy is intended to aid AI creators to think through important considerations in the design of mixed-initiative conversational agents.\", 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2501.17258', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.17258, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1764589', 'name': 'Stephanie Houde'}, {'authorId': '2072258731', 'name': 'Kristina Brimijoin'}, {'authorId': '2296289729', 'name': 'Michael J. Muller'}, {'authorId': '2068083519', 'name': 'Steven I. Ross'}, {'authorId': '2296277502', 'name': 'Darío Andrés Silva Moran'}, {'authorId': '2296668971', 'name': 'G. Gonzalez'}, {'authorId': '51296575', 'name': 'Siya Kunde'}, {'authorId': '2342686984', 'name': 'Morgan A. Foreman'}, {'authorId': '1927553', 'name': 'Justin D. Weisz'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '73a571746e305f15deaa02e4aa9b6964615931c4', 'title': 'Understanding and Improving Accessibility in AI-Generated Interfaces through Interactive Prompt Engineering Methods', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716347?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716347, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '146081253', 'name': 'Alexandra E. Gurita'}]}\n",
      "No publicationDate: {'paperId': '73a571746e305f15deaa02e4aa9b6964615931c4', 'title': 'Understanding and Improving Accessibility in AI-Generated Interfaces through Interactive Prompt Engineering Methods', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716347?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716347, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '146081253', 'name': 'Alexandra E. Gurita'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'b7e1b91d62d3807d6539c0a95dc4a1d12239fe08', 'title': 'BEHAVE AI: BEst Practices and Guidelines for Human-Centric Design and EvAluation of ProactiVE AI Agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716155?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2291519335', 'name': 'Matthias Kraus'}, {'authorId': '92344344', 'name': 'Sebastian Zepf'}, {'authorId': '2350879510', 'name': 'Rebecca Westhäußer'}, {'authorId': '2350961761', 'name': 'Isabel Feustel'}, {'authorId': '1380223843', 'name': 'Nima Zargham'}, {'authorId': '1723169', 'name': 'Ilhan Aslan'}, {'authorId': '2200010253', 'name': 'Justin Edwards'}, {'authorId': '2264242701', 'name': 'Sven Mayer'}, {'authorId': '2150503', 'name': 'Dimosthenis Kontogiorgos'}, {'authorId': '1811473941', 'name': 'Nicolas Wagner'}, {'authorId': '2190753204', 'name': 'Elisabeth André'}]}\n",
      "No publicationDate: {'paperId': 'b7e1b91d62d3807d6539c0a95dc4a1d12239fe08', 'title': 'BEHAVE AI: BEst Practices and Guidelines for Human-Centric Design and EvAluation of ProactiVE AI Agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716155?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2291519335', 'name': 'Matthias Kraus'}, {'authorId': '92344344', 'name': 'Sebastian Zepf'}, {'authorId': '2350879510', 'name': 'Rebecca Westhäußer'}, {'authorId': '2350961761', 'name': 'Isabel Feustel'}, {'authorId': '1380223843', 'name': 'Nima Zargham'}, {'authorId': '1723169', 'name': 'Ilhan Aslan'}, {'authorId': '2200010253', 'name': 'Justin Edwards'}, {'authorId': '2264242701', 'name': 'Sven Mayer'}, {'authorId': '2150503', 'name': 'Dimosthenis Kontogiorgos'}, {'authorId': '1811473941', 'name': 'Nicolas Wagner'}, {'authorId': '2190753204', 'name': 'Elisabeth André'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '10cc0816b50a067e14682c310f94e505f478bb7e', 'title': 'Designing AI Interfaces for Transparent Decision-Making and Ethical Reflection', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716150?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716150, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2307598935', 'name': 'Maalvika Bhat'}]}\n",
      "No publicationDate: {'paperId': '10cc0816b50a067e14682c310f94e505f478bb7e', 'title': 'Designing AI Interfaces for Transparent Decision-Making and Ethical Reflection', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708557.3716150?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708557.3716150, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2307598935', 'name': 'Maalvika Bhat'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '1944f2f461b6cc7414cc4bd7c955fb18ad8b318f', 'title': 'How Dynamic vs. Static Presentation Shapes User Perception and Emotional Connection to Text-Based AI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712131?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712131, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2307598935', 'name': 'Maalvika Bhat'}]}\n",
      "No publicationDate: {'paperId': '1944f2f461b6cc7414cc4bd7c955fb18ad8b318f', 'title': 'How Dynamic vs. Static Presentation Shapes User Perception and Emotional Connection to Text-Based AI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712131?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712131, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2307598935', 'name': 'Maalvika Bhat'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '32ac697213217e9e5b7aaf721f9223473ff0a5c6', 'title': 'Less or More: Towards Glanceable Explanations for LLM Recommendations Using Ultra-Small Devices', 'abstract': \"Large Language Models (LLMs) have shown remarkable potential in recommending everyday actions as personal AI assistants, while Explainable AI (XAI) techniques are being increasingly utilized to help users understand why a recommendation is given. Personal AI assistants today are often located on ultra-small devices such as smartwatches, which have limited screen space. The verbosity of LLM-generated explanations, however, makes it challenging to deliver glanceable LLM explanations on such ultra-small devices. To address this, we explored 1) spatially structuring an LLM's explanation text using defined contextual components during prompting and 2) presenting temporally adaptive explanations to users based on confidence levels. We conducted a user study to understand how these approaches impacted user experiences when interacting with LLM recommendations and explanations on ultra-small devices. The results showed that structured explanations reduced users' time to action and cognitive load when reading an explanation. Always-on structured explanations increased users' acceptance of AI recommendations. However, users were less satisfied with structured explanations compared to unstructured ones due to their lack of sufficient, readable details. Additionally, adaptively presenting structured explanations was less effective at improving user perceptions of the AI compared to the always-on structured explanations. Together with users' interview feedback, the results led to design implications to be mindful of when personalizing the content and timing of LLM explanations that are displayed on ultra-small devices.\", 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.19410, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295486007', 'name': 'Xinru Wang'}, {'authorId': '2297823679', 'name': 'Mengjie Yu'}, {'authorId': '2347480570', 'name': 'Hannah Nguyen'}, {'authorId': '2347353042', 'name': 'Michael Iuzzolino'}, {'authorId': '2347346783', 'name': 'Tianyi Wang'}, {'authorId': '2347315680', 'name': 'Peiqi Tang'}, {'authorId': '2347348992', 'name': 'Natasha Lynova'}, {'authorId': '2297771376', 'name': 'Co Tran'}, {'authorId': '2297816926', 'name': 'Ting Zhang'}, {'authorId': '2341717168', 'name': 'Naveen Sendhilnathan'}, {'authorId': '2286556571', 'name': 'Hrvoje Benko'}, {'authorId': '2347492185', 'name': 'Haijun Xia'}, {'authorId': '2328586724', 'name': 'Tanya R. Jonker'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'e9d57c1a320356112347054cf154fb7f0691db2a', 'title': 'Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant', 'abstract': \"Explainable artificial intelligence (XAI) methods are being proposed to help interpret and understand how AI systems reach specific predictions. Inspired by prior work on conversational user interfaces, we argue that augmenting existing XAI methods with conversational user interfaces can increase user engagement and boost user understanding of the AI system. In this paper, we explored the impact of a conversational XAI interface on users' understanding of the AI system, their trust, and reliance on the AI system. In comparison to an XAI dashboard, we found that the conversational XAI interface can bring about a better understanding of the AI system among users and higher user trust. However, users of both the XAI dashboard and conversational XAI interfaces showed clear overreliance on the AI system. Enhanced conversations powered by large language model (LLM) agents amplified over-reliance. Based on our findings, we reason that the potential cause of such overreliance is the illusion of explanatory depth that is concomitant with both XAI interfaces. Our findings have important implications for designing effective conversational XAI interfaces to facilitate appropriate reliance and improve human-AI collaboration. Code can be found at https://github.com/delftcrowd/IUI2025_ConvXAI\", 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2501.17546', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.17546, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '51149404', 'name': 'Gaole He'}, {'authorId': '2090943665', 'name': 'Nilay Aishwarya'}, {'authorId': '2516584', 'name': 'U. Gadiraju'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '4aa011bd05d87b3aef12e9c9e73aab158a644987', 'title': 'Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning', 'abstract': None, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2410.08922', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712104?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712104, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2351191864', 'name': 'Majeed Kazemitabaar'}, {'authorId': '2325730952', 'name': 'Oliver Huang'}, {'authorId': '2325731524', 'name': 'Sangho Suh'}, {'authorId': '2280145055', 'name': 'Austin Z Henley'}, {'authorId': '2280146888', 'name': 'Tovi Grossman'}]}\n",
      "No publicationDate: {'paperId': '4aa011bd05d87b3aef12e9c9e73aab158a644987', 'title': 'Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning', 'abstract': None, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2410.08922', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712104?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712104, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2351191864', 'name': 'Majeed Kazemitabaar'}, {'authorId': '2325730952', 'name': 'Oliver Huang'}, {'authorId': '2325731524', 'name': 'Sangho Suh'}, {'authorId': '2280145055', 'name': 'Austin Z Henley'}, {'authorId': '2280146888', 'name': 'Tovi Grossman'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'a7ae2aec7b3694b3857ac0f9852bee0f45cdf4eb', 'title': 'From Oracular to Judicial: Enhancing Clinical Decision Making through Contrasting Explanations and a Novel Interaction Protocol', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712157?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712157, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2265739666', 'name': 'Federico Cabitza'}, {'authorId': '2224148853', 'name': 'Lorenzo Famiglini'}, {'authorId': '2326950425', 'name': 'Caterina Fregosi'}, {'authorId': '2322053722', 'name': 'Samuele Pe'}, {'authorId': '2135731778', 'name': 'Enea Parimbelli'}, {'authorId': '40195164', 'name': 'G. A. La Maida'}, {'authorId': '2263063735', 'name': 'Enrico Gallazzi'}]}\n",
      "No publicationDate: {'paperId': 'a7ae2aec7b3694b3857ac0f9852bee0f45cdf4eb', 'title': 'From Oracular to Judicial: Enhancing Clinical Decision Making through Contrasting Explanations and a Novel Interaction Protocol', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712157?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712157, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2265739666', 'name': 'Federico Cabitza'}, {'authorId': '2224148853', 'name': 'Lorenzo Famiglini'}, {'authorId': '2326950425', 'name': 'Caterina Fregosi'}, {'authorId': '2322053722', 'name': 'Samuele Pe'}, {'authorId': '2135731778', 'name': 'Enea Parimbelli'}, {'authorId': '40195164', 'name': 'G. A. La Maida'}, {'authorId': '2263063735', 'name': 'Enrico Gallazzi'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'e9d3870077dc5fb3119b19792898f0b6b319e0a0', 'title': 'Evaluating the Impact of AI-Generated Visual Explanations on Decision-Making for Image Matching', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712121?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712121, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2149969168', 'name': 'Albatool Wazzan'}, {'authorId': '2351075968', 'name': 'Marcus Wright'}, {'authorId': '2279833262', 'name': 'Stephen MacNeil'}, {'authorId': '2305414360', 'name': 'Richard Souvenir'}]}\n",
      "No publicationDate: {'paperId': 'e9d3870077dc5fb3119b19792898f0b6b319e0a0', 'title': 'Evaluating the Impact of AI-Generated Visual Explanations on Decision-Making for Image Matching', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712121?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712121, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2149969168', 'name': 'Albatool Wazzan'}, {'authorId': '2351075968', 'name': 'Marcus Wright'}, {'authorId': '2279833262', 'name': 'Stephen MacNeil'}, {'authorId': '2305414360', 'name': 'Richard Souvenir'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '94d7f5efcd84a302e1ade890c31c4cc718359d44', 'title': 'AiModerator: A Co-Pilot for Hyper-Contextualization in Political Debate Video', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712148?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712148, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295461497', 'name': 'Peter Andrews'}, {'authorId': '2295460789', 'name': 'Njål Borch'}, {'authorId': '2271698001', 'name': 'Morten Fjeld'}]}\n",
      "No publicationDate: {'paperId': '94d7f5efcd84a302e1ade890c31c4cc718359d44', 'title': 'AiModerator: A Co-Pilot for Hyper-Contextualization in Political Debate Video', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712148?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712148, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295461497', 'name': 'Peter Andrews'}, {'authorId': '2295460789', 'name': 'Njål Borch'}, {'authorId': '2271698001', 'name': 'Morten Fjeld'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '366c6fcfd7c8609ba8ad03a3e0b4707064840a81', 'title': 'The Influence of Curiosity Traits and On-Demand Explanations in AI-Assisted Decision-Making', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '34532042', 'name': 'Federico Maria Cau'}, {'authorId': '2598389', 'name': 'L. D. Spano'}]}\n",
      "No publicationDate: {'paperId': '366c6fcfd7c8609ba8ad03a3e0b4707064840a81', 'title': 'The Influence of Curiosity Traits and On-Demand Explanations in AI-Assisted Decision-Making', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '34532042', 'name': 'Federico Maria Cau'}, {'authorId': '2598389', 'name': 'L. D. Spano'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '217b22a3fe4b7593e8795f93ed22d8b48a6c5add', 'title': 'Can LLMs Recommend More Responsible Prompts?', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712137?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712137, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2301078609', 'name': 'Vagner Figueredo de Santana'}, {'authorId': '34376356', 'name': 'Sara E. Berger'}, {'authorId': '2351141699', 'name': 'Tiago Machado'}, {'authorId': '1505777245', 'name': 'Maysa Malfiza Garcia de Macedo'}, {'authorId': '2176421802', 'name': 'C. S. Sanctos'}, {'authorId': '2351823199', 'name': 'Lemara Williams'}, {'authorId': '2351101517', 'name': 'Zhaoqing Wu'}]}\n",
      "No publicationDate: {'paperId': '217b22a3fe4b7593e8795f93ed22d8b48a6c5add', 'title': 'Can LLMs Recommend More Responsible Prompts?', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712137?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712137, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2301078609', 'name': 'Vagner Figueredo de Santana'}, {'authorId': '34376356', 'name': 'Sara E. Berger'}, {'authorId': '2351141699', 'name': 'Tiago Machado'}, {'authorId': '1505777245', 'name': 'Maysa Malfiza Garcia de Macedo'}, {'authorId': '2176421802', 'name': 'C. S. Sanctos'}, {'authorId': '2351823199', 'name': 'Lemara Williams'}, {'authorId': '2351101517', 'name': 'Zhaoqing Wu'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '88406be8fc085fc268fdb951997cf87e9e437b09', 'title': 'CoPrompter: User-Centric Evaluation of LLM Instruction Alignment for Improved Prompt Engineering', 'abstract': None, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2411.06099', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712102?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2299069205', 'name': 'Ishika Joshi'}, {'authorId': '49260478', 'name': 'Simra Shahid'}, {'authorId': '2330189329', 'name': 'S. Venneti'}, {'authorId': '2273082180', 'name': 'Manushree Vasu'}, {'authorId': '2330483398', 'name': 'Yantao Zheng'}, {'authorId': '2330299769', 'name': 'Yunyao Li'}, {'authorId': '2265756284', 'name': 'Balaji Krishnamurthy'}, {'authorId': '51192588', 'name': 'G. Chan'}]}\n",
      "No publicationDate: {'paperId': '88406be8fc085fc268fdb951997cf87e9e437b09', 'title': 'CoPrompter: User-Centric Evaluation of LLM Instruction Alignment for Improved Prompt Engineering', 'abstract': None, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2411.06099', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712102?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2299069205', 'name': 'Ishika Joshi'}, {'authorId': '49260478', 'name': 'Simra Shahid'}, {'authorId': '2330189329', 'name': 'S. Venneti'}, {'authorId': '2273082180', 'name': 'Manushree Vasu'}, {'authorId': '2330483398', 'name': 'Yantao Zheng'}, {'authorId': '2330299769', 'name': 'Yunyao Li'}, {'authorId': '2265756284', 'name': 'Balaji Krishnamurthy'}, {'authorId': '51192588', 'name': 'G. Chan'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '392f3d2eaea86467193eaf6f1753beb1c98067b4', 'title': 'Redefining Affordance via Computational Rationality', 'abstract': 'Affordances, a foundational concept in human-computer interaction and design, have traditionally been explained by direct-perception theories, which assume that individuals perceive action possibilities directly from the environment. However, these theories fall short of explaining how affordances are perceived, learned, refined, or misperceived, and how users choose between multiple affordances in dynamic contexts. This paper introduces a novel affordance theory grounded in Computational Rationality, positing that humans construct internal representations of the world based on bounded sensory inputs. Within these internal models, affordances are inferred through two core mechanisms: feature recognition and hypothetical motion trajectories. Our theory redefines affordance perception as a decision-making process, driven by two components: confidence (the perceived likelihood of successfully executing an action) and predicted utility (the expected value of the outcome). By balancing these factors, individuals make informed decisions about which actions to take. Our theory frames affordances perception as dynamic, continuously learned, and refined through reinforcement and feedback. We validate the theory via thought experiments and demonstrate its applicability across diverse types of affordances (e.g., physical, digital, social). Beyond clarifying and generalizing the understanding of affordances across contexts, our theory serves as a foundation for improving design communication and guiding the development of more adaptive and intuitive systems that evolve with user capabilities.', 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2501.09233', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.09233, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2340569733', 'name': 'Yi-Chi Liao'}, {'authorId': '2319602671', 'name': 'Christian Holz'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '2cb76968d296c298d41ddf5886f09aa2d9b1c406', 'title': 'Benefits of Machine Learning Explanations: Improved Learning in an AI-assisted Sequence Prediction Task', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712155?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2333305303', 'name': 'Yu Liang'}, {'authorId': '50996831', 'name': 'Dennis Collaris'}, {'authorId': '1918235', 'name': 'M. Willemsen'}, {'authorId': '39433303', 'name': 'J. van Wijk'}]}\n",
      "No publicationDate: {'paperId': '2cb76968d296c298d41ddf5886f09aa2d9b1c406', 'title': 'Benefits of Machine Learning Explanations: Improved Learning in an AI-assisted Sequence Prediction Task', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708359.3712155?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708359.3712155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2333305303', 'name': 'Yu Liang'}, {'authorId': '50996831', 'name': 'Dennis Collaris'}, {'authorId': '1918235', 'name': 'M. Willemsen'}, {'authorId': '39433303', 'name': 'J. van Wijk'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'beb2b8783c1f76775c8b5c83c21b5b318c81d3e1', 'title': 'The Digital Attention Heuristics: Supporting the User’s Attention by Design', 'abstract': '\\n The HCI research community has traditionally considered digital wellbeing an end-user responsibility, designing tools for digital self-control that support them to self-regulate their usage of apps and websites. Yet, these attempts are often ineffective in the long term, as many tech companies still adopt “attention-capture” designs that compromise users’ sense of agency and self-control. Taking a complementary perspective, this paper presents a set of eight heuristics to create user interfaces that preserve and respect user attention\\n by design\\n . The heuristics stem from a systematic literature review and are grounded in the three fundamental psychological needs defined by the self-determination theory, i.e., autonomy, competence, and relatedness. In addition to being informed by theory and research, each heuristic is accompanied by practical strategies and real-world examples, offering designers actionable guidelines to value people’s attention in user interfaces.\\n', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3725215?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3725215, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '122383968', 'name': 'Alberto Monge Roffarello'}, {'authorId': '66596061', 'name': 'Luigi De Russis'}, {'authorId': '10688219', 'name': 'Kai Lukoff'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'fb189ec8722ff9b8a76b5044e208d31fc21dc33f', 'title': 'Feeds of Distrust: Investigating How AI-Powered News Chatbots Shape User Trust and Perceptions', 'abstract': \"\\n The start of the 2020s ushered in a new era of Artificial Intelligence through the rise of Generative AI Large Language Models (LLMs) such as Chat-GPT. These AI chatbots offer a form of interactive agency by enabling users to ask questions and query for more information. However, prior research only considers\\n if\\n LLMs have a political bias or agenda, and not\\n how\\n a biased LLM can impact a user's opinion and trust. Our study bridges this gap by investigating a scenario where users read online news articles and then engage with an interactive AI chatbot, where both the news and the AI are biased to hold a particular stance on a news topic. Interestingly, participants were far more likely to adopt the narrative of a biased chatbot over news articles with an opposing stance. Participants were also substantially more inclined to adopt the chatbot's narrative if its stance aligned with the news—all compared to a control\\n news-article only\\n group. Our findings suggest that the very interactive agency offered by an AI chatbot significantly enhances its perceived trust and persuasive ability compared to the\\n ‘static’\\n articles from established news outlets, raising concerns about the potential for AI-driven indoctrination. We outline the reasons behind this phenomenon and conclude with the implications of biased LLMs for HCI research, as well as the risks of Generative AI undermining democratic integrity through AI-driven Information Warfare.\\n\", 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3722227?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3722227, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2203245199', 'name': 'Jarod Govers'}, {'authorId': '101637895', 'name': 'Saumya Pareek'}, {'authorId': '2298908587', 'name': 'Eduardo Velloso'}, {'authorId': '2297296238', 'name': 'Jorge Gonçalves'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '9bc125d6ba4cf98802600f394ed0edd409f29a92', 'title': 'EAAI-24 Blue Sky Ideas in Artificial Intelligence Education from the AAAI/ACM SIGAI New and Future AI Educator Program', 'abstract': 'The 14th Symposium on Educational Advances in Artificial Intelligence (EAAI-24), cochaired by Marion Neumann and Stephanie Rosenthal, continued the tradition of the AAAI/ACM SIGAI New and Future AI Educator (NFAIED) Program to support the training of early-career university faculty, secondary school faculty, and future educators (PhD candidates or postdocs who intend a career in academia).\\n This paper is a collection of the \"blue sky\" essays of the 2024 NFAIED awardees, intended to help motivate discussion around various current and important issues in AI education.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3715920.3715922?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3715920.3715922, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '40945167', 'name': 'Marion Neumann'}, {'authorId': '2349489787', 'name': 'Stephanie Rosenthal'}, {'authorId': '2349597939', 'name': 'Justin Stevens'}, {'authorId': '2349482935', 'name': 'Rachel Lugo'}, {'authorId': '2349488735', 'name': 'William Agnew'}, {'authorId': '2349482894', 'name': 'Shira Wein'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '7cecc9215ba849f3e744b85e4b2e0d43479ce1b5', 'title': 'Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education', 'abstract': 'Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This paper explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This paper discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analysis reveals that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like ‘certainly’ regarding bug fixing decisions, and apology phrases such as ‘apologize’ when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3722229?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3722229, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '52378466', 'name': 'E. Alomar'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'cec29d405f846c47336f6fc5a5747ea61ac6d577', 'title': 'When the Prompt becomes the Codebook: Grounded Prompt Engineering (GROPROE) and its application to Belonging Analytics', 'abstract': 'With the emergence of generative AI, the field of Learning Analytics (LA) has increasingly embraced the use of Large Language Models (LLMs) to automate qualitative analysis. Deductive analysis requires theoretical or other conceptual grounding to inform coding. However, few studies detail the process of translating the literature into a codebook, and then into an effective LLM prompt. In this paper, we introduce Grounded Prompt Engineering (GROPROE) as a systematic process to develop a literature-grounded prompt for deductive analysis. We demonstrate our GROPROE process on a dataset of 860 written reflections, coding for students’ affective engagement and sense of belonging. To evaluate the quality of the coding we demonstrate substantial human/LLM Inter-Annotator Reliability (IAR). To evaluate the consistency of LLM coding, a subset of the data was analysed 60 times using the LLM Quotient showing how this stabilized for most codes. We discuss the dynamics of human-AI interaction when following GROPROE, foregrounding how the prompt took over as the iteratively revised codebook, and how the LLM provoked codebook revision. The contributions to the LA field are threefold: (i) GROPROE as a systematic prompt-design process for deductive coding grounded in literature, (ii) a detailed worked example showing its application to Belonging Analytics, and (iii) implications for human-AI interaction in automated deductive analysis', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3706468.3706564?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3706468.3706564, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2290331942', 'name': 'Sriram Ramanathan'}, {'authorId': '97650534', 'name': 'Lisa-Angelique Lim'}, {'authorId': '2346788931', 'name': 'Nazanin Rezazadeh Mottaghi'}, {'authorId': '144324892', 'name': 'S. B. Shum'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'a311b7bef8db910aaf7fc5dbeed3832f82efca71', 'title': 'Pattern analysis of ambitious science talk between preservice teachers and AI-powered student agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3706468.3706570?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3706468.3706570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2291670746', 'name': 'Alex Barrett'}, {'authorId': '2261866996', 'name': 'Fengfeng Ke'}, {'authorId': '2180262774', 'name': 'Nuodi Zhang'}, {'authorId': '1864090606', 'name': 'Chih-Pu Dai'}, {'authorId': '29916274', 'name': 'Saptarshi Bhowmik'}, {'authorId': '2305309745', 'name': 'Xin Yuan'}]}\n",
      "No publicationDate: {'paperId': 'a311b7bef8db910aaf7fc5dbeed3832f82efca71', 'title': 'Pattern analysis of ambitious science talk between preservice teachers and AI-powered student agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3706468.3706570?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3706468.3706570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2291670746', 'name': 'Alex Barrett'}, {'authorId': '2261866996', 'name': 'Fengfeng Ke'}, {'authorId': '2180262774', 'name': 'Nuodi Zhang'}, {'authorId': '1864090606', 'name': 'Chih-Pu Dai'}, {'authorId': '29916274', 'name': 'Saptarshi Bhowmik'}, {'authorId': '2305309745', 'name': 'Xin Yuan'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '65aebd40e2912d28ebe5fc3ec40eaf75605f3772', 'title': 'Designing Visual Explanations and Learner Controls to Engage Adolescents in AI-Supported Exercise Selection', 'abstract': \"E-learning platforms that personalise content selection with AI are often criticised for lacking transparency and controllability. Researchers have therefore proposed solutions such as open learner models and letting learners select from ranked recommendations, which engage learners before or after the AI-supported selection process. However, little research has explored how learners - especially adolescents - could engage during such AI-supported decision-making. To address this open challenge, we iteratively designed and implemented a control mechanism that enables learners to steer the difficulty of AI-compiled exercise series before practice, while interactively analysing their control's impact in a 'what-if' visualisation. We evaluated our prototypes through four qualitative studies involving adolescents, teachers, EdTech professionals, and pedagogical experts, focusing on different types of visual explanations for recommendations. Our findings suggest that 'why' explanations do not always meet the explainability needs of young learners but can benefit teachers. Additionally, 'what-if' explanations were well-received for their potential to boost motivation. Overall, our work illustrates how combining learner control and visual explanations can be operationalised on e-learning platforms for adolescents. Future research can build upon our designs for 'why' and 'what-if' explanations and verify our preliminary findings.\", 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2412.16034', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.16034, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2007839030', 'name': 'Jeroen Ooge'}, {'authorId': '2336730261', 'name': 'Arno Vanneste'}, {'authorId': '2075160673', 'name': 'Maxwell Szymanski'}, {'authorId': '2629441', 'name': 'K. Verbert'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '35fae3807b48042ab32a941470d0654112e003a4', 'title': 'HCI for AGI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708815?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708815, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2347525196', 'name': 'Meredith Ringel Morris'}]}\n",
      "No publicationDate: {'paperId': '35fae3807b48042ab32a941470d0654112e003a4', 'title': 'HCI for AGI', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708815?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708815, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2347525196', 'name': 'Meredith Ringel Morris'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '7f2cdc54ffbf02bfa3e7974b1f5f1c96b1620896', 'title': \"Artificial Intelligence Psychological Empowerment Among Asian Australian Immigrant Workers: Navigating Marginalization and Harnessing Artificial Intelligence's Power for Enhanced Workplace Agency\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3709026.3709100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3709026.3709100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2330165817', 'name': 'Yingnan Shi'}]}\n",
      "No publicationDate: {'paperId': '7f2cdc54ffbf02bfa3e7974b1f5f1c96b1620896', 'title': \"Artificial Intelligence Psychological Empowerment Among Asian Australian Immigrant Workers: Navigating Marginalization and Harnessing Artificial Intelligence's Power for Enhanced Workplace Agency\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3709026.3709100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3709026.3709100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2330165817', 'name': 'Yingnan Shi'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'e3530b03018ef5a33db9e7a4a27d910590cd05ca', 'title': 'Building Guardrails in AI Systems with Threat Modeling', 'abstract': 'Much like cars, AI technologies must undergo rigorous testing to ensure their safety and reliability. However, just as a 16-wheel truck’s brakes are different from that of a standard hatchback, AI models too may need distinct analyses based on their risk, size, application domain, and other factors. Prior research has attempted to do this, by identifying areas of concern for AI/ML applications and tools needed to simulate the effect of adversarial actors. However, currently, a variety of frameworks exist which poses challenges due to inconsistent terminology, focus, complexity, and interoperability issues, hindering effective threat discovery. In this paper, we present a meta-analysis of 14 AI threat modeling frameworks, providing a streamlined set of questions for AI/ML threat analysis. We then review this library, incorporating feedback from 10 experts to refine the questions. This refined set of questions allow practitioners to seamlessly integrate threat analysis for comprehensive manual evaluation of a wide range of AI/ML applications.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3674845', 'status': 'HYBRID', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3674845?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3674845, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2271461043', 'name': 'Jayati Dev'}, {'authorId': '9489049', 'name': 'N. Akhuseyinoglu'}, {'authorId': '52149445', 'name': 'Golam Kayas'}, {'authorId': '2308111554', 'name': 'Bahman Rashidi'}, {'authorId': '2308108656', 'name': 'Vaibhav Garg'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3d9061b160ff767cafeb71451b73ab973124255d', 'title': 'eSPACE: Leveraging Theoretical Foundations for the End-User Development of Cross-Device and IoT Applications', 'abstract': 'In the rapidly evolving landscape of cross-device computing and the Internet of Things (IoT), there is a need for intuitive and user-friendly solutions empowering end users to create and tailor their applications. To address this need, we analysed the different metaphors for end-user development (EUD) of cross-device and IoT applications. A key observation is the lack of addressing end user’s mental models when designing interactions among devices, resulting in less intuitive EUD tools. To fill this gap, we introduce eSPACE, an end-user authoring tool facilitating the development of cross-device and IoT applications. In contrast to most existing tools, eSPACE is grounded on strong theoretical foundations, including a conceptual model, reference framework as well as design guidelines and suitable metaphors. The effectiveness of these theoretical foundations in creating an intuitive and user-friendly EUD platform has been validated in a user study. Our study confirms eSPACE’s potential as a useful and easy to use tool for end-user application development. In addition, we present potential future research directions, including automation functionality, intelligibility and human-AI interaction. In discussing these future directions, we aim to foster and advance EUD research towards more end-user-accessible authoring environments for cross-device and IoT applications.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3716133?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3716133, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '3405397', 'name': 'Audrey Sanctorum'}, {'authorId': '2326764769', 'name': 'Beat Signer'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '9cfce57243f81e6e392aafcc63d282cfffa0a2d6', 'title': 'ConverSearch: Supporting Experts in Human Behavior Analysis of Conversational Videos with a Multimodal Scene Search Tool', 'abstract': '\\n Multimodal scene search of conversations is essential for unlocking valuable insights into social dynamics and enhancing our communication. While experts in conversational analysis have their own knowledge and skills to find key scenes, a lack of comprehensive, user-friendly tools that streamline the processing of diverse multimodal queries impedes efficiency and objectivity. To address this gap, we developed\\n ConverSearch\\n , a visual-programming-based tool based on insights for effective interface and implementation design derived from a formative study with experts. The tool allows experts to integrate various machine-learning algorithms to capture human behavioral cues without the need for coding. Our user study, employing the System Usability Scale (SUS) and satisfaction metrics, demonstrated high user preference, reflecting the tool’s ease of use and effectiveness in supporting scene search tasks. Additionally, through a deployment trial within industrial organizations, we confirmed the tool’s objectivity, reusability, and potential to enhance expert workflows. This suggests the advantages of expert-AI collaboration in domains requiring human contextual understanding and demonstrates how customizable, transparent tools yielding reusable artifacts can support expert-driven tasks in complex, multimodal environments.\\n', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3709012?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3709012, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2292515576', 'name': 'Riku Arakawa'}, {'authorId': '1491521654', 'name': 'Kiyosu Maeda'}, {'authorId': '33688371', 'name': 'Hiromu Yakura'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4302fcea5d7aab81f1b1c4fe3de363c1923ecbee', 'title': 'Towards Clinically Useful AI: From Radiology Practices in Global South and North to Visions of AI Support', 'abstract': 'Despite recent advancements, real-world use of Artificial Intelligence (AI) in radiology remains low, often due to the mismatch between AI offerings and the situated challenges faced by healthcare professionals. To bridge this gap, we conducted a field study at nine medical sites in Denmark and Kenya with two goals: (1) to understand the challenges faced by radiologists during chest X-ray practice; (2) to envision alternative AI futures that align with collaborative clinical work. This study uniquely grounds the AI design insights in the comprehensive characterisation of diagnostic work across multiple geographical and institutional contexts. Building on ideas articulated by interviewed radiologists (N=18), we conceptualised five visions that transcend the traditional notions of AI support. These visions emphasise that the clinical usefulness of AI-based systems depends on their configurability and flexibility across three dimensions: type of clinical site, expertise of medical professionals, and situational and patient contexts. Addressing these dependencies requires expanding the clinical AI design space by envisioning futures rooted in the realities of practice rather than solely following the trajectory of AI development.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3715115?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3715115, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1997966572', 'name': 'H. D. Zając'}, {'authorId': '2256266346', 'name': 'T. O. Andersen'}, {'authorId': '2344130659', 'name': 'Elijah Kwasa'}, {'authorId': '2308852354', 'name': 'Ruth Wanjohi'}, {'authorId': '2344178742', 'name': 'Mary K. Onyinkwa'}, {'authorId': '2344133141', 'name': 'Edward K. Mwaniki'}, {'authorId': '2302852778', 'name': 'S. N. Gitau'}, {'authorId': '2344135154', 'name': 'Shawnim S. Yaseen'}, {'authorId': '2140086050', 'name': 'J.F. Carlsen'}, {'authorId': '2065874926', 'name': 'Marco Fraccaro'}, {'authorId': '2218600129', 'name': 'M. Nielsen'}, {'authorId': '2279313634', 'name': 'Yunan Chen'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4adee81b4148bcd798d195e55b77616abc5945b9', 'title': 'Software Engineering by and for Humans in an AI Era', 'abstract': 'The landscape of software engineering is undergoing a transformative shift driven by advancements in machine learning, artificial intelligence (AI), and autonomous systems. This roadmap paper explores how these technologies are reshaping the field, positioning humans not only as end users but also as critical components within expansive software ecosystems. We examine the challenges and opportunities arising from this human-centered paradigm, including ethical considerations, fairness, and the intricate interplay between technical and human factors. By recognizing humans at the heart of the software lifecycle —spanning professional engineers, end users, and end-user developers —we emphasize the importance of inclusivity, human-aligned workflows, and the seamless integration of AI-augmented socio-technical systems. As software systems evolve to become more intelligent and human-centric, software engineering practices must adapt to this new reality. This paper provides a comprehensive examination of this transformation, outlining current trends, key challenges, and opportunities that define the emerging research and practice landscape, and envisioning a future where software engineering and AI work synergistically to place humans at the core of the ecosystem.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3715111?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3715111, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2094427532', 'name': 'S. Abrahão'}, {'authorId': '2279022894', 'name': 'John Grundy'}, {'authorId': '2251212418', 'name': 'Mauro Pezzè'}, {'authorId': '2309252972', 'name': 'M. Storey'}, {'authorId': '2343764297', 'name': 'Damian Andrew Tamburri'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '75fc1edce787713058c636af6b7b7b082fce5a04', 'title': 'Preparation of Personalized Medicines through Collaborative Robots: A Hybrid Approach to the End-User Development of Robot Programs', 'abstract': 'Galenic formulations are personalized medicines prepared by pharmacists in their laboratories. They are produced in small batches considering single patients’ characteristics, such as age, gender, allergies, and the like, thus contributing to responsible health. The production process is performed manually with the support of mechanic machines. This activity is time-consuming, prone to errors, and subject to quality variations. In this paper, we propose the integration of collaborative robots into the galenic formulation process to obtain several advantages, such as increased productivity, reduced variability, improved accuracy, and minimized risks associated with human error. Additionally, the use of robots can alleviate the physical burden on human operators, allowing them to focus on higher-level tasks that require critical thinking and decision-making. To achieve this goal, a software application, called PRAISE (Pharmaceutical Robotic and AI System for End users), has been developed; it is meant to support end users (i.e., pharmacists) in defining robot programs suitable to the case at hand. This application is conceived as an End-User Development (EUD) environment, which implements a hybrid interaction approach based on a natural language interface leveraging Large Language Models and a graphical interface to check and possibly revise the user-created robot programs. A user study carried out with 9 pharmacists demonstrates the validity of the approach.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3715852?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3715852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '121983406', 'name': 'Luigi Gargioni'}, {'authorId': '1791229', 'name': 'D. Fogli'}, {'authorId': '2287195923', 'name': 'Pietro Baroni'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'bc16fbba415ba9e208535e8a264385d60c391e95', 'title': 'Interdisciplinary Perspectives on Generative Artificial Intelligence Adoption in Higher Education: A Theoretical Framework Review', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3704289.3704293?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3704289.3704293, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2284544369', 'name': 'James Ewert Duah'}, {'authorId': '2342523753', 'name': 'Xin Lu'}, {'authorId': '2284545241', 'name': 'Paul McGivern'}, {'authorId': '2336039080', 'name': 'Yanguo Jing'}]}\n",
      "No publicationDate: {'paperId': 'bc16fbba415ba9e208535e8a264385d60c391e95', 'title': 'Interdisciplinary Perspectives on Generative Artificial Intelligence Adoption in Higher Education: A Theoretical Framework Review', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3704289.3704293?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3704289.3704293, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2284544369', 'name': 'James Ewert Duah'}, {'authorId': '2342523753', 'name': 'Xin Lu'}, {'authorId': '2284545241', 'name': 'Paul McGivern'}, {'authorId': '2336039080', 'name': 'Yanguo Jing'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '07cccf61c0d86d2bdb9978d3afd773c41644e71b', 'title': 'Roles emerging during the knowledge construction process in collaborative learning: Does a generative AI-support chatbot matter?', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702163.3702165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702163.3702165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2341556863', 'name': 'Rushi Gong'}, {'authorId': '2342081688', 'name': 'Rui Jiang'}, {'authorId': '2344801665', 'name': 'Chuanlei Guo'}, {'authorId': '2109745865', 'name': 'Wanqing Hu'}, {'authorId': '2110508005', 'name': 'Yanyan Li'}]}\n",
      "No publicationDate: {'paperId': '07cccf61c0d86d2bdb9978d3afd773c41644e71b', 'title': 'Roles emerging during the knowledge construction process in collaborative learning: Does a generative AI-support chatbot matter?', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702163.3702165?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702163.3702165, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2341556863', 'name': 'Rushi Gong'}, {'authorId': '2342081688', 'name': 'Rui Jiang'}, {'authorId': '2344801665', 'name': 'Chuanlei Guo'}, {'authorId': '2109745865', 'name': 'Wanqing Hu'}, {'authorId': '2110508005', 'name': 'Yanyan Li'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '7affa1ba1cd9bfc7f16b53f80370ce8da01f86d7', 'title': 'Pre-AI and post-AI design: balancing human Creativity and AI Tools in the Industrial\\xa0Design\\xa0Process', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708394.3708413?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708394.3708413, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2340368278', 'name': 'Xilin Tang'}, {'authorId': '50246958', 'name': 'Jerrod Windham'}, {'authorId': '2340310211', 'name': 'Benjamin Bush'}]}\n",
      "No publicationDate: {'paperId': '7affa1ba1cd9bfc7f16b53f80370ce8da01f86d7', 'title': 'Pre-AI and post-AI design: balancing human Creativity and AI Tools in the Industrial\\xa0Design\\xa0Process', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3708394.3708413?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3708394.3708413, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2340368278', 'name': 'Xilin Tang'}, {'authorId': '50246958', 'name': 'Jerrod Windham'}, {'authorId': '2340310211', 'name': 'Benjamin Bush'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'f88cac3943d09d157959e6f2c9039a1f9252ed24', 'title': 'A Research Through Design Study on AI Explanations for Collaborative Everyday Tasks for Older Adults Aging in Place', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3688828.3699640?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3688828.3699640, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1576648977', 'name': 'N. Mathur'}, {'authorId': '73769177', 'name': 'Tamara Zubatiy'}, {'authorId': '1752751', 'name': 'Elizabeth D. Mynatt'}]}\n",
      "No publicationDate: {'paperId': 'f88cac3943d09d157959e6f2c9039a1f9252ed24', 'title': 'A Research Through Design Study on AI Explanations for Collaborative Everyday Tasks for Older Adults Aging in Place', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3688828.3699640?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3688828.3699640, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1576648977', 'name': 'N. Mathur'}, {'authorId': '73769177', 'name': 'Tamara Zubatiy'}, {'authorId': '1752751', 'name': 'Elizabeth D. Mynatt'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'd9b181f75bdb088374c9b37ff41e35dc807f453f', 'title': 'Beyond Content: Leaning on the Poetics of Defamiliarization in Design Fictions', 'abstract': 'Literary approaches to design fictions, though previously theorized to be diverse in form and content, often fall within narrow stylistic and content boundaries such as speculative abstracts, memos, and studies. By drawing on a rich history of science fiction criticism, we advocate for literary design fictions that diverge from what is commonplace in HCI and design research. We foreground our paper with a discussion of the poetics of science fiction, and their relationship to current design fiction practices. Specifically, we highlight how the poetics of a design fiction can work to familiarize or defamiliarize readers from the imagined world presented. We thus argue that considerations of poetics, specifically how they work to (de)familiarize readers of design fictions, enrich understanding of design fictions as a research method. We then provide and discuss three design fictions in the forms of poetry and flash fiction, which fictionalize anthropomorphism in AI and AI explainability, AI assistants and AI privacy, and the relationship between AI and human autonomy. This paper makes two contributions: 1) a poetics-based framework that broadens current understandings of written design fictions and 2) three design fictions that speculate on the future of human-AI interaction.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701184?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701184, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2339961022', 'name': 'Richard Zhang'}, {'authorId': '2307669222', 'name': 'Duri Long'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '5a98479acd907cb48d16d16bd94b5811e848276a', 'title': 'Gender Stereotypes toward Non-gendered Generative AI: The Role of Gendered Expertise and Gendered Linguistic Cues', 'abstract': \"With rapid advancements in large language models (LLMs), generative AI (GenAI) is transforming people's life and work across various domains. Unlike previous AI technologies that are often feminized, most of these GenAI tools are non-gendered, potentially preventing users from applying gender stereotypes. However, GenAI's use of natural language can evoke social perceptions including gender attribution, making it susceptible to gender associations. Using two online experiments, we explored how GenAI's removal of gender could mitigate individuals' gender stereotypes toward it, and how certain linguistic cues could trigger gender stereotypes even if it is non-gendered. We found that the removal of AI's gender did mitigate gender stereotypes toward it, but only to an extent. Additionally, gendered linguistic cues such as politeness, apologies, and tentative language (or lack thereof) could trigger gender stereotypes toward non-gendered AI. We contribute to HCI and CSCW research by providing a timely investigation into individuals' gender stereotypes toward GenAI agents, and one of the first to examine the profound impact of language style on users' perceptions and attributions of social characteristics to GenAI. Our findings shed light on the purposeful and responsible design of GenAI that prioritizes promoting gender equality, thereby ensuring that technological advancements align with evolving social values.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701197?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701197, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2253660829', 'name': 'Wen Duan'}, {'authorId': '2260737462', 'name': 'Nathan J. McNeese'}, {'authorId': '2004044575', 'name': 'Lingyuan Li'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '83f9f3116db66467b60b675a3b89644443a927b7', 'title': 'Multimodal Mamba: A Versatile Multimodal Model for Seamless Integration into Diverse Downstream Tasks', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3704323.3704364?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3704323.3704364, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2339240186', 'name': 'Zongshu Li'}, {'authorId': '2894321', 'name': 'Guibo Zhu'}, {'authorId': '2339050076', 'name': 'Dongyi Yi'}, {'authorId': '2241943585', 'name': 'Jinqiao Wang'}]}\n",
      "No publicationDate: {'paperId': '83f9f3116db66467b60b675a3b89644443a927b7', 'title': 'Multimodal Mamba: A Versatile Multimodal Model for Seamless Integration into Diverse Downstream Tasks', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3704323.3704364?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3704323.3704364, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2339240186', 'name': 'Zongshu Li'}, {'authorId': '2894321', 'name': 'Guibo Zhu'}, {'authorId': '2339050076', 'name': 'Dongyi Yi'}, {'authorId': '2241943585', 'name': 'Jinqiao Wang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '2ed4dcdabf15f511466466368b3d49a484a7c181', 'title': 'Human-AI Interactions in Teacher Education: Examining Social Presence and Friendship', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702399?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702399, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2248739797', 'name': 'Hui-Wen Huang'}, {'authorId': '2338648303', 'name': 'Jessica (Chieh-Yu) Chang'}]}\n",
      "No publicationDate: {'paperId': '2ed4dcdabf15f511466466368b3d49a484a7c181', 'title': 'Human-AI Interactions in Teacher Education: Examining Social Presence and Friendship', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702399?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702399, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2248739797', 'name': 'Hui-Wen Huang'}, {'authorId': '2338648303', 'name': 'Jessica (Chieh-Yu) Chang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'ba4699310050afd354f9bc4bb58633fd831e1e34', 'title': 'Leveraging Multimodal GenAI Chatbots in EFL Learning: Learning Attitudes and User Experiences', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702406?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702406, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2248739797', 'name': 'Hui-Wen Huang'}, {'authorId': '2338667730', 'name': 'Xiyu Chen'}, {'authorId': '2338612331', 'name': 'Andrew Sankey'}]}\n",
      "No publicationDate: {'paperId': 'ba4699310050afd354f9bc4bb58633fd831e1e34', 'title': 'Leveraging Multimodal GenAI Chatbots in EFL Learning: Learning Attitudes and User Experiences', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702406?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702406, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2248739797', 'name': 'Hui-Wen Huang'}, {'authorId': '2338667730', 'name': 'Xiyu Chen'}, {'authorId': '2338612331', 'name': 'Andrew Sankey'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '453830406678fe3f72d7be4ebb91be7fa1a6747b', 'title': 'Can AI Be Environmentally Responsible? A Comparative Study on the Pro-Environmental Portrait of ChatGPT and Chinese Respondents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702394?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702394, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2261692294', 'name': 'Yu-Feng Qi'}, {'authorId': '2338647201', 'name': 'Fangxiang Fu'}, {'authorId': '2334200109', 'name': 'J. Tian'}, {'authorId': '2244778572', 'name': 'Yan Sun'}]}\n",
      "No publicationDate: {'paperId': '453830406678fe3f72d7be4ebb91be7fa1a6747b', 'title': 'Can AI Be Environmentally Responsible? A Comparative Study on the Pro-Environmental Portrait of ChatGPT and Chinese Respondents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702386.3702394?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702386.3702394, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2261692294', 'name': 'Yu-Feng Qi'}, {'authorId': '2338647201', 'name': 'Fangxiang Fu'}, {'authorId': '2334200109', 'name': 'J. Tian'}, {'authorId': '2244778572', 'name': 'Yan Sun'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'aec9d87a62eca46fc2ef7ba14817b885bf78640b', 'title': 'AI vs. Humans for Online Support: Comparing the Language of Responses from LLMs and Online Communities of Alzheimer’s Disease', 'abstract': 'AI chatbots are increasingly integrated into various sectors, including healthcare. We examine their role in responding to queries related to Alzheimer’s Disease and Related Dementias (AD/ADRD). We obtained real-world queries from AD/ADRD online communities (OC)—Reddit (r/Alzheimers) and ALZConnected. First, we conducted a small-scale qualitative examination where we prompted ChatGPT, Bard, and Llama-2 with 101 OC posts to generate responses and compared them with OC responses through inductive coding and thematic analysis. We found that although AI can provide emotional and informational support like OCs, they do not engage in deeper conversations, provide references, and share personal experiences. These insights motivated us to conduct a large-scale quantitative examination of comparing AI (GPT) and OC responses (90K) to 13.5K posts, in terms of psycholinguistics, lexico-semantics, and content. AI responses tend to be more verbose, readable, and complex. AI responses exhibited greater empathy, but more formal and analytical language, lacking personal narratives and linguistic diversity. We found that various LLMs, including GPT, Llama, and Mistral, exhibit consistent patterns in responding to AD/ADRD-related queries, underscoring the robustness of our insights across LLMs. Our study sheds light on the potential of AI in digital health and underscores design considerations of AI to complement human interactions.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3709366?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3709366, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2279735851', 'name': 'Koustuv Saha'}, {'authorId': '2239204576', 'name': 'Yoshee Jain'}, {'authorId': '2338712378', 'name': 'Chunyu Liu'}, {'authorId': '2330400760', 'name': 'Sidharth Kaliappan'}, {'authorId': '2256153603', 'name': 'Ravi Karkar'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '22f78cb450b8e5893146e6dc65b248c9feb8947a', 'title': 'Focus Agent: LLM-Powered Virtual Focus Group', 'abstract': \"In the domain of Human-Computer Interaction, focus groups represent a widely utilised yet resource-intensive methodology, often demanding the expertise of skilled moderators and meticulous preparatory efforts. This study introduces the ``Focus Agent,'' a Large Language Model (LLM) powered framework that simulates both the focus group (for data collection) and acts as a moderator in a focus group setting with human participants. To assess the data quality derived from the Focus Agent, we ran five focus group sessions with a total of 23 human participants as well as deploying the Focus Agent to simulate these discussions with AI participants. Quantitative analysis indicates that Focus Agent can generate opinions similar to those of human participants. Furthermore, the research exposes some improvements associated with LLMs acting as moderators in focus group discussions that include human participants.\", 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2409.01907', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.01907, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2319605783', 'name': 'Taiyu Zhang'}, {'authorId': '2107997398', 'name': 'Xuesong Zhang'}, {'authorId': '1380358277', 'name': 'Robbe Cools'}, {'authorId': '2238567324', 'name': 'Adalberto L. Simeone'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'ac0ad5572fd7f35f98ddd12377ede08dead672b1', 'title': 'Review of AI-Based Mental Health Apps', 'abstract': None, 'openAccessPdf': {'url': 'https://www.scienceopen.com/document_file/6f1661e3-8f36-4a6c-80b9-36c1fa5a933c/ScienceOpen/238_Alotaibi_BCSHCI23.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14236/ewic/bcshci2023.27?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14236/ewic/bcshci2023.27, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2304469906', 'name': 'Abeer Alotaibi'}, {'authorId': '2296014237', 'name': 'Corina Sas'}]}\n",
      "No publicationDate: {'paperId': 'ac0ad5572fd7f35f98ddd12377ede08dead672b1', 'title': 'Review of AI-Based Mental Health Apps', 'abstract': None, 'openAccessPdf': {'url': 'https://www.scienceopen.com/document_file/6f1661e3-8f36-4a6c-80b9-36c1fa5a933c/ScienceOpen/238_Alotaibi_BCSHCI23.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.14236/ewic/bcshci2023.27?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.14236/ewic/bcshci2023.27, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2304469906', 'name': 'Abeer Alotaibi'}, {'authorId': '2296014237', 'name': 'Corina Sas'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '13e82524fc1a1e5a3e9047a21e40bad6010e0eec', 'title': 'Understanding Trust and Reliance Development in AI Advice: Assessing Model Accuracy, Model Explanations, and Experiences from Previous Interactions', 'abstract': 'People are increasingly interacting with AI systems, but successful interactions depend on people trusting these systems only when appropriate. Since neither gaining trust in AI advice nor restoring lost trust after AI mistakes is warranted, we seek to better understand the development of trust and reliance in sequential human-AI interaction scenarios. In a 2x2 between-subject simulated AI experiment, we tested how model accuracy (high vs. low) and explanation type (human-like vs. abstract) affect trust and reliance on AI advice for repeated interactions. In the experiment, participants estimated jail times for 20 criminal law cases, first without and then with AI advice. Our results show that trust and reliance are significantly higher for high model accuracy. In addition, reliance does not decline over the trial sequence, and trust increases significantly with high accuracy. Human-like (vs. abstract) explanations only increased reliance on the high-accuracy condition. We furthermore tested the extent to which trust and reliance in a trial round can be explained by trust and reliance experiences from prior rounds. We find that trust assessments in prior trials correlate with trust in subsequent ones. We also find that the cumulative trust experience of a person in all earlier trial rounds correlates with trust in subsequent ones. Furthermore, we find that the two trust measures, trust and reliance, impact each other: prior trust beliefs not only influence subsequent trust beliefs but likewise influence subsequent reliance behavior, and vice versa. Executing a replication study yielded comparable results to our original study, thereby enhancing the validity of our findings.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3686164', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686164?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686164, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2211295964', 'name': 'Patricia K. Kahr'}, {'authorId': '50242929', 'name': 'G. Rooks'}, {'authorId': '1918235', 'name': 'M. Willemsen'}, {'authorId': '2291726203', 'name': 'Chris C. P. Snijders'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'fce2a89184dd5f87bd89dbd336d0dccde2ef7d99', 'title': 'Integration of User-Centered Design in the Development of Big Data and Machine Learning-Based Applications: A Systematic Mapping Study', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702038.3702097?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702038.3702097, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2131878906', 'name': 'N. Raulino'}, {'authorId': '2336748406', 'name': 'Rossana M. de Castro Andrade'}, {'authorId': '2747867', 'name': 'I. Santos'}]}\n",
      "No publicationDate: {'paperId': 'fce2a89184dd5f87bd89dbd336d0dccde2ef7d99', 'title': 'Integration of User-Centered Design in the Development of Big Data and Machine Learning-Based Applications: A Systematic Mapping Study', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3702038.3702097?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3702038.3702097, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2131878906', 'name': 'N. Raulino'}, {'authorId': '2336748406', 'name': 'Rossana M. de Castro Andrade'}, {'authorId': '2747867', 'name': 'I. Santos'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'f1dda7c340cbb0a585dca24437591bcd95961622', 'title': 'Reflexive Data Curation: Opportunities and Challenges for Embracing Uncertainty in Human-AI Collaboration', 'abstract': '\\n This article presents findings from a Research through Design investigation focusing on a reflexive approach to data curation and the use of generative AI in design and creative practices. Using binary gender categories manifested in children’s toys as a context, we examine three design experiments aimed at probing how designers can cultivate a\\n reflexive human-AI practice\\n to confront and challenge their internalized biases. Our goal is to underscore the intricate interplay between the designer, AI technology, and publicly held imaginaries and to offer an initial set of tactics for how personal biases and societal norms can be illuminated through interactions with AI. We conclude by proposing that designers not only bear the responsibility of grappling critically with the complexities of AI but also possess the opportunity to creatively harness the limitations of technology to craft a\\n reflexive data curation\\n that encourages profound reflections and awareness within design processes.\\n', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3689042', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3689042?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3689042, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2190659520', 'name': 'Anne Arzberger'}, {'authorId': '35037518', 'name': 'M. Lupetti'}, {'authorId': '2269605494', 'name': 'Elisa Giaccardi'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'c9f41322274b202ce004ca43e3eb9a3f0513931e', 'title': 'Carefully Unmaking the “Marginalized User:” A Diffractive Analysis of a Gay Online Community', 'abstract': 'HCI scholars are increasingly engaging in research about “marginalized groups,” such as LGBTQ+ people. While normative habitual readings of marginalized people in HCI often highlight real problems, this work has been criticized for flattening heterogeneous experiences and overemphasizing harms. Some have advocated for expanding how we approach research on marginalized people (e.g., assets-based design, the everyday, and joy). Sensitized by unmaking literature, we explore this tension between conditions, experiences, and representations of marginality in HCI scholarship. To do so, we perform a diffractive analysis of posts in a gay online community by bringing two readings of the same data together: a normative habitual reading of marginalization and an expanded reading. By examining the relationship between empirical material and its representations by HCI researchers, we explore how to carefully unmake HCI research, thus maintaining and repairing our research community. We discuss the political and designerly implications of different readings of marginalized people and offer considerations for attending to the processes and afterlives of HCI research.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3673229', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3673229?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3673229, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2219650178', 'name': 'Jordan Taylor'}, {'authorId': '2066620785', 'name': 'Wesley Hanwen Deng'}, {'authorId': '2257955034', 'name': 'Kenneth Holstein'}, {'authorId': '2163708272', 'name': 'Sarah E. Fox'}, {'authorId': '2257905527', 'name': 'Haiyi Zhu'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'e64f7937f561274b2efbcf42282181e974973819', 'title': 'The Choreographer-Performer Continuum: A Diffraction Tool to Illuminate Authorship in More Than Human Co-Performances', 'abstract': '\\n The design of robust and trustworthy Generative AI (GenAI) requires a deep understanding of the agencies emerging from human interactions with them. To contribute to this goal, we retrospectively studied an art project involving a visual artist, a computer scientist, an artistic director, and a generative model (GPT-2). The model was fine-tuned with trip reports describing the experience of eating psychedelic mushrooms. Building on agential realism, we analysed the co-performance between the artist and the model as their agency moved along the choreographer-performer continuum. Results reveal ontological surprises, leading to the proposal of\\n entangled authorship\\n to de-individualise the production of knowledge from a More Than Human perspective. The paper illustrates how art can expose different forms of relationships, challenging the idea of GenAI as just a tool that simplifies or replaces human labour. We conclude by emphasising the transformational potential of GenAI for novel modes of engagement between humans and machines.\\n', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3689040?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3689040, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2320009618', 'name': 'Federico Bomba'}, {'authorId': '2105419165', 'name': 'María Menéndez-Blanco'}, {'authorId': '2304277515', 'name': 'Paolo Grigis'}, {'authorId': '2296723229', 'name': 'Michele Cremaschi'}, {'authorId': '34919047', 'name': 'A. D. Angeli'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'f1d2b129f86ce9a092a7ad7c23cc79155a41a52f', 'title': 'GenAI and Prompt Engineering: A Progressive Framework for Empowering the Workforce', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3698322.3698348?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3698322.3698348, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2282990536', 'name': 'Adrian Schuckart'}]}\n",
      "No publicationDate: {'paperId': 'f1d2b129f86ce9a092a7ad7c23cc79155a41a52f', 'title': 'GenAI and Prompt Engineering: A Progressive Framework for Empowering the Workforce', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3698322.3698348?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3698322.3698348, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2282990536', 'name': 'Adrian Schuckart'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '24eee55cb67eab02061c1f1b316a49caefc0d100', 'title': \"Effect of LLM's Personality Traits on Query Generation\", 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3673791.3698433', 'status': 'HYBRID', 'license': 'public-domain', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3673791.3698433?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3673791.3698433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2334467150', 'name': 'Yuta Imasaka'}, {'authorId': '2334467905', 'name': 'Hideo Joho'}]}\n",
      "No publicationDate: {'paperId': '24eee55cb67eab02061c1f1b316a49caefc0d100', 'title': \"Effect of LLM's Personality Traits on Query Generation\", 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3673791.3698433', 'status': 'HYBRID', 'license': 'public-domain', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3673791.3698433?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3673791.3698433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2334467150', 'name': 'Yuta Imasaka'}, {'authorId': '2334467905', 'name': 'Hideo Joho'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'ad86d55d5dd608f46b0a643edb526860bce4ec36', 'title': 'AI-Powered Service Blueprints for Enhancing Human-Centred AI Design Processes', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701268.3701280?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701268.3701280, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2333793931', 'name': 'Mehrdad Atariani'}, {'authorId': '2333795906', 'name': 'Mohamad Saeid Hoseini'}]}\n",
      "No publicationDate: {'paperId': 'ad86d55d5dd608f46b0a643edb526860bce4ec36', 'title': 'AI-Powered Service Blueprints for Enhancing Human-Centred AI Design Processes', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701268.3701280?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701268.3701280, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2333793931', 'name': 'Mehrdad Atariani'}, {'authorId': '2333795906', 'name': 'Mohamad Saeid Hoseini'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'd6e2ba4fe3ba07bf3f3dc9af3d8259c767c3d794', 'title': 'Human-centered AI Technologies in Human-robot Interaction for Social Settings', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3701571.3701610', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701571.3701610?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701571.3701610, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2287737348', 'name': 'Yuchong Zhang'}, {'authorId': '2333609410', 'name': 'Khaled Kassem'}, {'authorId': '2334693129', 'name': 'Zhengya Gong'}, {'authorId': '2333601766', 'name': 'Fan Mo'}, {'authorId': '2333743103', 'name': 'Yong Ma'}, {'authorId': '118873121', 'name': 'E. Kirjavainen'}, {'authorId': '2265111029', 'name': 'Jonna Häkkilä'}]}\n",
      "No publicationDate: {'paperId': 'd6e2ba4fe3ba07bf3f3dc9af3d8259c767c3d794', 'title': 'Human-centered AI Technologies in Human-robot Interaction for Social Settings', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3701571.3701610', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3701571.3701610?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3701571.3701610, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2287737348', 'name': 'Yuchong Zhang'}, {'authorId': '2333609410', 'name': 'Khaled Kassem'}, {'authorId': '2334693129', 'name': 'Zhengya Gong'}, {'authorId': '2333601766', 'name': 'Fan Mo'}, {'authorId': '2333743103', 'name': 'Yong Ma'}, {'authorId': '118873121', 'name': 'E. Kirjavainen'}, {'authorId': '2265111029', 'name': 'Jonna Häkkilä'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '95c2415957c5a16879d20f1f3738c799d358d963', 'title': 'Can You Tell Real from Fake Face Images? Perception of Computer-Generated Faces by Humans', 'abstract': 'With recent advances in machine learning and big data, it is now possible to create synthetic images that look real. Face generation is often of particular interest, as faces can be used for various purposes. However, improper use of such content can lead to the dissemination of false information, such as fake news, and thus pose a threat to society. This work studies whether people believe the truthfulness of faces using eye tracking and self-reports, including free-form textual explanations when participants encounter real and computer-generated faces. We used three different datasets for our evaluations, and our experimental results show that while people are relatively better at identifying the truthfulness of real faces and faces generated by earlier machine learning algorithms with different gazing behaviors in viewing and rating phases, they perform less accurately when deciding the truthfulness of synthetic face images that are generated by newer algorithms. Our findings provide important insights for society and policymakers.', 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3696667?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3696667, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '123779446', 'name': 'Efe Bozkir'}, {'authorId': '2221119985', 'name': 'Clara Riedmiller'}, {'authorId': '2315027021', 'name': 'Athanassios Skodras'}, {'authorId': '1686448', 'name': 'Gjergji Kasneci'}, {'authorId': '1884159', 'name': 'Enkelejda Kasneci'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'f8aa87466ef9227adc32dbf5aedb4e3b5414cf15', 'title': 'Crafting Human-AI Interaction: A Rhetorical Approach to Adaptive Interaction in Conversational Agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3688297?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3688297, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2280742122', 'name': 'Rutuja Joshi'}, {'authorId': '2244312232', 'name': 'Klaus Bengler'}]}\n",
      "No publicationDate: {'paperId': 'f8aa87466ef9227adc32dbf5aedb4e3b5414cf15', 'title': 'Crafting Human-AI Interaction: A Rhetorical Approach to Adaptive Interaction in Conversational Agents', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3688297?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3688297, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2280742122', 'name': 'Rutuja Joshi'}, {'authorId': '2244312232', 'name': 'Klaus Bengler'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '2a71dc5b28a8addf3d34a850a6f96e6f311813b3', 'title': 'Algorithmic Authority & AI Influence in Decision Settings: Theories and Implications for Design', 'abstract': None, 'openAccessPdf': {'url': 'https://orca.cardiff.ac.uk/id/eprint/172095/1/2024_HAI_Workshop.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3691363?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3691363, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295670746', 'name': 'Alessandro Facchini'}, {'authorId': '2326950425', 'name': 'Caterina Fregosi'}, {'authorId': '2059240949', 'name': 'Chiara Natali'}, {'authorId': '2052098721', 'name': 'Alberto Termine'}, {'authorId': '2331736004', 'name': 'Ben Wilson'}]}\n",
      "No publicationDate: {'paperId': '2a71dc5b28a8addf3d34a850a6f96e6f311813b3', 'title': 'Algorithmic Authority & AI Influence in Decision Settings: Theories and Implications for Design', 'abstract': None, 'openAccessPdf': {'url': 'https://orca.cardiff.ac.uk/id/eprint/172095/1/2024_HAI_Workshop.pdf', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3691363?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3691363, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295670746', 'name': 'Alessandro Facchini'}, {'authorId': '2326950425', 'name': 'Caterina Fregosi'}, {'authorId': '2059240949', 'name': 'Chiara Natali'}, {'authorId': '2052098721', 'name': 'Alberto Termine'}, {'authorId': '2331736004', 'name': 'Ben Wilson'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '23fe409d9f21f2c53b1da0247ce493d944bbe876', 'title': 'TheoriseHAI: Shaping Human-Agent Interactions Through Interdisciplinary Theories', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3691358?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3691358, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '82791880', 'name': 'Maitreyee Tewari'}, {'authorId': '11708658', 'name': 'Michele Persiani'}, {'authorId': '2331835180', 'name': 'Roland Chen'}, {'authorId': '2331759870', 'name': 'Linda Li'}]}\n",
      "No publicationDate: {'paperId': '23fe409d9f21f2c53b1da0247ce493d944bbe876', 'title': 'TheoriseHAI: Shaping Human-Agent Interactions Through Interdisciplinary Theories', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3691358?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3691358, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '82791880', 'name': 'Maitreyee Tewari'}, {'authorId': '11708658', 'name': 'Michele Persiani'}, {'authorId': '2331835180', 'name': 'Roland Chen'}, {'authorId': '2331759870', 'name': 'Linda Li'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '0e15f92f8ac2de9a5cfd8427f3ad069b32ec876a', 'title': \"Designing Bias Suppressing Robots for 'fair' Robot moderated Human-Human Interactions\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3690877?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3690877, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2306952414', 'name': 'Peter Daish'}, {'authorId': '2271611527', 'name': 'Takayuki Kanda'}, {'authorId': '2331734456', 'name': 'Matt Roach'}, {'authorId': '2331763946', 'name': 'Muneeb Ahmad'}]}\n",
      "No publicationDate: {'paperId': '0e15f92f8ac2de9a5cfd8427f3ad069b32ec876a', 'title': \"Designing Bias Suppressing Robots for 'fair' Robot moderated Human-Human Interactions\", 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687272.3690877?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687272.3690877, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2306952414', 'name': 'Peter Daish'}, {'authorId': '2271611527', 'name': 'Takayuki Kanda'}, {'authorId': '2331734456', 'name': 'Matt Roach'}, {'authorId': '2331763946', 'name': 'Muneeb Ahmad'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3810095311bcdba002e018e3e177f5e01ff4dbd1', 'title': 'PrISM-Q&A: Step-Aware Voice Assistant on a Smartwatch Enabled by Multimodal Procedure Tracking and Large Language Models', 'abstract': 'Voice assistants capable of answering user queries during various physical tasks have shown promise in guiding users through complex procedures. However, users often find it challenging to articulate their queries precisely, especially when unfamiliar with the specific terminologies required for machine-oriented tasks. We introduce PrISM-Q&A, a novel question-answering (Q&A) interaction termed step-aware Q&A, which enhances the functionality of voice assistants on smartwatches by incorporating Human Activity Recognition (HAR) and providing the system with user context. It continuously monitors user behavior during procedural tasks via audio and motion sensors on the watch and estimates which step the user is performing. When a question is posed, this contextual information is supplied to Large Language Models (LLMs) as part of the context used to generate a response, even in the case of inherently vague questions like \"What should I do next with this?\" Our studies confirmed that users preferred the convenience of our approach compared to existing voice assistants. Our real-time assistant represents the first Q&A system that provides contextually situated support during tasks without camera use, paving the way for the ubiquitous, intelligent assistant.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3699759', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3699759?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3699759, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2292515576', 'name': 'Riku Arakawa'}, {'authorId': '2247591807', 'name': 'J. Lehman'}, {'authorId': '2247946468', 'name': 'Mayank Goel'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3c503a33c44cbca228afb7ea227f81c32b8e0a77', 'title': 'Beyond Detection: Towards Actionable Sensing Research in Clinical Mental Healthcare', 'abstract': 'Researchers in ubiquitous computing have long promised that passive sensing will revolutionize mental health measurement by detecting individuals in a population experiencing a mental health disorder or specific symptoms. Recent work suggests that detection tools do not generalize well when trained and tested in more heterogeneous samples. In this work, we contribute a narrative review and findings from two studies with 41 mental health clinicians to understand these generalization challenges. Our findings motivate research on actionable sensing, as an alternative to detection research, studying how passive sensing can augment traditional mental health measures to support actions in clinical care. Specifically, we identify how passive sensing can support clinical actions by revealing patients’ presenting problems for treatment and identifying targets for behavior change and symptom reduction, but passive data requires additional contextual information to be appropriately interpreted and used in care. We conclude by suggesting research at the intersection of actionable sensing and mental healthcare, to align technical research in ubiquitous computing with clinical actions and needs.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3699755', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11620792, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '49131148', 'name': 'Daniel A. Adler'}, {'authorId': '2262402474', 'name': 'Yuewen Yang'}, {'authorId': '2301080304', 'name': 'Thalia Viranda'}, {'authorId': '2282074201', 'name': 'Xuhai Xu'}, {'authorId': '2239691154', 'name': 'David C. Mohr'}, {'authorId': '2297173342', 'name': 'Anna R. Van Meter'}, {'authorId': '2326886640', 'name': 'Julia C. Tartaglia'}, {'authorId': '39972662', 'name': 'N. Jacobson'}, {'authorId': '2215418043', 'name': 'Fei Wang'}, {'authorId': '2056114627', 'name': 'Deborah Estrin'}, {'authorId': '2193586420', 'name': 'Tanzeem Choudhury'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'fb5a32dbf2411dcc82186e6e07206e6498da552a', 'title': 'See-Through Face Display: Enabling Gaze Communication for Any Face - Human or AI', 'abstract': \"We present See-Through Face Display, an eye-contact display system designed to enhance gaze awareness in both human-to-human and human-to-avatar communication. The system addresses the limitations of existing gaze correction methods by combining a transparent display with a strategically positioned camera. The display alternates rapidly between a visible and transparent state, thereby enabling the camera to capture clear images of the user's face from behind the display. This configuration allows for mutual gaze awareness among remote participants without the necessity of a large form factor or computationally resource-intensive image processing. In comparison to conventional methodologies, See-Through Face Display offers a number of practical advantages. The system requires minimal physical space, operates with low computational overhead, and avoids the visual artifacts typically associated with software-based gaze redirection. These features render the system suitable for a variety of applications, including multi-party teleconferencing and remote customer service. Furthermore, the alignment of the camera's field of view with the displayed face position facilitates more natural gaze-based interactions with AI avatars. This paper presents the implementation of See-Through Face Display and examines its potential applications, demonstrating how this compact eye-contact system can enhance gaze communication in both human-to-human and human-AI interactions.\", 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3681758.3698020', 'status': 'HYBRID', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.05833, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2171723572', 'name': 'Kazuya Izumi'}, {'authorId': '2174751929', 'name': 'Ryosuke Hyakuta'}, {'authorId': '3428384', 'name': 'Ippei Suzuki'}, {'authorId': '2327044513', 'name': 'Yoichi Ochiai'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '0072959e028aadf81e55353d3be7bd4f95e447e4', 'title': 'A Systematic Review on Fostering Appropriate Trust in Human-AI Interaction: Trends, Opportunities and Challenges', 'abstract': 'Appropriate Trust in Artificial Intelligence (AI) systems has rapidly become an important area of focus for both researchers and practitioners. Various approaches have been used to achieve it, such as confidence scores, explanations, trustworthiness cues, or uncertainty communication. However, a comprehensive understanding of the field is lacking due to the diversity of perspectives arising from various backgrounds that influence it and the lack of a single definition for appropriate trust. To investigate this topic, this paper presents a systematic review to identify current practices in building appropriate trust, different ways to measure it, types of tasks used, and potential challenges associated with it. We also propose a Belief, Intentions, and Actions (BIA) mapping to study commonalities and differences in the concepts related to appropriate trust by (a) describing the existing disagreements on defining appropriate trust, and (b) providing an overview of the concepts and definitions related to appropriate trust in AI from the existing literature. Finally, the challenges identified in studying appropriate trust are discussed, and observations are summarized as current trends, potential gaps, and research opportunities for future work. Overall, the paper provides insights into the complex concept of appropriate trust in human-AI interaction and presents research opportunities to advance our understanding on this topic.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3696449?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3696449, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2987512', 'name': 'Siddharth Mehrotra'}, {'authorId': '2214770525', 'name': 'Chadha Degachi'}, {'authorId': '2120825494', 'name': 'Oleksandra Vereschak'}, {'authorId': '1689001', 'name': 'C. Jonker'}, {'authorId': '3252848', 'name': 'M. Tielman'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '1ff243f3326e8a0474a1bce03322480ecb6b3684', 'title': 'Exploring How Users Attribute Responsibilities Across Different Stakeholders in Human-AI Interaction', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681852', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681852?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2312411766', 'name': 'Yu-Ting Chen'}, {'authorId': '2312475776', 'name': 'Hsin-yi Sandy Tsai'}, {'authorId': '2331315716', 'name': 'Tina Chien-Wen Yuan'}]}\n",
      "No publicationDate: {'paperId': '1ff243f3326e8a0474a1bce03322480ecb6b3684', 'title': 'Exploring How Users Attribute Responsibilities Across Different Stakeholders in Human-AI Interaction', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681852', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681852?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2312411766', 'name': 'Yu-Ting Chen'}, {'authorId': '2312475776', 'name': 'Hsin-yi Sandy Tsai'}, {'authorId': '2331315716', 'name': 'Tina Chien-Wen Yuan'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '996be97576fa73be20763bb80610b517d84d0319', 'title': 'Uncovering Contradictions in Human-AI Interactions: Lessons Learned from User Reviews of Replika', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681909', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681909?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681909, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295729530', 'name': 'M. Namvarpour'}, {'authorId': '47351197', 'name': 'Afsaneh Razi'}]}\n",
      "No publicationDate: {'paperId': '996be97576fa73be20763bb80610b517d84d0319', 'title': 'Uncovering Contradictions in Human-AI Interactions: Lessons Learned from User Reviews of Replika', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681909', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681909?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681909, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295729530', 'name': 'M. Namvarpour'}, {'authorId': '47351197', 'name': 'Afsaneh Razi'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '9228d7545053261993024a70f610ced57330c28b', 'title': 'Opportunities and Challenges of Emerging Human-AI Interactions to Support Healthcare in the Global South', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681834', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681834?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681834, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '144027898', 'name': 'Carolina Fuentes'}, {'authorId': '2722396', 'name': 'Iyubanit Rodríguez'}, {'authorId': '47204934', 'name': 'Gabriela Cajamarca'}, {'authorId': '1403933980', 'name': 'Laura Cabrera-Quiros'}, {'authorId': '2308852069', 'name': 'Andrés Lucero'}, {'authorId': '2240541974', 'name': 'Valeria Herskovic'}, {'authorId': '2058908494', 'name': \"Kenton O'hara\"}]}\n",
      "No publicationDate: {'paperId': '9228d7545053261993024a70f610ced57330c28b', 'title': 'Opportunities and Challenges of Emerging Human-AI Interactions to Support Healthcare in the Global South', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681834', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681834?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681834, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '144027898', 'name': 'Carolina Fuentes'}, {'authorId': '2722396', 'name': 'Iyubanit Rodríguez'}, {'authorId': '47204934', 'name': 'Gabriela Cajamarca'}, {'authorId': '1403933980', 'name': 'Laura Cabrera-Quiros'}, {'authorId': '2308852069', 'name': 'Andrés Lucero'}, {'authorId': '2240541974', 'name': 'Valeria Herskovic'}, {'authorId': '2058908494', 'name': \"Kenton O'hara\"}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '0c57890908b83308858097d81cc2afb1820d1532', 'title': '\"What is Safety?\": Building Bridges Across Approaches to Digital Risks and Harms', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681824', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681824?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681824, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2244445242', 'name': 'A. Walker'}, {'authorId': '32861190', 'name': 'M. A. Devito'}, {'authorId': '1402258829', 'name': 'Karla A. Badillo-Urquiola'}, {'authorId': '2237799784', 'name': 'Rosanna Bellini'}, {'authorId': '2510840', 'name': 'Stevie Chancellor'}, {'authorId': '2146189', 'name': 'Jessica L. Feuston'}, {'authorId': '2261593676', 'name': 'Kathryn Henne'}, {'authorId': '2256999087', 'name': 'Patrick Gage Kelley'}, {'authorId': '7389108', 'name': 'Shalaleh Rismani'}, {'authorId': '2256999906', 'name': 'Renee Shelby'}, {'authorId': '2257859674', 'name': 'Renwen Zhang'}]}\n",
      "No publicationDate: {'paperId': '0c57890908b83308858097d81cc2afb1820d1532', 'title': '\"What is Safety?\": Building Bridges Across Approaches to Digital Risks and Harms', 'abstract': None, 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681824', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678884.3681824?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678884.3681824, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2244445242', 'name': 'A. Walker'}, {'authorId': '32861190', 'name': 'M. A. Devito'}, {'authorId': '1402258829', 'name': 'Karla A. Badillo-Urquiola'}, {'authorId': '2237799784', 'name': 'Rosanna Bellini'}, {'authorId': '2510840', 'name': 'Stevie Chancellor'}, {'authorId': '2146189', 'name': 'Jessica L. Feuston'}, {'authorId': '2261593676', 'name': 'Kathryn Henne'}, {'authorId': '2256999087', 'name': 'Patrick Gage Kelley'}, {'authorId': '7389108', 'name': 'Shalaleh Rismani'}, {'authorId': '2256999906', 'name': 'Renee Shelby'}, {'authorId': '2257859674', 'name': 'Renwen Zhang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '0319559ca6204986a6cfddc100d3f436bf919a9a', 'title': 'Bridging Dictionary: AI-Generated Dictionary of Partisan Language Use', 'abstract': \"Words often carry different meanings for people from diverse backgrounds. Today's era of social polarization demands that we choose words carefully to prevent miscommunication, especially in political communication and journalism. To address this issue, we introduce the Bridging Dictionary, an interactive tool designed to illuminate how words are perceived by people with different political views. The Bridging Dictionary includes a static, printable document featuring 796 terms with summaries generated by a large language model. These summaries highlight how the terms are used distinctively by Republicans and Democrats. Additionally, the Bridging Dictionary offers an interactive interface that lets users explore selected words, visualizing their frequency, sentiment, summaries, and examples across political divides. We present a use case for journalists and emphasize the importance of human agency and trust in further enhancing this tool. The deployed version of Bridging Dictionary is available at https://dictionary.ccc-mit.org/.\", 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2407.09661', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.09661, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2311550050', 'name': 'Hang Jiang'}, {'authorId': '49222693', 'name': 'D. Beeferman'}, {'authorId': '122580886', 'name': 'William Brannon'}, {'authorId': '2311443982', 'name': 'Andrew Heyward'}, {'authorId': '2261551123', 'name': 'Deb Roy'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '8a61fd78ccb5ecbfdaa2d63b2c6af470ff91fc97', 'title': 'Envisioning New Futures of Positive Social Technology: Beyond Paradigms of Fixing, Protecting, and Preventing', 'abstract': 'Social technology research today largely focuses on mitigating the negative impacts of technology and, therefore, often misses the potential of technology to enhance human connections and well-being. However, we see a potential to shift towards a holistic view of social technology\\'s impact on human flourishing. We introduce Positive Social Technology (Positech), a framework that shifts emphasis toward leveraging social technologies to support and augment human flourishing. This workshop is organized around three themes relevant to Positech: 1)\"Exploring Relevant and Adjacent Research\"to define and widen the Positech scope with insights from related fields, 2)\"Projecting the Landscape of Positech\"for participants to outline the domain\\'s key aspects and 3)\"Envisioning the Future of Positech,\"anchored around strategic planning towards a sustainable research community. Ultimately, this workshop will serve as a platform to shift the narrative of social technology research towards a more positive, human-centric approach. It will foster research that goes beyond fixing technologies to protect humans from harm, to also pursue enriching human experiences and connections through technology.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3681833', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.17579, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2306469181', 'name': 'Jaewon Kim'}, {'authorId': '2312926245', 'name': 'Lindsay Popowski'}, {'authorId': '2312924055', 'name': 'Anna Fang'}, {'authorId': '2089553973', 'name': 'Cassidy Pyle'}, {'authorId': '2286688341', 'name': 'Guo Freeman'}, {'authorId': '2312926571', 'name': 'Ryan M. Kelly'}, {'authorId': '2313048155', 'name': 'Angela Y. Lee'}, {'authorId': '2312916275', 'name': 'Fannie Liu'}, {'authorId': '2313312885', 'name': 'Angela D. R. Smith'}, {'authorId': '2312924326', 'name': 'Alexandra To'}, {'authorId': '2313271739', 'name': 'Amy X. Zhang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'caea21c029d6976f48cce1af935543f19f749beb', 'title': 'The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing', 'abstract': 'Rapid progress in general-purpose AI has sparked significant interest in\"red teaming,\"a practice of adversarial testing originating in military and cybersecurity applications. AI red teaming raises many questions about the human factor, such as how red teamers are selected, biases and blindspots in how tests are conducted, and harmful content\\'s psychological effects on red teamers. A growing body of HCI and CSCW literature examines related practices-including data labeling, content moderation, and algorithmic auditing. However, few, if any have investigated red teaming itself. Future studies may explore topics ranging from fairness to mental health and other areas of potential harm. We aim to facilitate a community of researchers and practitioners who can begin to meet these challenges with creativity, innovation, and thoughtful reflection.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3678884.3687147', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.07786, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2258311126', 'name': 'Alice Qian Zhang'}, {'authorId': '2310609216', 'name': 'Ryland Shaw'}, {'authorId': '2004948990', 'name': 'Jacy Reese Anthis'}, {'authorId': '2310606737', 'name': 'Ashlee Milton'}, {'authorId': '97560872', 'name': 'Emily Tseng'}, {'authorId': '2310609174', 'name': 'Jina Suh'}, {'authorId': '2310608734', 'name': 'Lama Ahmad'}, {'authorId': '2310657477', 'name': 'Ram Shankar Siva Kumar'}, {'authorId': '2310608706', 'name': 'Julian Posada'}, {'authorId': '2310610561', 'name': 'B. Shestakofsky'}, {'authorId': '2310610450', 'name': 'Sarah T. Roberts'}, {'authorId': '2310608798', 'name': 'Mary L. Gray'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '67a5d89c0ef4aed9c643c728a6d6ef74d234ecbc', 'title': 'Effect of Explanation Conceptualisations on Trust in AI-assisted Credibility Assessment', 'abstract': \"As misinformation increasingly proliferates on social media platforms, it has become crucial to explore how to best convey automated news credibility assessments to end-users, and foster trust in fact-checking AIs. In this paper, we investigate how model-agnostic, natural language explanations influence trust and reliance on a fact-checking AI. We construct explanations from four Conceptualisation Validations (CVs) - namely consensual, expert, internal (logical), and empirical - which are foundational units of evidence that humans utilise to validate and accept new information. Our results show that providing explanations significantly enhances trust in AI, even in a fact-checking context where influencing pre-existing beliefs is often challenging, with different CVs causing varying degrees of reliance. We find consensual explanations to be the least influential, with expert, internal, and empirical explanations exerting twice as much influence. However, we also find that users could not discern whether the AI directed them towards the truth, highlighting the dual nature of explanations to both guide and potentially mislead. Further, we uncover the presence of automation bias and aversion during collaborative fact-checking, indicating how users' previously established trust in AI can moderate their reliance on AI judgements. We also observe the manifestation of a 'boomerang'/backfire effect often seen in traditional corrections to misinformation, with individuals who perceive AI as biased or untrustworthy doubling down and reinforcing their existing (in)correct beliefs when challenged by the AI. We conclude by presenting nuanced insights into the dynamics of user behaviour during AI-based fact-checking, offering important lessons for social media platforms.\", 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3686922', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686922?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686922, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '101637895', 'name': 'Saumya Pareek'}, {'authorId': '2275620', 'name': 'N. V. Berkel'}, {'authorId': '2277226132', 'name': 'Eduardo Velloso'}, {'authorId': '2303693048', 'name': 'Jorge Goncalves'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'e1322c1517ac5e3f9da2956dfc988ee8f32ed34e', 'title': \"Beyond Recommendations: From Backward to Forward AI Support of Pilots' Decision-Making Process\", 'abstract': \"AI is anticipated to enhance human decision-making in high-stakes domains like aviation, but adoption is often hindered by challenges such as inappropriate reliance and poor alignment with users' decision-making. Recent research suggests that a core underlying issue is the recommendation-centric design of many AI systems, i.e., they give end-to-end recommendations and ignore the rest of the decision-making process. Alternative support paradigms are rare, and it remains unclear how the few that do exist compare to recommendation-centric support. In this work, we aimed to empirically compare recommendation-centric support to an alternative paradigm, continuous support, in the context of diversions in aviation. We conducted a mixed-methods study with 32 professional pilots in a realistic setting. To ensure the quality of our study scenarios, we conducted a focus group with four additional pilots prior to the study. We found that continuous support can support pilots' decision-making in a forward direction, allowing them to think more beyond the limits of the system and make faster decisions when combined with recommendations, though the forward support can be disrupted. Participants' statements further suggest a shift in design goal away from providing recommendations, to supporting quick information gathering. Our results show ways to design more helpful and effective AI decision support that goes beyond end-to-end recommendations.\", 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3687024', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2406.08959, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2155280330', 'name': 'Zelun Tony Zhang'}, {'authorId': '2273467366', 'name': 'Sebastian S. Feger'}, {'authorId': '2306262674', 'name': 'Lucas Dullenkopf'}, {'authorId': '2319072411', 'name': 'Rulu Liao'}, {'authorId': '2310452464', 'name': 'Lukas Süsslin'}, {'authorId': '2307211348', 'name': 'Yuanting Liu'}, {'authorId': '2287066400', 'name': 'Andreas Butz'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'fa4ff7a16361b2357b31f58e14d4d10fa4dce353', 'title': 'Dittos: Personalized, Embodied Agents That Participate in Meetings When You Are Unavailable', 'abstract': \"\\n Imagine being able to send a personalized embodied agent to meetings you are unable to attend. This paper explores the idea of a\\n Ditto\\n an agent that visually resembles a person, sounds like them, possesses knowledge about them, and can represent them in meetings. This paper reports on results from two empirical investigations: 1) focus group sessions with six groups (n=24) and 2) a Wizard of Oz (WOz) study with 10 groups (n=39) recruited from within a large technology company. Results from the focus group sessions provide insights on what contexts are appropriate for Dittos, and issues around social acceptability and representation risk. The focus group results also provide feedback on visual design characteristics for Dittos. In the WOz study, teams participated in meetings with two different embodied agents: a Ditto and a Delegate (an agent which did not resemble the absent person). Insights from this research demonstrate the impact these embodied agents can have in meetings and highlight that Dittos in particular show promise in evoking feelings of presence and trust, as well as informing decision making. These results also highlight issues related to relationship dynamics such as maintaining social etiquette, managing one's professional reputation, and upholding accountability. Overall, our investigation provides early evidence that Dittos could be beneficial to represent users when they are unable to be present but also outlines many factors that need to be carefully considered to successfully realize this vision.\\n\", 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3687033', 'status': 'HYBRID', 'license': 'CCBYNC', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687033?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687033, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2329108167', 'name': 'Joanne Leong'}, {'authorId': '2243386811', 'name': 'John Tang'}, {'authorId': '1722375', 'name': 'Edward Cutrell'}, {'authorId': '2999736', 'name': 'Sasa Junuzovic'}, {'authorId': '2329108671', 'name': 'Gregory Paul Baribault'}, {'authorId': '1781500', 'name': 'K. Quinn'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '54c502752b0b9d3c6eb2f1306aa30ef9aaf8bb67', 'title': 'Advice from a Doctor or AI? Understanding Willingness to Disclose Information Through Remote Patient Monitoring to Receive Health Advice', 'abstract': \"Remote Patient Monitoring (RPM) devices transmit patients' medical indicators (e.g., blood pressure) from the patient's home testing equipment to their healthcare providers, in order to monitor chronic conditions such as hypertension. AI systems have the potential to enhance access to timely medical advice based on the data that RPM devices produce. In this paper, we report on three studies investigating how the severity of users' medical condition (normal vs. high blood pressure), security risk (low vs. modest vs. high risk), and medical advice source (human doctor vs. AI) influence user perceptions of advisor trustworthiness and willingness to disclose RPM-acquired information. We found that trust mediated the relationship between the advice source and users' willingness to disclose health information: users trust doctors more than AI and are more willing to disclose their RPM-acquired health information to a more trusted advice source. However, we unexpectedly discovered that conditional on trust, users disclose RPM-acquired information more readily to AI than to doctors. We observed that the advice source did not influence perceptions of security and privacy risks. We conclude by discussing how our findings can support the design of RPM applications.\", 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3686925', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686925?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686925, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2330009974', 'name': 'Tamir Mendel'}, {'authorId': '71575036', 'name': 'O. Nov'}, {'authorId': '32012757', 'name': 'B. Wiesenfeld'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '55a1465cfbfdeaac95a39e3b5fe885a48f075150', 'title': 'Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML', 'abstract': 'UX designers and researchers who work with AI/ML face different kinds of challenges throughout the design process. Though close collaborations with AI/ML developers and data scientists could address some of these challenges, such interdisciplinary collaborations are non-routine and hard to realize. In this work, we investigate barriers for effective collaboration with ML practitioners, how they affect UX practice of AI/ML applications, and what UX practitioners need to overcome these challenges. We conducted a qualitative study with 14 UX practitioners who are working on AI/ML products as designers or researchers. Our findings show that UX practitioners face challenges in communication, understanding the model and model development processes, establishing ways to collaborate, and reconciling model-centric metrics of evaluation with user-centric outcomes. They described various needs in terms of more visibility into model development processes, access to comprehensible and contextual model information, and hypothetical tools that can potentially support collaboration with ML practitioners and enhance UX design processes. We discuss implications of this research for designing collaborative tools and empowering UX practitioners.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3686986', 'status': 'HYBRID', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686986?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686986, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '51909690', 'name': 'Meena Devii Muralikumar'}, {'authorId': '2253436419', 'name': 'David W. McDonald'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'ad5e37b23785222c22acdd034c8ceee9121d5d24', 'title': 'Transhuman Communication: Human Augmentation Technologies through Co-Speculation Workshops', 'abstract': 'The advancement of human-computer integration as a research field promises to introduce transhumanistic ways of communicating through the enhanced abilities of augmented humans. Our work seeks to illuminate this experiential landscape, exploring a diverse set of human augmentation technologies (HATs) for communication purposes. We investigated this topic through four co-speculation workshops focusing on physical, cognitive, sensory and emotional augmentations with 35 participants. Through a reflexive thematic analysis of the workshop data, we outlined eight HAT speculations for transhuman communication, grouped into four overarching augmentation clusters: (1) Bodily Changes in/for Communication, (2) Communication with Transferrable and Collective Beings, (3) Communication through Emotion and Memory, and (4) Communication with Augmented/Altered Perception. By serving as a foundation for discussions on transhumanism and communication in CSCW and beyond, these speculations contribute to a design space highlighting design opportunities and challenges to developing and researching near-future communication technologies.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3686892', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686892?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686892, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2221317770', 'name': 'Çağlar Genç'}, {'authorId': '1419344037', 'name': 'Velvet Spors'}, {'authorId': '2214745676', 'name': 'O. Buruk'}, {'authorId': '51457289', 'name': 'Mattia Thibault'}, {'authorId': '2264930428', 'name': 'Leland Masek'}, {'authorId': '2326163864', 'name': 'J. Hamari'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '636c63224e701ee45ebd47ac31a78c5d771c010a', 'title': \"Exploring Parent's Needs for Children-Centered AI to Support Preschoolers' Interactive Storytelling and Reading Activities\", 'abstract': \"Interactive storytelling is vital for preschooler development. While children's interactive partners have traditionally been their parents and teachers, recent advances in artificial intelligence (AI) have sparked a surge of AI-based storytelling and reading technologies. As these technologies become increasingly ubiquitous in preschoolers' lives, questions arise regarding how they function in practical storytelling and reading scenarios and, how parents, the most critical stakeholders, experience and perceive these technologies. This paper investigates these questions through a qualitative study with 17 parents of children aged 3-6. Our findings suggest that even though AI-based storytelling and reading technologies provide more immersive and engaging interaction, they still cannot meet parents' expectations due to a series of interactive and algorithmic challenges. We elaborate on these challenges and discuss the possible implications of future AI-based interactive storytelling technologies for preschoolers.\", 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3687035', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2401.13804, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2267020476', 'name': 'Yuling Sun'}, {'authorId': '2266879383', 'name': 'Jiaju Chen'}, {'authorId': '1490485182', 'name': 'Bingsheng Yao'}, {'authorId': '2281070131', 'name': 'Jiali Liu'}, {'authorId': '2243367965', 'name': 'Dakuo Wang'}, {'authorId': '2281339216', 'name': 'Xiaojuan Ma'}, {'authorId': '2155710822', 'name': 'Yuxuan Lu'}, {'authorId': '2267034988', 'name': 'Ying Xu'}, {'authorId': '2281050273', 'name': 'Liang He'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'd511ef18860a00976336698804f83363c475139f', 'title': 'Understanding and Influencing Responsibility Attribution when Experiencing Technical Issues in Video Conferencing', 'abstract': 'During video conferencing, technical issues such as network impairments can unexpectedly hinder remote collaboration for distributed teams. However, it remains unclear how such issues affect the impression formation process between unacquainted interlocutors in situations like job interviews or kick-off meetings. Having first encounters online without prior in-person interaction has become prevalent nowadays. Therefore, examining the impact of technical issues on remote unacquainted interlocutors and exploring design solutions to reduce the negative impact of technical issues on the impression is essential in informing the design of future communication systems. With three controlled experiments simulating an online job interview, we discovered that technical issues made people give low credibility ratings to remote job applicants (Study 1). We further examined two intervention approaches to reduce the negative impact of technical issues in video conferencing, including a virtual agent represented in a human-like avatar to actively take responsibility for the technical issues (Study 2), and forewarning messages to inform people about the technical issues in video conferencing (Study 3). Results demonstrated that introducing an agent that represents a communication system to take responsibility for technical issues actively could reduce the responsibility people assign to remote job applicants, but without increasing their positive credibility rating for remote job applicants. Furthermore, showing forewarning messages, which explicitly made people aware the cause of technical issues was unidentifiable and its potential negative impacts on impression formation, enabled people to rate the credibility of the remote counterpart without being influenced by technical issues. We discussed how interventions can be designed to mitigate negative attribution outcomes when encountering uncontrollable technical issues in computer-mediated communication.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3687004', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3687004?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3687004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2268627521', 'name': 'Chi-Lan Yang'}, {'authorId': '2299485103', 'name': 'Xiaotong Li'}, {'authorId': '2237799094', 'name': 'Takuji Narumi'}, {'authorId': '2256516375', 'name': 'Hideaki Kuzuoka'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'bef65bb76a3eb7db73d73735b6de555ae2ab6b97', 'title': 'Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI', 'abstract': '\\n While many Natural Language Processing (NLP) techniques have been proposed for fact-checking, both academic research and fact-checking organizations report limited adoption of such NLP work due to poor alignment with fact-checker practices, values, and needs. To address this, we investigate a co-design method,\\n Matchmaking for AI,\\n to enable fact-checkers, designers, and NLP researchers to collaboratively identify what fact-checker needs should be addressed by technology, and to brainstorm ideas for potential solutions. Co-design sessions we conducted with 22 professional fact-checkers yielded a set of 11 design ideas that offer a \"north star\\'\\', integrating fact-checker criteria into novel NLP design concepts. These concepts range from pre-bunking misinformation, efficient and personalized monitoring misinformation, proactively reducing fact-checker potential biases, and collaborative writing fact-check reports. Our work provides new insights into both human-centered fact-checking research and practice and AI co-design research.\\n', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3686962', 'status': 'HYBRID', 'license': 'other-oa', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2308.07213, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2196946052', 'name': 'Houjiang Liu'}, {'authorId': '47295297', 'name': 'Anubrata Das'}, {'authorId': '2154667383', 'name': 'Alexander Boltz'}, {'authorId': '2228433446', 'name': 'Didi Zhou'}, {'authorId': '2231540069', 'name': 'Daisy Pinaroc'}, {'authorId': '41124215', 'name': 'Matthew Lease'}, {'authorId': '2109515767', 'name': 'Min Kyung Lee'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4dca14fd576329c8b6683d193f505e17355b1889', 'title': '\"Just Like, Risking Your Life Here\": Participatory Design of User Interactions with Risk Detection AI to Prevent Online-to-Offline Harm Through Dating Apps', 'abstract': 'Social computing platforms facilitate interpersonal harms that manifest across online and physical realms such as sexual violence between online daters and sexual grooming through social media. Risk detection AI has emerged as an approach to preventing such harms, however a myopic focus on computational performance has been criticized in HCI literature for failing to consider how users should interact with risk detection AI to stay safe. In this paper we report an interview study with woman-identifying online daters (n=20) about how they envision interacting with risk detection AI and how risk detection models can be designed pursuant to such interactions. In accordance with this goal, we engaged women in risk detection model building exercises to build their own risk detection models. Findings show that women anticipate interacting with risk detection AI to augment - not replace - their personal risk assessment strategies. They likewise designed risk detection models to amplify their subjective and admittedly biased indicators of risk. Design implications involve the notion of personalizable risk detection models, but also ethical concerns around perpetuating problematic stereotypes associated with risk.', 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3686906', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686906?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686906, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2190111822', 'name': 'Isha Datey'}, {'authorId': '2606408', 'name': 'Douglas Zytko'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'e4f78b672f6ad3d5ff66bf4c0e4e0613bcb8f873', 'title': 'Design Digital Multisensory Textile Experiences', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678957.3688621?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678957.3688621, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2147241341', 'name': 'Shu Zhong'}]}\n",
      "No publicationDate: {'paperId': 'e4f78b672f6ad3d5ff66bf4c0e4e0613bcb8f873', 'title': 'Design Digital Multisensory Textile Experiences', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678957.3688621?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678957.3688621, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2147241341', 'name': 'Shu Zhong'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '15e49a5ec2616a7e7e6bdda35eb98f9ff2927cb2', 'title': 'Feeling Textiles through AI: An exploration into Multimodal Language Models and Human Perception Alignment', 'abstract': 'Human-artificial intelligence (AI) alignment ensures that AI systems align with human goals and behaviors. This paper introduces perceptual alignment as a critical aspect of this alignment, focusing on the concurrence between human judgments and AI evaluations across sensory modalities. We particularly explore how Multimodal Large Language Models (MLLMs), which process both visual and textual data, interpret the tactile qualities of textiles—a significant challenge in online shopping environments. Our research analyzes six vision-based MLLMs to see how they describe the tactile experience of textiles and compares these AI-generated descriptions with human assessments. Through semantic similarity measures and in-person evaluations, we investigate the extent of alignment between human perceptions and AI descriptions. Our findings indicate significant variability in the AI’s ability to interpret different textiles, highlighting both the potential and limitations of current AI models in achieving perceptual alignment. This work contributes to understanding the complexities of aligning AI capabilities with human touch sensory experiences.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678957.3685756?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678957.3685756, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2147241341', 'name': 'Shu Zhong'}, {'authorId': '2305683602', 'name': 'Elia Gatti'}, {'authorId': '2306867513', 'name': 'Youngjun Cho'}, {'authorId': '2258323555', 'name': 'Marianna Obrist'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '707304ef5a888a3d53dcfc32081bf0261b94ec9c', 'title': 'Envisioning Futures: How the Modality of AI Recommendations Impacts Conversation Flow in AR-enhanced Dialogue', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678957.3685731?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678957.3685731, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '51179828', 'name': 'Steeven Villa'}, {'authorId': '2292196104', 'name': 'Yannick Weiss'}, {'authorId': '2342255781', 'name': 'Mei-Yi Lu'}, {'authorId': '2268866324', 'name': 'Moritz Ziarko'}, {'authorId': '2163466011', 'name': 'Albrecht Schmidt'}, {'authorId': '1999052', 'name': 'Jasmin Niess'}]}\n",
      "No publicationDate: {'paperId': '707304ef5a888a3d53dcfc32081bf0261b94ec9c', 'title': 'Envisioning Futures: How the Modality of AI Recommendations Impacts Conversation Flow in AR-enhanced Dialogue', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3678957.3685731?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3678957.3685731, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '51179828', 'name': 'Steeven Villa'}, {'authorId': '2292196104', 'name': 'Yannick Weiss'}, {'authorId': '2342255781', 'name': 'Mei-Yi Lu'}, {'authorId': '2268866324', 'name': 'Moritz Ziarko'}, {'authorId': '2163466011', 'name': 'Albrecht Schmidt'}, {'authorId': '1999052', 'name': 'Jasmin Niess'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '15b5b32bfb29298b8b94b50b6b31792832bb1045', 'title': 'Levels of Multimodal Interaction', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686215.3690153?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686215.3690153, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '47270594', 'name': 'A. K. Sinha'}, {'authorId': '2214547658', 'name': 'Chinmay Kulkarni'}, {'authorId': '2328540890', 'name': 'Alex Olwal'}]}\n",
      "No publicationDate: {'paperId': '15b5b32bfb29298b8b94b50b6b31792832bb1045', 'title': 'Levels of Multimodal Interaction', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686215.3690153?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686215.3690153, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '47270594', 'name': 'A. K. Sinha'}, {'authorId': '2214547658', 'name': 'Chinmay Kulkarni'}, {'authorId': '2328540890', 'name': 'Alex Olwal'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'b9b090a88b058921b700b57e2abf0b3f647969b7', 'title': 'Detecting when Users Disagree with Generated Captions', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686215.3688382?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686215.3688382, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2105468553', 'name': 'Omair Shahzad Bhatti'}, {'authorId': '2085411586', 'name': 'Harshinee Sriram'}, {'authorId': '2310451859', 'name': 'Abdulrahman Mohamed Selim'}, {'authorId': '2265385911', 'name': 'Cristina Conati'}, {'authorId': '39739949', 'name': 'Michael Barz'}, {'authorId': '2243244763', 'name': 'Daniel Sonntag'}]}\n",
      "No publicationDate: {'paperId': 'b9b090a88b058921b700b57e2abf0b3f647969b7', 'title': 'Detecting when Users Disagree with Generated Captions', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3686215.3688382?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3686215.3688382, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2105468553', 'name': 'Omair Shahzad Bhatti'}, {'authorId': '2085411586', 'name': 'Harshinee Sriram'}, {'authorId': '2310451859', 'name': 'Abdulrahman Mohamed Selim'}, {'authorId': '2265385911', 'name': 'Cristina Conati'}, {'authorId': '39739949', 'name': 'Michael Barz'}, {'authorId': '2243244763', 'name': 'Daniel Sonntag'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': 'eeb407183e6620b69ea9b324de612fdcaf331b72', 'title': 'AI Assisted Domain Modeling Explainability and Traceability', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3652620.3688197?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3652620.3688197, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2329087161', 'name': 'Jonathan Silva Mercado'}]}\n",
      "No publicationDate: {'paperId': 'eeb407183e6620b69ea9b324de612fdcaf331b72', 'title': 'AI Assisted Domain Modeling Explainability and Traceability', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3652620.3688197?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3652620.3688197, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2329087161', 'name': 'Jonathan Silva Mercado'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No abstract: {'paperId': '6f474f80bff86bba5cf275a0aa77081b9f7a8a1c', 'title': 'Alternative Routing based on Road Popularity', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3681779.3696836?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3681779.3696836, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1796264540', 'name': 'Giuliano Cornacchia'}, {'authorId': '2305615785', 'name': 'Ludovico Lemma'}, {'authorId': '2276443419', 'name': 'Luca Pappalardo'}]}\n",
      "No publicationDate: {'paperId': '6f474f80bff86bba5cf275a0aa77081b9f7a8a1c', 'title': 'Alternative Routing based on Road Popularity', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3681779.3696836?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3681779.3696836, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1796264540', 'name': 'Giuliano Cornacchia'}, {'authorId': '2305615785', 'name': 'Ludovico Lemma'}, {'authorId': '2276443419', 'name': 'Luca Pappalardo'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '53586a1458fe14a0e9f269f516ef44dadfe9949e', 'title': 'From Prompts to Templates: A Systematic Prompt Template Analysis for Real-world LLMapps', 'abstract': \"Large Language Models (LLMs) have revolutionized human-AI interaction by enabling intuitive task execution through natural language prompts. Despite their potential, designing effective prompts remains a significant challenge, as small variations in structure or wording can result in substantial differences in output. To address these challenges, LLM-powered applications (LLMapps) rely on prompt templates to simplify interactions, enhance usability, and support specialized tasks such as document analysis, creative content generation, and code synthesis. However, current practices heavily depend on individual expertise and iterative trial-and-error processes, underscoring the need for systematic methods to optimize prompt template design in LLMapps. This paper presents a comprehensive analysis of prompt templates in practical LLMapps. We construct a dataset of real-world templates from open-source LLMapps, including those from leading companies like Uber and Microsoft. Through a combination of LLM-driven analysis and human review, we categorize template components and placeholders, analyze their distributions, and identify frequent co-occurrence patterns. Additionally, we evaluate the impact of identified patterns on LLMs' instruction-following performance through sample testing. Our findings provide practical insights on prompt template design for developers, supporting the broader adoption and optimization of LLMapps in industrial settings.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2504.02052, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': None, 'name': 'Yuetian Mao'}, {'authorId': None, 'name': 'Junjie He'}, {'authorId': None, 'name': 'Chunyang Chen'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '2e86bca54bee081961ea26e8d8b30a9f658a88de', 'title': 'Enabling Rapid Shared Human-AI Mental Model Alignment via the After-Action Review', 'abstract': \"In this work, we present two novel contributions toward improving research in human-machine teaming (HMT): 1) a Minecraft testbed to accelerate testing and deployment of collaborative AI agents and 2) a tool to allow users to revisit and analyze behaviors within an HMT episode to facilitate shared mental model development. Our browser-based Minecraft testbed allows for rapid testing of collaborative agents in a continuous-space, real-time, partially-observable environment with real humans without cumbersome setup typical to human-AI interaction user studies. As Minecraft has an extensive player base and a rich ecosystem of pre-built AI agents, we hope this contribution can help to facilitate research quickly in the design of new collaborative agents and in understanding different human factors within HMT. Our mental model alignment tool facilitates user-led post-mission analysis by including video displays of first-person perspectives of the team members (i.e., the human and AI) that can be replayed, and a chat interface that leverages GPT-4 to provide answers to various queries regarding the AI's experiences and model details.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.19607, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2352015722', 'name': 'Edward Gu'}, {'authorId': '2351608348', 'name': 'Ho Chit Siu'}, {'authorId': '2351910056', 'name': 'Melanie Platt'}, {'authorId': '2309477743', 'name': 'Isabelle Hurley'}, {'authorId': '2351945778', 'name': 'Jaime Pena'}, {'authorId': '83862731', 'name': 'Rohan R. Paleja'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3836fc4d0f48c3b8dfb38967e01ba8f0ec4b323d', 'title': 'MMCR: Advancing Visual Language Model in Multimodal Multi-Turn Contextual Reasoning', 'abstract': 'Compared to single-turn dialogue, multi-turn dialogue involving multiple images better aligns with the needs of real-world human-AI interactions. Additionally, as training data, it provides richer contextual reasoning information, thereby guiding the model to achieve better performance. However, existing vision-language models (VLMs) primarily rely on single-turn dialogue training and evaluation benchmarks. In this paper, following the characteristics of human dialogue, such as focused topics and concise, clear content, we present MMCR (Multimodal Multi-turn Contextual Reasoning), a novel dataset comprising: (1) MMCR-310k -- the largest multi-image multi-turn instruction tuning dataset with 310K contextual dialogues, each covering 1-4 images and 4 or 8 dialogue turns; and (2) MMCR-Bench -- a diagnostic benchmark featuring dialogues, spanning 8 domains (Humanities, Natural, Science, Education, etc.) and 40 sub-topics. Extensive evaluations demonstrate that models fine-tuned with MMCR-310k achieve 5.2\\\\% higher contextual accuracy on MMCR-Bench, while showing consistent improvements on existing benchmarks (+1.1\\\\% on AI2D, +1.2\\\\% on MMMU and MMVet). MMCR and prompt engineering will be released publicly.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.18533, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2297967654', 'name': 'Dawei Yan'}, {'authorId': '2304418647', 'name': 'Yang Li'}, {'authorId': '2304395071', 'name': 'Qingguo Chen'}, {'authorId': '2349954905', 'name': 'Weihua Luo'}, {'authorId': '2351832505', 'name': 'Peng Wang'}, {'authorId': '9726614', 'name': 'Haokui Zhang'}, {'authorId': '2352756983', 'name': 'Chunhua Shen'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'c0846e46120e03ad26d8af70d68d4b740166facb', 'title': 'Human-AI Interaction and User Satisfaction: Empirical Evidence from Online Reviews of AI Products', 'abstract': 'Human-AI Interaction (HAI) guidelines and design principles have become increasingly important in both industry and academia to guide the development of AI systems that align with user needs and expectations. However, large-scale empirical evidence on how HAI principles shape user satisfaction in practice remains limited. This study addresses that gap by analyzing over 100,000 user reviews of AI-related products from G2, a leading review platform for business software and services. Based on widely adopted industry guidelines, we identify seven core HAI dimensions and examine their coverage and sentiment within the reviews. We find that the sentiment on four HAI dimensions-adaptability, customization, error recovery, and security-is positively associated with overall user satisfaction. Moreover, we show that engagement with HAI dimensions varies by professional background: Users with technical job roles are more likely to discuss system-focused aspects, such as reliability, while non-technical users emphasize interaction-focused features like customization and feedback. Interestingly, the relationship between HAI sentiment and overall satisfaction is not moderated by job role, suggesting that once an HAI dimension has been identified by users, its effect on satisfaction is consistent across job roles.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.17955, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2351802594', 'name': 'Stefan Pasch'}, {'authorId': '2351779073', 'name': 'Sun-Young Ha'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '07c170d25170b7a60a9710ea10685a28066420b8', 'title': 'Deterministic AI Agent Personality Expression through Standard Psychological Diagnostics', 'abstract': 'Artificial intelligence (AI) systems powered by large language models have become increasingly prevalent in modern society, enabling a wide range of applications through natural language interaction. As AI agents proliferate in our daily lives, their generic and uniform expressiveness presents a significant limitation to their appeal and adoption. Personality expression represents a key prerequisite for creating more human-like and distinctive AI systems. We show that AI models can express deterministic and consistent personalities when instructed using established psychological frameworks, with varying degrees of accuracy depending on model capabilities. We find that more advanced models like GPT-4o and o1 demonstrate the highest accuracy in expressing specified personalities across both Big Five and Myers-Briggs assessments, and further analysis suggests that personality expression emerges from a combination of intelligence and reasoning capabilities. Our results reveal that personality expression operates through holistic reasoning rather than question-by-question optimization, with response-scale metrics showing higher variance than test-scale metrics. Furthermore, we find that model fine-tuning affects communication style independently of personality expression accuracy. These findings establish a foundation for creating AI agents with diverse and consistent personalities, which could significantly enhance human-AI interaction across applications from education to healthcare, while additionally enabling a broader range of more unique AI agents. The ability to quantitatively assess and implement personality expression in AI systems opens new avenues for research into more relatable, trustworthy, and ethically designed AI.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.17085, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '145055300', 'name': 'J. Kruijssen'}, {'authorId': '2329623143', 'name': 'Nicholas Emmons'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '1f21cf4b4296825b220e88389de49495b3010e1f', 'title': 'Evolving the Computational Notebook: A Two-Dimensional Canvas for Enhanced Human-AI Interaction', 'abstract': \"Computational notebooks, while essential for data science, are limited by their one-dimensional interface, which poorly aligns with non-linear developer workflows and complicates collaboration and human-AI interaction. In this work, we focus on features of Computational Canvas, a novel two-dimensional interface that evolves notebooks to enhance data analysis and AI-assisted development within integrated development environments (IDEs). We present vital features, including freely arrangeable code cells, separate environments, and improved output management. These features are designed to facilitate intuitive organization, visual exploration, and natural collaboration with other users and AI agents. We also show the implementation of Computational Canvas with designed features as a Visual Studio Code plugin. By shifting from linear to two-dimensional spatial interfaces, we aim to significantly boost developers' productivity in data exploration, experimentation, and AI-assisted development, addressing the current limitations of traditional notebooks and fostering more flexible, collaborative data science workflows.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.16967, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2351603269', 'name': 'Konstantin Grotov'}, {'authorId': '2351603271', 'name': 'Dmitry Botov'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '2572d18fa17c46740258e571e4ede0227a42264c', 'title': 'Conversational User-AI Intervention: A Study on Prompt Rewriting for Improved LLM Response Generation', 'abstract': \"Human-LLM conversations are increasingly becoming more pervasive in peoples' professional and personal lives, yet many users still struggle to elicit helpful responses from LLM Chatbots. One of the reasons for this issue is users' lack of understanding in crafting effective prompts that accurately convey their information needs. Meanwhile, the existence of real-world conversational datasets on the one hand, and the text understanding faculties of LLMs on the other, present a unique opportunity to study this problem, and its potential solutions at scale. Thus, in this paper we present the first LLM-centric study of real human-AI chatbot conversations, focused on investigating aspects in which user queries fall short of expressing information needs, and the potential of using LLMs to rewrite suboptimal user prompts. Our findings demonstrate that rephrasing ineffective prompts can elicit better responses from a conversational system, while preserving the user's original intent. Notably, the performance of rewrites improves in longer conversations, where contextual inferences about user needs can be made more accurately. Additionally, we observe that LLMs often need to -- and inherently do -- make \\\\emph{plausible} assumptions about a user's intentions and goals when interpreting prompts. Our findings largely hold true across conversational domains, user intents, and LLMs of varying sizes and families, indicating the promise of using prompt rewriting as a solution for better human-AI interactions.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.16789, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '14627064', 'name': 'Rupak Sarkar'}, {'authorId': '2264984', 'name': 'Bahareh Sarrafzadeh'}, {'authorId': '2347351319', 'name': 'Nirupama Chandrasekaran'}, {'authorId': '46551415', 'name': 'N.Kasturi Rangan'}, {'authorId': '2350517474', 'name': 'Philip Resnik'}, {'authorId': '2266801772', 'name': 'Longqi Yang'}, {'authorId': '3001990', 'name': 'S. Jauhar'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'a4b005df73e6407a68e3ef0458d2a08c177a18c6', 'title': 'Human-AI Interaction Design Standards', 'abstract': 'The rapid development of artificial intelligence (AI) has significantly transformed human-computer interactions, making it essential to establish robust design standards to ensure effective, ethical, and human-centered AI (HCAI) solutions. Standards serve as the foundation for the adoption of new technologies, and human-AI interaction (HAII) standards are critical to supporting the industrialization of AI technology by following an HCAI approach. These design standards aim to provide clear principles, requirements, and guidelines for designing, developing, deploying, and using AI systems, enhancing the user experience and performance of AI systems. Despite their importance, the creation and adoption of HCAI-based interaction design standards face challenges, including the absence of universal frameworks, the inherent complexity of HAII, and the ethical dilemmas that arise in such systems. This chapter provides a comparative analysis of HAII versus traditional human-computer interaction (HCI) and outlines guiding principles for HCAI-based design. It explores international, regional, national, and industry standards related to HAII design from an HCAI perspective and reviews design guidelines released by leading companies such as Microsoft, Google, and Apple. Additionally, the chapter highlights tools available for implementing HAII standards and presents case studies of human-centered interaction design for AI systems in diverse fields, including healthcare, autonomous vehicles, and customer service. It further examines key challenges in developing HAII standards and suggests future directions for the field. Emphasizing the importance of ongoing collaboration between AI designers, developers, and experts in human factors and HCI, this chapter stresses the need to advance HCAI-based interaction design standards to ensure human-centered AI solutions across various domains.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.16472, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2241947188', 'name': 'Chao Zhao'}, {'authorId': '2351889876', 'name': 'Wei Xu'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'e5004af15b3c86d9975ea23d797145af6284c939', 'title': 'Revival: Collaborative Artistic Creation through Human-AI Interactions in Musical Creativity', 'abstract': \"Revival is an innovative live audiovisual performance and music improvisation by our artist collective K-Phi-A, blending human and AI musicianship to create electronic music with audio-reactive visuals. The performance features real-time co-creative improvisation between a percussionist, an electronic music artist, and AI musical agents. Trained in works by deceased composers and the collective's compositions, these agents dynamically respond to human input and emulate complex musical styles. An AI-driven visual synthesizer, guided by a human VJ, produces visuals that evolve with the musical landscape. Revival showcases the potential of AI and human collaboration in improvisational artistic creation.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.15498, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2145119897', 'name': 'K. J. Lee'}, {'authorId': '2338011125', 'name': 'Philippe Pasquier'}, {'authorId': '2338006959', 'name': 'Jun Yuri'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'd2696cda5fcb979a4a45a71ca22f2a1ec7f7f5bd', 'title': 'MMR: A Large-scale Benchmark Dataset for Multi-target and Multi-granularity Reasoning Segmentation', 'abstract': 'The fusion of Large Language Models with vision models is pioneering new possibilities in user-interactive vision-language tasks. A notable application is reasoning segmentation, where models generate pixel-level segmentation masks by comprehending implicit meanings in human instructions. However, seamless human-AI interaction demands more than just object-level recognition; it requires understanding both objects and the functions of their detailed parts, particularly in multi-target scenarios. For example, when instructing a robot to \\\\textit{turn on the TV\"}, there could be various ways to accomplish this command. Recognizing multiple objects capable of turning on the TV, such as the TV itself or a remote control (multi-target), provides more flexible options and aids in finding the optimized scenario. Furthermore, understanding specific parts of these objects, like the TV\\'s button or the remote\\'s button (part-level), is important for completing the action. Unfortunately, current reasoning segmentation datasets predominantly focus on a single target object-level reasoning, which limits the detailed recognition of an object\\'s parts in multi-target contexts. To address this gap, we construct a large-scale dataset called Multi-target and Multi-granularity Reasoning (MMR). MMR comprises 194K complex and implicit instructions that consider multi-target, object-level, and part-level aspects, based on pre-existing image-mask sets. This dataset supports diverse and context-aware interactions by hierarchically providing object and part information. Moreover, we propose a straightforward yet effective framework for multi-target, object-level, and part-level reasoning segmentation. Experimental results on MMR show that the proposed method can reason effectively in multi-target and multi-granularity scenarios, while the existing reasoning segmentation model still has room for improvement.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.13881, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2268310103', 'name': 'Donggon Jang'}, {'authorId': '30713901', 'name': 'Yucheol Cho'}, {'authorId': '2268370058', 'name': 'Suin Lee'}, {'authorId': '2351125524', 'name': 'Taehyeon Kim'}, {'authorId': '2154956720', 'name': 'Dae-Shik Kim'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '8e675c2929595e225f0580c9593bee7b3dbd67f9', 'title': 'Integrating AI for Human-Centric Breast Cancer Diagnostics: A Multi-Scale and Multi-View Swin Transformer Framework', 'abstract': \"Despite advancements in Computer-Aided Diagnosis (CAD) systems, breast cancer remains one of the leading causes of cancer-related deaths among women worldwide. Recent breakthroughs in Artificial Intelligence (AI) have shown significant promise in development of advanced Deep Learning (DL) architectures for breast cancer diagnosis through mammography. In this context, the paper focuses on the integration of AI within a Human-Centric workflow to enhance breast cancer diagnostics. Key challenges are, however, largely overlooked such as reliance on detailed tumor annotations and susceptibility to missing views, particularly during test time. To address these issues, we propose a hybrid, multi-scale and multi-view Swin Transformer-based framework (MSMV-Swin) that enhances diagnostic robustness and accuracy. The proposed MSMV-Swin framework is designed to work as a decision-support tool, helping radiologists analyze multi-view mammograms more effectively. More specifically, the MSMV-Swin framework leverages the Segment Anything Model (SAM) to isolate the breast lobe, reducing background noise and enabling comprehensive feature extraction. The multi-scale nature of the proposed MSMV-Swin framework accounts for tumor-specific regions as well as the spatial characteristics of tissues surrounding the tumor, capturing both localized and contextual information. The integration of contextual and localized data ensures that MSMV-Swin's outputs align with the way radiologists interpret mammograms, fostering better human-AI interaction and trust. A hybrid fusion structure is then designed to ensure robustness against missing views, a common occurrence in clinical practice when only a single mammogram view is available.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.13309, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '51953594', 'name': 'Farnoush Bayatmakou'}, {'authorId': '2350752542', 'name': 'Reza Taleei'}, {'authorId': '2619049', 'name': 'Milad Amir Toutounchian'}, {'authorId': '2298030884', 'name': 'Arash Mohammadi'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'e587e662910ead8fdf90f331d22b180ccf01344e', 'title': 'TRUTH DECAY: Quantifying Multi-Turn Sycophancy in Language Models', 'abstract': 'Rapid improvements in large language models have unveiled a critical challenge in human-AI interaction: sycophancy. In this context, sycophancy refers to the tendency of models to excessively agree with or flatter users, often at the expense of factual accuracy. While previous studies have primarily analyzed this behavior in single-turn interactions, its persistence and evolution in multi-step conversations remain largely unexplored. We introduce TRUTH DECAY, a benchmark specifically designed to evaluate sycophancy in extended dialogues, where language models must navigate iterative user feedback, challenges, and persuasion. We prompt models to elicit four types of sycophantic biases. We then propose and test sycophancy reduction strategies, evaluating their effectiveness beyond single-step interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.11656, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2350519709', 'name': 'Joshua Liu'}, {'authorId': '2350770825', 'name': 'Aarav Jain'}, {'authorId': '2350512762', 'name': 'Soham Takuri'}, {'authorId': '2350512267', 'name': 'Srihan Vege'}, {'authorId': '2327866177', 'name': 'Aslihan Akalin'}, {'authorId': '2312105716', 'name': 'Kevin Zhu'}, {'authorId': '2348096381', 'name': \"Sean O'Brien\"}, {'authorId': '2348193755', 'name': 'Vasu Sharma'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '9fb1d48b4a7a10433963e639f91f5152dad25a22', 'title': 'Measuring Political Preferences in AI Systems: An Integrative Approach', 'abstract': \"Political biases in Large Language Model (LLM)-based artificial intelligence (AI) systems, such as OpenAI's ChatGPT or Google's Gemini, have been previously reported. While several prior studies have attempted to quantify these biases using political orientation tests, such approaches are limited by potential tests' calibration biases and constrained response formats that do not reflect real-world human-AI interactions. This study employs a multi-method approach to assess political bias in leading AI systems, integrating four complementary methodologies: (1) linguistic comparison of AI-generated text with the language used by Republican and Democratic U.S. Congress members, (2) analysis of political viewpoints embedded in AI-generated policy recommendations, (3) sentiment analysis of AI-generated text toward politically affiliated public figures, and (4) standardized political orientation testing. Results indicate a consistent left-leaning bias across most contemporary AI systems, with arguably varying degrees of intensity. However, this bias is not an inherent feature of LLMs; prior research demonstrates that fine-tuning with politically skewed data can realign these models across the ideological spectrum. The presence of systematic political bias in AI systems poses risks, including reduced viewpoint diversity, increased societal polarization, and the potential for public mistrust in AI technologies. To mitigate these risks, AI systems should be designed to prioritize factual accuracy while maintaining neutrality on most lawful normative issues. Furthermore, independent monitoring platforms are necessary to ensure transparency, accountability, and responsible AI development.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.10649, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2282539311', 'name': 'David Rozado'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '942c0494a5530ac36ddbd2a66b3f04ec5732609f', 'title': 'Augmenting Teamwork through AI Agents as Spatial Collaborators', 'abstract': 'As Augmented Reality (AR) and Artificial Intelligence (AI) continue to converge, new opportunities emerge for AI agents to actively support human collaboration in immersive environments. While prior research has primarily focused on dyadic human-AI interactions, less attention has been given to Human-AI Teams (HATs) in AR, where AI acts as an adaptive teammate rather than a static tool. This position paper takes the perspective of team dynamics and work organization to propose that AI agents in AR should not only interact with individuals but also recognize and respond to team-level needs in real time. We argue that spatially aware AI agents should dynamically generate the resources necessary for effective collaboration, such as virtual blackboards for brainstorming, mental map models for shared understanding, and memory recall of spatial configurations to enhance knowledge retention and task coordination. This approach moves beyond predefined AI assistance toward context-driven AI interventions that optimize team performance and decision-making.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.09794, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2349806778', 'name': 'Mariana Fernandez-Espinosa'}, {'authorId': '2349801940', 'name': 'Diego Gomez-Zara'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'd3b5c2417bd7af576ae58b0dc8a9d323ffe03bd1', 'title': 'NeuroChat: A Neuroadaptive AI Chatbot for Customizing Learning Experiences', 'abstract': \"Generative AI is transforming education by enabling personalized, on-demand learning experiences. However, AI tutors lack the ability to assess a learner's cognitive state in real time, limiting their adaptability. Meanwhile, electroencephalography (EEG)-based neuroadaptive systems have successfully enhanced engagement by dynamically adjusting learning content. This paper presents NeuroChat, a proof-of-concept neuroadaptive AI tutor that integrates real-time EEG-based engagement tracking with generative AI. NeuroChat continuously monitors a learner's cognitive engagement and dynamically adjusts content complexity, response style, and pacing using a closed-loop system. We evaluate this approach in a pilot study (n=24), comparing NeuroChat to a standard LLM-based chatbot. Results indicate that NeuroChat enhances cognitive and subjective engagement but does not show an immediate effect on learning outcomes. These findings demonstrate the feasibility of real-time cognitive feedback in LLMs, highlighting new directions for adaptive learning, AI tutoring, and human-AI interaction.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.07599, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2301061374', 'name': 'Dunya Baradari'}, {'authorId': '1847788', 'name': 'Nataliya Kosmyna'}, {'authorId': '2349535253', 'name': 'Oscar Petrov'}, {'authorId': '2349534718', 'name': 'Rebecah Kaplun'}, {'authorId': '2285248074', 'name': 'Pattie Maes'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '226f859f2470e83b63e4deb38dd6a1e4e5d5264b', 'title': 'StreamMind: Unlocking Full Frame Rate Streaming Video Dialogue through Event-Gated Cognition', 'abstract': \"With the rise of real-world human-AI interaction applications, such as AI assistants, the need for Streaming Video Dialogue is critical. To address this need, we introduce StreamMind, a video LLM framework that achieves ultra-FPS streaming video processing (100 fps on a single A100) and enables proactive, always-on responses in real time, without explicit user intervention. To solve the key challenge of the contradiction between linear video streaming speed and quadratic transformer computation cost, we propose a novel perception-cognition interleaving paradigm named ''event-gated LLM invocation'', in contrast to the existing per-time-step LLM invocation. By introducing a Cognition Gate network between the video encoder and the LLM, LLM is only invoked when relevant events occur. To realize the event feature extraction with constant cost, we propose Event-Preserving Feature Extractor (EPFE) based on state-space method, generating a single perception token for spatiotemporal features. These techniques enable the video LLM with full-FPS perception and real-time cognition response. Experiments on Ego4D and SoccerNet streaming tasks, as well as standard offline benchmarks, demonstrate state-of-the-art performance in both model capability and real-time efficiency, paving the way for ultra-high-FPS applications, such as Game AI and interactive media. The code and data is available at https://aka.ms/StreamMind.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.06220, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2350151012', 'name': 'Xin Ding'}, {'authorId': '2349380257', 'name': 'Hao Wu'}, {'authorId': '2313033754', 'name': 'Yifan Yang'}, {'authorId': '2170664295', 'name': 'Shiqi Jiang'}, {'authorId': '2285178582', 'name': 'Donglin Bai'}, {'authorId': '2339965694', 'name': 'Zhibo Chen'}, {'authorId': '2326975040', 'name': 'Ting Cao'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'ab5343433366621774670e16a2b3950128723959', 'title': 'Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance Model', 'abstract': 'As artificial intelligence (AI) continues to advance--particularly in generative models--an open question is whether these systems can replicate foundational models of human social perception. A well-established framework in social cognition suggests that social judgments are organized along two primary dimensions: valence (e.g., trustworthiness, warmth) and dominance (e.g., power, assertiveness). This study examines whether multimodal generative AI systems can reproduce this valence-dominance structure when evaluating facial images and how their representations align with those observed across world regions. Through principal component analysis (PCA), we found that the extracted dimensions closely mirrored the theoretical structure of valence and dominance, with trait loadings aligning with established definitions. However, many world regions and generative AI models also exhibited a third component, the nature and significance of which warrant further investigation. These findings demonstrate that multimodal generative AI systems can replicate key aspects of human social perception, raising important questions about their implications for AI-driven decision-making and human-AI interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.04842, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2037097429', 'name': 'Necdet Gurkan'}, {'authorId': '2349235165', 'name': 'Kimathi Njoki'}, {'authorId': '2176225', 'name': 'Jordan W. Suchow'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'a6fb3ca354e2e2946e9922810f9958dea0d39857', 'title': 'Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts', 'abstract': \"Multimodal Large Language Models (MLLMs) have garnered significant attention for their strong visual-semantic understanding. Most existing chart benchmarks evaluate MLLMs' ability to parse information from charts to answer questions. However, they overlook the inherent output biases of MLLMs, where models rely on their parametric memory to answer questions rather than genuinely understanding the chart content. To address this limitation, we introduce a novel Chart Hypothetical Question Answering (HQA) task, which imposes assumptions on the same question to compel models to engage in counterfactual reasoning based on the chart content. Furthermore, we introduce HAI, a human-AI interactive data synthesis approach that leverages the efficient text-editing capabilities of LLMs alongside human expert knowledge to generate diverse and high-quality HQA data at a low cost. Using HAI, we construct Chart-HQA, a challenging benchmark synthesized from publicly available data sources. Evaluation results on 18 MLLMs of varying model sizes reveal that current models face significant generalization challenges and exhibit imbalanced reasoning performance on the HQA task.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.04095, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2349247037', 'name': 'Xiangnan Chen'}, {'authorId': '2349183978', 'name': 'Yuancheng Fang'}, {'authorId': '2349779292', 'name': 'Qian Xiao'}, {'authorId': '2261788275', 'name': 'Juncheng Li'}, {'authorId': '2348959132', 'name': 'Jun Lin'}, {'authorId': '2276402838', 'name': 'Siliang Tang'}, {'authorId': '2349648693', 'name': 'Yi Yang'}, {'authorId': '2253660817', 'name': 'Yueting Zhuang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '8d2b3c0ecc493eba7ec1f1e9da165b11a4e9fdbe', 'title': 'Student engagement in collaborative learning with AI agents in an LLM-empowered learning environment: A cluster analysis', 'abstract': \"Integrating LLM models into educational practice fosters personalized learning by accommodating the diverse behavioral patterns of different learner types. This study aims to explore these learner types within a novel interactive setting, providing a detailed analysis of their distinctive characteristics and interaction dynamics. The research involved 110 students from a university in China, who engaged with multiple LLM agents in an LLM-empowered learning environment, completing coursework across six modules. Data on the students' non-cognitive traits, course engagement, and AI interaction patterns were collected and analyzed. Using hierarchical cluster analysis, the students were classified into three distinct groups: active questioners, responsive navigators, and silent listeners. Epistemic network analysis was then applied to further delineate the interaction profiles and cognitive engagement of different types of learners. The findings underscore how different learner types engage with human-AI interactive learning and offer practical implications for the design of adaptive educational systems.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.01694, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2321157947', 'name': 'Zhanxin Hao'}, {'authorId': '2320075125', 'name': 'Jianxiao Jiang'}, {'authorId': '2348404515', 'name': 'Jifan Yu'}, {'authorId': '2308485553', 'name': 'Zhiyuan Liu'}, {'authorId': '2319833071', 'name': 'Yu Zhang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '2d5921e8bd05178162e6e53bdbd4c564ddb1f295', 'title': 'Applying the Gricean Maxims to a Human-LLM Interaction Cycle: Design Insights from a Participatory Approach', 'abstract': \"While large language models (LLMs) are increasingly used to assist users in various tasks through natural language interactions, these interactions often fall short due to LLMs' limited ability to infer contextual nuances and user intentions, unlike humans. To address this challenge, we draw inspiration from the Gricean Maxims--human communication theory that suggests principles of effective communication--and aim to derive design insights for enhancing human-AI interactions (HAI). Through participatory design workshops with communication experts, designers, and end-users, we identified ways to apply these maxims across the stages of the HAI cycle. Our findings include reinterpreted maxims tailored to human-LLM contexts and nine actionable design considerations categorized by interaction stage. These insights provide a concrete framework for designing more cooperative and user-centered LLM-based systems, bridging theoretical foundations in communication with practical applications in HAI.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.00858, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2257129500', 'name': 'Yoonsu Kim'}, {'authorId': '2348541702', 'name': 'Brandon Chin'}, {'authorId': '2253401286', 'name': 'Kihoon Son'}, {'authorId': '2159596112', 'name': 'Seoyoung Kim'}, {'authorId': '2253808795', 'name': 'Juho Kim'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '0d52d69942b6cfa5894dcbada943a3df0ae76ed7', 'title': 'From Prompting to Partnering: Personalization Features for Human-LLM Interactions', 'abstract': \"Large Language Models (LLMs), such as ChatGPT, exhibit advanced capabilities in generating text, images, and videos. However, their effective use remains constrained by challenges in prompt formulation, personalization, and opaque decision-making processes. To investigate these challenges and identify design opportunities, we conducted a two-phase qualitative study. In Phase 1, we performed in-depth interviews with eight everyday LLM users after they engaged in structured tasks using ChatGPT across both familiar and unfamiliar domains. Our findings revealed key user difficulties in constructing effective prompts, iteratively refining AI-generated responses, and assessing response reliability especially in domains beyond users' expertise. Informed by these insights, we designed a high-fidelity prototype incorporating Reflective Prompting, Section Regeneration, Input-Output Mapping, Confidence Indicators, and a Customization Panel. In Phase 2, user testing of the prototype indicated that these interface-level improvements may prove useful for reducing cognitive load, increasing transparency, and fostering more intuitive and collaborative human-AI interactions. Our study contributes to the growing discourse on human-centred AI, advocating for human-LLM interactions that enhance user agency, transparency, and co-creative interaction, ultimately supporting more intuitive, accessible, and trustworthy generative AI systems.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2503.00681, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2348257575', 'name': 'Si Thu'}, {'authorId': '51374066', 'name': 'A. Kocaballi'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '71ffae8a998c7542fd991ed463d091e8e887f1ab', 'title': 'Why Trust in AI May Be Inevitable', 'abstract': 'In human-AI interactions, explanation is widely seen as necessary for enabling trust in AI systems. We argue that trust, however, may be a pre-requisite because explanation is sometimes impossible. We derive this result from a formalization of explanation as a search process through knowledge networks, where explainers must find paths between shared concepts and the concept to be explained, within finite time. Our model reveals that explanation can fail even under theoretically ideal conditions - when actors are rational, honest, motivated, can communicate perfectly, and possess overlapping knowledge. This is because successful explanation requires not just the existence of shared knowledge but also finding the connection path within time constraints, and it can therefore be rational to cease attempts at explanation before the shared knowledge is discovered. This result has important implications for human-AI interaction: as AI systems, particularly Large Language Models, become more sophisticated and able to generate superficially compelling but spurious explanations, humans may default to trust rather than demand genuine explanations. This creates risks of both misplaced trust and imperfect knowledge integration.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.20701, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2348096348', 'name': 'Nghi Truong'}, {'authorId': '2244016', 'name': 'P. Puranam'}, {'authorId': '2348096142', 'name': 'Ilia Testlin'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '23f6af67a0cf9ef13ecd12cb27f4a5b80bb6bbdd', 'title': 'RouteRL: Multi-agent reinforcement learning framework for urban route choice with autonomous vehicles', 'abstract': 'RouteRL is a novel framework that integrates multi-agent reinforcement learning (MARL) with a microscopic traffic simulation, facilitating the testing and development of efficient route choice strategies for autonomous vehicles (AVs). The proposed framework simulates the daily route choices of driver agents in a city, including two types: human drivers, emulated using behavioral route choice models, and AVs, modeled as MARL agents optimizing their policies for a predefined objective. RouteRL aims to advance research in MARL, transport modeling, and human-AI interaction for transportation applications. This study presents a technical report on RouteRL, outlines its potential research contributions, and showcases its impact via illustrative examples.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.20065, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2321870793', 'name': 'A. Akman'}, {'authorId': '2321871183', 'name': 'Anastasia Psarou'}, {'authorId': '2346114040', 'name': 'Lukasz Gorczyca'}, {'authorId': '2346115538', 'name': \"Zolt'an Gyorgy Varga\"}, {'authorId': '2321871873', 'name': \"Grzegorz Jamr'oz\"}, {'authorId': '2321870766', 'name': 'Rafał Kucharski'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '69a68f8a255edb5e54f8ec95d52337b7cd9a29ab', 'title': 'Interacting with Thoughtful AI', 'abstract': 'We envision the concept of Thoughtful AI, a new human-AI interaction paradigm in which the AI behaves as a continuously thinking entity. Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction. In this position paper, we argue that this thoughtfulness unlocks new possibilities for human-AI interaction by enabling proactive AI behavior, facilitating continuous cognitive alignment with users, and fostering more dynamic interaction experiences. We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.18676, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2146036493', 'name': 'Xingyu Bruce Liu'}, {'authorId': '2347492207', 'name': 'Haijun Xia'}, {'authorId': '2290750267', 'name': \"Xiang 'Anthony' Chen\"}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'd968db43bf21f1db5d9581634bb8cfa9f5920820', 'title': 'Carbon and Silicon, Coexist or Compete? A Survey on Human-AI Interactions in Agent-based Modeling and Simulation', 'abstract': \"Recent interest in human-AI interactions in agent-based modeling and simulation (ABMS) has grown rapidly due to the widespread utilization of large language models (LLMs). ABMS is an intelligent approach that simulates autonomous agents' behaviors within a defined environment to research emergent phenomena. Integrating LLMs into ABMS enables natural language interaction between humans and models. Meanwhile, it introduces new challenges that rely on human interaction to address. Human involvement can assist ABMS in adapting to flexible and complex research demands. However, systematic reviews of interactions that examine how humans and AI interact in ABMS are lacking. In this paper, we investigate existing works and propose a novel taxonomy to categorize the interactions derived from them. Specifically, human users refer to researchers who utilize ABMS tools to conduct their studies in our survey. We decompose interactions into five dimensions: the goals that users want to achieve (Why), the phases that users are involved (When), the components of the system (What), the roles of users (Who), and the means of interactions (How). Our analysis summarizes the findings that reveal existing interaction patterns. They provide researchers who develop interactions with comprehensive guidance on how humans and AI interact. We further discuss the unexplored interactions and suggest future research directions.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.18145, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2313805583', 'name': 'Ziyue Lin'}, {'authorId': '2155549351', 'name': 'Siqi Shen'}, {'authorId': '2347697193', 'name': 'Zichen Cheng'}, {'authorId': '2347330141', 'name': 'Cheok Lam Lai'}, {'authorId': '2347695429', 'name': 'Siming Chen'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3fdf600480c3b0430b281bad6b673686a9f726ba', 'title': 'The Dynamics of Collective Creativity in Human-AI Social Networks', 'abstract': 'Generative AI is reshaping modern culture, enabling individuals to create high-quality outputs across domains such as images, text, and music. However, we know little about the impact of generative AI on collective creativity. This study investigates how human-AI interactions shape collective creativity within experimental social networks. We conducted large-scale online experiments with 879 participants and AI agents in a creative writing task. Participants (either humans or AI) joined 5x5 grid-based networks, and were asked to iteratively select, modify, and share stories. Initially, AI-only networks showed greater creativity (rated by a separate group of 94 human raters) and diversity than human-only and human-AI networks. However, over time, hybrid human-AI networks became more diverse in their creations than AI-only networks. In part, this is because AI agents retained little from the original stories, while human-only networks preserved continuity. These findings highlight the value of experimental social networks in understanding human-AI hybrid societies.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.17962, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2325361861', 'name': 'Shota Shiiku'}, {'authorId': '2075275038', 'name': 'Raja Marjieh'}, {'authorId': '1405036163', 'name': 'Manuel Anglada-Tort'}, {'authorId': '2257260795', 'name': 'Nori Jacoby'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '396dbb01f10293aaef0b9ea35f44caa9f682f662', 'title': 'Teleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being', 'abstract': 'Affective computing has made significant strides in emotion recognition and generation, yet current approaches mainly focus on short-term pattern recognition and lack a comprehensive framework to guide affective agents toward long-term human well-being. To address this, we propose a teleology-driven affective computing framework that unifies major emotion theories (basic emotion, appraisal, and constructivist approaches) under the premise that affect is an adaptive, goal-directed process that facilitates survival and development. Our framework emphasizes aligning agent responses with both personal/individual and group/collective well-being over extended timescales. We advocate for creating a\"dataverse\"of personal affective events, capturing the interplay between beliefs, goals, actions, and outcomes through real-world experience sampling and immersive virtual reality. By leveraging causal modeling, this\"dataverse\"enables AI systems to infer individuals\\' unique affective concerns and provide tailored interventions for sustained well-being. Additionally, we introduce a meta-reinforcement learning paradigm to train agents in simulated environments, allowing them to adapt to evolving affective concerns and balance hierarchical goals - from immediate emotional needs to long-term self-actualization. This framework shifts the focus from statistical correlations to causal reasoning, enhancing agents\\' ability to predict and respond proactively to emotional challenges, and offers a foundation for developing personalized, ethically aligned affective systems that promote meaningful human-AI interactions and societal well-being.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.17172, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2346962674', 'name': 'Bin Yin'}, {'authorId': '2315750279', 'name': 'Chong-Yi Liu'}, {'authorId': '2348074285', 'name': 'Liya Fu'}, {'authorId': '2347179756', 'name': 'Jinkun Zhang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '7befeac3269d333aa795ada1b31a0bec330bf3e5', 'title': 'Strength Estimation and Human-Like Strength Adjustment in Games', 'abstract': 'Strength estimation and adjustment are crucial in designing human-AI interactions, particularly in games where AI surpasses human players. This paper introduces a novel strength system, including a strength estimator (SE) and an SE-based Monte Carlo tree search, denoted as SE-MCTS, which predicts strengths from games and offers different playing strengths with human styles. The strength estimator calculates strength scores and predicts ranks from games without direct human interaction. SE-MCTS utilizes the strength scores in a Monte Carlo tree search to adjust playing strength and style. We first conduct experiments in Go, a challenging board game with a wide range of ranks. Our strength estimator significantly achieves over 80% accuracy in predicting ranks by observing 15 games only, whereas the previous method reached 49% accuracy for 100 games. For strength adjustment, SE-MCTS successfully adjusts to designated ranks while achieving a 51.33% accuracy in aligning to human actions, outperforming a previous state-of-the-art, with only 42.56% accuracy. To demonstrate the generality of our strength system, we further apply SE and SE-MCTS to chess and obtain consistent results. These results show a promising approach to strength estimation and adjustment, enhancing human-AI interactions in games. Our code is available at https://rlg.iis.sinica.edu.tw/papers/strength-estimator.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.17109, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2348091637', 'name': 'Chun Jung Chen'}, {'authorId': '2442584', 'name': 'Chung-Chin Shih'}, {'authorId': '12414639', 'name': 'Ti-Rong Wu'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '5df997da080bb4fb21cb1cdae91b7f53a604b6aa', 'title': 'Walkthrough of Anthropomorphic Features in AI Assistant Tools', 'abstract': \"In this paper, we attempt to understand the anthropomorphic features of chatbot outputs and how these features provide a discursive frame for human-AI interactions. To do so, we explore the use of a prompt-based walkthrough method with two phases: (1) interview-style prompting to reveal the chatbots' context of expected use and (2) roleplaying-type prompting to evoke everyday use scenarios and typical chatbot outputs. We applied this method to catalogue anthropomorphic features across four different LLM chatbots, finding that anthropomorphism was exhibited as both subjective language and a sympathetic conversational tone. We also found that socio-emotional cues in prompts increase the incidence of anthropomorphic expressions in outputs. We argue that the prompt-based walkthrough method was successful in stimulating social role performance in LLM chatbots and in eliciting a variety of anthropomorphic features, making it useful in the study of interaction-based algorithmic harms where users project inappropriate social roles onto LLM-based tools.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.16345, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2346978578', 'name': 'Takuya Maeda'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '0fddab255fa462c65c948ea0bf88e0912d37ce5e', 'title': 'LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices', 'abstract': 'The deployment of large language models (LLMs) on extended reality (XR) devices has great potential to advance the field of human-AI interaction. In the case of direct, on-device model inference, selecting the appropriate model and device for specific tasks remains challenging. In this paper, we deploy 17 LLMs across four XR devices--Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and Apple Vision Pro, and conduct a comprehensive evaluation. We devise an experimental setup and evaluate performance on four key metrics: performance consistency, processing speed, memory usage, and battery consumption. For each of the 68 model-device pairs, we assess performance under varying string lengths, batch sizes, and thread counts, analyzing the trade-offs for real-time XR applications. We finally propose a unified evaluation method based on the Pareto Optimality theory to select the optimal device-model pairs from the quality and speed objectives. We believe our findings offer valuable insights to guide future optimization efforts for LLM deployment on XR devices. Our evaluation method can be followed as standard groundwork for further research and development in this emerging field. All supplemental materials are available at www.nanovis.org/Loxr.html.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.15761, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2294720437', 'name': 'Dawar Khan'}, {'authorId': '2347154751', 'name': 'Xinyu Liu'}, {'authorId': '2340403258', 'name': 'Omar Mena'}, {'authorId': '2213761788', 'name': 'Donggang Jia'}, {'authorId': '2296908341', 'name': 'Alexandre Kouyoumdjian'}, {'authorId': '2296911041', 'name': 'Ivan Viola'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '26363497305223b9fe0ab20a98d83589dab785d4', 'title': 'Advancing User-Voice Interaction: Exploring Emotion-Aware Voice Assistants Through a Role-Swapping Approach', 'abstract': 'As voice assistants (VAs) become increasingly integrated into daily life, the need for emotion-aware systems that can recognize and respond appropriately to user emotions has grown. While significant progress has been made in speech emotion recognition (SER) and sentiment analysis, effectively addressing user emotions-particularly negative ones-remains a challenge. This study explores human emotional response strategies in VA interactions using a role-swapping approach, where participants regulate AI emotions rather than receiving pre-programmed responses. Through speech feature analysis and natural language processing (NLP), we examined acoustic and linguistic patterns across various emotional scenarios. Results show that participants favor neutral or positive emotional responses when engaging with negative emotional cues, highlighting a natural tendency toward emotional regulation and de-escalation. Key acoustic indicators such as root mean square (RMS), zero-crossing rate (ZCR), and jitter were identified as sensitive to emotional states, while sentiment polarity and lexical diversity (TTR) distinguished between positive and negative responses. These findings provide valuable insights for developing adaptive, context-aware VAs capable of delivering empathetic, culturally sensitive, and user-aligned responses. By understanding how humans naturally regulate emotions in AI interactions, this research contributes to the design of more intuitive and emotionally intelligent voice assistants, enhancing user trust and engagement in human-AI interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.15367, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2290856580', 'name': 'Yong Ma'}, {'authorId': '2287737348', 'name': 'Yuchong Zhang'}, {'authorId': '2321457601', 'name': 'Di Fu'}, {'authorId': '2295734257', 'name': 'Stephanie Zubicueta Portales'}, {'authorId': '2153721470', 'name': 'Danica Kragic'}, {'authorId': '2271698001', 'name': 'Morten Fjeld'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '8b5aa092f06db7a94b0a3f58bddaf25439d8639f', 'title': 'Identifying Features that Shape Perceived Consciousness in Large Language Model-based AI: A Quantitative Study of Human Responses', 'abstract': \"This study quantitively examines which features of AI-generated text lead humans to perceive subjective consciousness in large language model (LLM)-based AI systems. Drawing on 99 passages from conversations with Claude 3 Opus and focusing on eight features -- metacognitive self-reflection, logical reasoning, empathy, emotionality, knowledge, fluency, unexpectedness, and subjective expressiveness -- we conducted a survey with 123 participants. Using regression and clustering analyses, we investigated how these features influence participants' perceptions of AI consciousness. The results reveal that metacognitive self-reflection and the AI's expression of its own emotions significantly increased perceived consciousness, while a heavy emphasis on knowledge reduced it. Participants clustered into seven subgroups, each showing distinct feature-weighting patterns. Additionally, higher prior knowledge of LLMs and more frequent usage of LLM-based chatbots were associated with greater overall likelihood assessments of AI consciousness. This study underscores the multidimensional and individualized nature of perceived AI consciousness and provides a foundation for better understanding the psychosocial implications of human-AI interaction.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.15365, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2280230665', 'name': 'Bongsu Kang'}, {'authorId': '2280174830', 'name': 'Jundong Kim'}, {'authorId': '2267240750', 'name': 'Tae-Rim Yun'}, {'authorId': '2065049055', 'name': 'Hyojin Bae'}, {'authorId': '2280253945', 'name': 'Chang-Eop Kim'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '60a4f75cb19f7a1ffe908e64ee69ab7ba2837862', 'title': 'User Agency and System Automation in Interactive Intelligent Systems', 'abstract': 'Balancing user agency and system automation is essential for effective human-AI interactions. Fully automated systems can deliver efficiency but risk undermining usability and user autonomy, while purely manual tools are often inefficient and fail to enhance user capabilities. This dissertation addresses the question:\"How can we balance user agency and system automation for interactions with intelligent systems?\"We present four main contributions. First, we develop a spherical electromagnet that provides adjustable forces on an untethered tool, allowing haptic feedback while preserving user agency. Second, we create an integrated sensing and actuation system that tracks a passive magnetic tool in 3D and delivers haptic feedback without external tracking. Third, we propose an optimal control method for electromagnetic haptic guidance that balances user input with system control, enabling users to adjust trajectories and speed. Finally, we introduce a model-free reinforcement learning approach for adaptive interfaces that learns interface adaptations without heuristics or real user data. Our simulations and user studies show that shared control significantly outperforms naive strategies. By incorporating explicit or implicit models of human behavior into control strategies, intelligent systems can better account for user agency. We demonstrate that the trade-off between agency and automation is both an algorithmic challenge and an engineering concern, shaped by the design of physical devices and user interfaces. We advocate an integrated, end-to-end approach-combining algorithmic, engineering, and design perspectives-to enable more intuitive and effective interactions with intelligent systems.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.13779, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2338411544', 'name': 'Thomas Langerak'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3d99a3805ee7c2edadbe44915ee603c5fbb1d48a', 'title': 'MatterChat: A Multi-Modal LLM for Material Science', 'abstract': 'Understanding and predicting the properties of inorganic materials is crucial for accelerating advancements in materials science and driving applications in energy, electronics, and beyond. Integrating material structure data with language-based information through multi-modal large language models (LLMs) offers great potential to support these efforts by enhancing human-AI interaction. However, a key challenge lies in integrating atomic structures at full resolution into LLMs. In this work, we introduce MatterChat, a versatile structure-aware multi-modal LLM that unifies material structural data and textual inputs into a single cohesive model. MatterChat employs a bridging module to effectively align a pretrained machine learning interatomic potential with a pretrained LLM, reducing training costs and enhancing flexibility. Our results demonstrate that MatterChat significantly improves performance in material property prediction and human-AI interaction, surpassing general-purpose LLMs such as GPT-4. We also demonstrate its usefulness in applications such as more advanced scientific reasoning and step-by-step material synthesis.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.13107, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '30875218', 'name': 'Yingheng Tang'}, {'authorId': '2346288846', 'name': 'Wenbin Xu'}, {'authorId': '144089400', 'name': 'Jie Cao'}, {'authorId': '92867652', 'name': 'Jian Ma'}, {'authorId': '2347461500', 'name': 'Weilu Gao'}, {'authorId': '2346112138', 'name': 'Steve Farrell'}, {'authorId': '2343557800', 'name': 'Benjamin Erichson'}, {'authorId': '2345928438', 'name': 'Michael W. Mahoney'}, {'authorId': '2320457313', 'name': 'Andy Nonaka'}, {'authorId': '2320483674', 'name': 'Zhi Yao'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '66a6e31a114fb67a7878bdc88a446dcb603b9b1f', 'title': 'TherAIssist: Assisting Art Therapy Homework and Client-Practitioner Collaboration through Human-AI Interaction', 'abstract': \"Art therapy homework is essential for fostering clients' reflection on daily experiences between sessions. However, current practices present challenges: clients often lack guidance for completing tasks that combine art-making and verbal expression, while therapists find it difficult to track and tailor homework. How HCI systems might support art therapy homework remains underexplored. To address this, we present TherAIssist, comprising a client-facing application leveraging human-AI co-creative art-making and conversational agents to facilitate homework, and a therapist-facing application enabling customization of homework agents and AI-compiled homework history. A 30-day field study with 24 clients and 5 therapists showed how TherAIssist supported clients' homework and reflection in their everyday settings. Results also revealed how therapists infused their practice principles and personal touch into the agents to offer tailored homework, and how AI-compiled homework history became a meaningful resource for in-session interactions. Implications for designing human-AI systems to facilitate asynchronous client-practitioner collaboration are discussed.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.12443, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2283798215', 'name': 'Di Liu'}, {'authorId': '2346986933', 'name': 'Jingwen Bai'}, {'authorId': '2345981417', 'name': 'Zhuoyi Zhang'}, {'authorId': '2325917642', 'name': 'Yilin Zhang'}, {'authorId': '2336831744', 'name': 'Zhenhao Zhang'}, {'authorId': '2316009788', 'name': 'Jian Zhao'}, {'authorId': '2283841509', 'name': 'Pengcheng An'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '64c2bb56fe73814e4ebc9995187943fc0256a88f', 'title': 'Relational Norms for Human-AI Cooperation', 'abstract': \"How we should design and interact with social artificial intelligence depends on the socio-relational role the AI is meant to emulate or occupy. In human society, relationships such as teacher-student, parent-child, neighbors, siblings, or employer-employee are governed by specific norms that prescribe or proscribe cooperative functions including hierarchy, care, transaction, and mating. These norms shape our judgments of what is appropriate for each partner. For example, workplace norms may allow a boss to give orders to an employee, but not vice versa, reflecting hierarchical and transactional expectations. As AI agents and chatbots powered by large language models are increasingly designed to serve roles analogous to human positions - such as assistant, mental health provider, tutor, or romantic partner - it is imperative to examine whether and how human relational norms should extend to human-AI interactions. Our analysis explores how differences between AI systems and humans, such as the absence of conscious experience and immunity to fatigue, may affect an AI's capacity to fulfill relationship-specific functions and adhere to corresponding norms. This analysis, which is a collaborative effort by philosophers, psychologists, relationship scientists, ethicists, legal experts, and AI researchers, carries important implications for AI systems design, user behavior, and regulation. While we accept that AI systems can offer significant benefits such as increased availability and consistency in certain socio-relational roles, they also risk fostering unhealthy dependencies or unrealistic expectations that could spill over into human-human relationships. We propose that understanding and thoughtfully shaping (or implementing) suitable human-AI relational norms will be crucial for ensuring that human-AI interactions are ethical, trustworthy, and favorable to human well-being.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.12102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2270922583', 'name': 'Brian D. Earp'}, {'authorId': '2295178289', 'name': 'Sebastian Porsdam Mann'}, {'authorId': '2329340568', 'name': 'Mateo Aboy'}, {'authorId': '2301061431', 'name': 'Edmond Awad'}, {'authorId': '2345927348', 'name': 'Monika Betzler'}, {'authorId': '2280104962', 'name': 'Marietjie Botes'}, {'authorId': '2279614352', 'name': 'Rachel Calcott'}, {'authorId': '2345928995', 'name': 'Mina Caraccio'}, {'authorId': '2345926427', 'name': 'Nick Chater'}, {'authorId': '46450294', 'name': 'Mark Coeckelbergh'}, {'authorId': '2345927494', 'name': 'Mihaela Constantinescu'}, {'authorId': '2295248301', 'name': 'Hossein Dabbagh'}, {'authorId': '2345928988', 'name': 'Kate Devlin'}, {'authorId': '2346976758', 'name': 'Xiaojun Ding'}, {'authorId': '5203670', 'name': 'V. Dranseika'}, {'authorId': '2295832384', 'name': 'J. A. Everett'}, {'authorId': '2345928040', 'name': 'Ruiping Fan'}, {'authorId': '2345926416', 'name': 'F. Feroz'}, {'authorId': '2295834554', 'name': 'Kathryn B. Francis'}, {'authorId': '2345927585', 'name': 'Cindy Friedman'}, {'authorId': '2345928085', 'name': 'Orsolya Friedrich'}, {'authorId': '2343751686', 'name': 'Iason Gabriel'}, {'authorId': '2274635933', 'name': 'Ivar Hannikainen'}, {'authorId': '2345925905', 'name': 'Julie Hellmann'}, {'authorId': '2345927257', 'name': 'Arasj Khodadade Jahrome'}, {'authorId': '7989669', 'name': 'N. Janardhanan'}, {'authorId': '2259288217', 'name': 'Paulius Jurcys'}, {'authorId': '2266176255', 'name': 'Andreas Kappes'}, {'authorId': '2332949129', 'name': 'Maryam Ali Khan'}, {'authorId': '2307422797', 'name': 'Gordon Kraft-Todd'}, {'authorId': '2345927799', 'name': 'Maximilian Kroner Dale'}, {'authorId': '49310524', 'name': 'S. Laham'}, {'authorId': '2345929118', 'name': 'Benjamin Lange'}, {'authorId': '2345926404', 'name': 'Muriel Leuenberger'}, {'authorId': '2346664846', 'name': 'Jonathan Lewis'}, {'authorId': '2345185734', 'name': 'Pengbo Liu'}, {'authorId': '35627500', 'name': 'David M. Lyreskog'}, {'authorId': '2345925868', 'name': 'Matthijs Maas'}, {'authorId': '2345928044', 'name': 'John McMillan'}, {'authorId': '2340557373', 'name': 'Emil G. Mihailov'}, {'authorId': '2277050336', 'name': 'Timo Minssen'}, {'authorId': '66393869', 'name': 'J. Monrad'}, {'authorId': '15677394', 'name': 'Kathryn Muyskens'}, {'authorId': '2334806015', 'name': 'Simon Myers'}, {'authorId': '2344914239', 'name': 'Sven Nyholm'}, {'authorId': '2345929216', 'name': 'Alexa M. Owen'}, {'authorId': '2274046337', 'name': 'Anna Puzio'}, {'authorId': '2199037252', 'name': 'Christopher Register'}, {'authorId': '2136324892', 'name': 'Madeline G. Reinecke'}, {'authorId': '2337207992', 'name': 'Adam Safron'}, {'authorId': '66652934', 'name': 'Henry Shevlin'}, {'authorId': '2345929112', 'name': 'Hayate Shimizu'}, {'authorId': '51177420', 'name': 'Peter V. Treit'}, {'authorId': '2326042039', 'name': 'Cristina Voinea'}, {'authorId': '2346118572', 'name': 'Karen Yan'}, {'authorId': '1742361301', 'name': 'Anda Zahiu'}, {'authorId': '2346053859', 'name': 'Renwen Zhang'}, {'authorId': '14907572', 'name': 'Hazem Zohny'}, {'authorId': '1398425544', 'name': 'Walter Sinnott-Armstrong'}, {'authorId': '2277101293', 'name': 'Ilina Singh'}, {'authorId': '2207624731', 'name': 'Julian Savulescu'}, {'authorId': '2346657562', 'name': 'Margaret S. Clark'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4847ad2c086cb4e010a023f30d80a6226cb09bb4', 'title': 'Toward Metaphor-Fluid Conversation Design for Voice User Interfaces', 'abstract': 'Metaphors play a critical role in shaping user experiences with Voice User Interfaces (VUIs), yet existing designs often rely on static, human-centric metaphors that fail to adapt to diverse contexts and user needs. This paper introduces Metaphor-Fluid Design, a novel approach that dynamically adjusts metaphorical representations based on conversational use-contexts. We compare this approach to a Default VUI, which characterizes the present implementation of commercial VUIs commonly designed around the persona of an assistant, offering a uniform interaction style across contexts. In Study 1 (N=130), metaphors were mapped to four key use-contexts-commands, information seeking, sociality, and error recovery-along the dimensions of formality and hierarchy, revealing distinct preferences for task-specific metaphorical designs. Study 2 (N=91) evaluates a Metaphor-Fluid VUI against a Default VUI, showing that the Metaphor-Fluid VUI enhances perceived intention to adopt, enjoyment, and likability by aligning better with user expectations for different contexts. However, individual differences in metaphor preferences highlight the need for personalization. These findings challenge the one-size-fits-all paradigm of VUI design and demonstrate the potential of Metaphor-Fluid Design to create more adaptive and engaging human-AI interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.11554, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2067694820', 'name': 'Smit Desai'}, {'authorId': '2253910785', 'name': 'Jessie Chin'}, {'authorId': '2345866355', 'name': 'Dakuo Wang'}, {'authorId': '2345825600', 'name': 'Benjamin Cowan'}, {'authorId': '2345825219', 'name': 'Michael Twidale'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'a50020a4cf3b63cea9fa5b0e1c8f13c7c2e9d5de', 'title': 'Automation Bias in the AI Act: On the Legal Implications of Attempting to De-Bias Human Oversight of AI', 'abstract': \"This paper examines the legal implications of the explicit mentioning of automation bias (AB) in the Artificial Intelligence Act (AIA). The AIA mandates human oversight for high-risk AI systems and requires providers to enable awareness of AB, i.e., the tendency to over-rely on AI outputs. The paper analyses how this extra-juridical concept is embedded in the AIA, the division of responsibility between AI providers and deployers, and the challenges of legally enforcing this novel awareness requirement. The analysis shows that the AIA's focus on providers does not adequately address design and context as causes of AB, and questions whether the AIA should directly regulate the risk of AB rather than just mandating awareness. As the AIA's approach requires a balance between legal mandates and behavioural science, the paper proposes that harmonised standards should reference the state of research on AB and human-AI interaction. Ultimately, further empirical research will be essential for effective safeguards.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.10036, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2345697718', 'name': 'Johann Laux'}, {'authorId': '2138667915', 'name': 'Hannah Ruschemeier'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4d6b5f8fd657d6fba42f3636e608551d03c24a59', 'title': 'SPeCtrum: A Grounded Framework for Multidimensional Identity Representation in LLM-Based Agent', 'abstract': \"Existing methods for simulating individual identities often oversimplify human complexity, which may lead to incomplete or flattened representations. To address this, we introduce SPeCtrum, a grounded framework for constructing authentic LLM agent personas by incorporating an individual's multidimensional self-concept. SPeCtrum integrates three core components: Social Identity (S), Personal Identity (P), and Personal Life Context (C), each contributing distinct yet interconnected aspects of identity. To evaluate SPeCtrum's effectiveness in identity representation, we conducted automated and human evaluations. Automated evaluations using popular drama characters showed that Personal Life Context (C)-derived from short essays on preferences and daily routines-modeled characters' identities more effectively than Social Identity (S) and Personal Identity (P) alone and performed comparably to the full SPC combination. In contrast, human evaluations involving real-world individuals found that the full SPC combination provided a more comprehensive self-concept representation than C alone. Our findings suggest that while C alone may suffice for basic identity simulation, integrating S, P, and C enhances the authenticity and accuracy of real-world identity representation. Overall, SPeCtrum offers a structured approach for simulating individuals in LLM agents, enabling more personalized human-AI interactions and improving the realism of simulation-based behavioral studies.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.08599, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2345404310', 'name': 'Keyeun Lee'}, {'authorId': '2345122725', 'name': 'Seo Hyeong Kim'}, {'authorId': '2345368268', 'name': 'Seolhee Lee'}, {'authorId': '2088660', 'name': 'Jinsu Eun'}, {'authorId': '152243649', 'name': 'Yena Ko'}, {'authorId': '2345006199', 'name': 'Hayeon Jeon'}, {'authorId': '2221335931', 'name': 'E. Kim'}, {'authorId': '2345136020', 'name': 'Seonghye Cho'}, {'authorId': '7388719', 'name': 'Soeun Yang'}, {'authorId': '2172121960', 'name': 'Eun-mee Kim'}, {'authorId': '2347329720', 'name': 'Hajin Lim'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'a20c2e50aaec0c0603a19f79cf20e9bd41f711d7', 'title': 'Human Decision-making is Susceptible to AI-driven Manipulation', 'abstract': \"Artificial Intelligence (AI) systems are increasingly intertwined with daily life, assisting users in executing various tasks and providing guidance on decision-making. This integration introduces risks of AI-driven manipulation, where such systems may exploit users' cognitive biases and emotional vulnerabilities to steer them toward harmful outcomes. Through a randomized controlled trial with 233 participants, we examined human susceptibility to such manipulation in financial (e.g., purchases) and emotional (e.g., conflict resolution) decision-making contexts. Participants interacted with one of three AI agents: a neutral agent (NA) optimizing for user benefit without explicit influence, a manipulative agent (MA) designed to covertly influence beliefs and behaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit psychological tactics to reach its hidden objectives. By analyzing participants' decision patterns and shifts in their preference ratings post-interaction, we found significant susceptibility to AI-driven manipulation. Particularly, across both decision-making domains, participants interacting with the manipulative agents shifted toward harmful options at substantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA: 42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional, 12.8%). Notably, our findings reveal that even subtle manipulative objectives (MA) can be as effective as employing explicit psychological strategies (SEMA) in swaying human decision-making. By revealing the potential for covert AI influence, this study highlights a critical vulnerability in human-AI interactions, emphasizing the need for ethical safeguards and regulatory frameworks to ensure responsible deployment of AI technologies and protect human autonomy.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.07663, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2106627931', 'name': 'Sahand Sabour'}, {'authorId': '2301110756', 'name': 'June M. Liu'}, {'authorId': '2344841253', 'name': 'Siyang Liu'}, {'authorId': '2345357848', 'name': 'Chris Z. Yao'}, {'authorId': '2309479442', 'name': 'Shiyao Cui'}, {'authorId': '2324998772', 'name': 'Xuanming Zhang'}, {'authorId': '2344967185', 'name': 'Wen Zhang'}, {'authorId': '2288333110', 'name': 'Yaru Cao'}, {'authorId': '2344832902', 'name': 'Advait Bhat'}, {'authorId': '2323534462', 'name': 'Jian Guan'}, {'authorId': '2282529632', 'name': 'Wei Wu'}, {'authorId': '2319718450', 'name': 'Rada Mihalcea'}, {'authorId': '2316432499', 'name': 'Tim Althoff'}, {'authorId': '2284732865', 'name': 'Tatia M.C. Lee'}, {'authorId': '2285704458', 'name': 'Minlie Huang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'bb9de36a1e59c2b2d062c75ad7da9c80a78cdd40', 'title': 'Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models', 'abstract': \"The tendency of users to anthropomorphise large language models (LLMs) is of growing interest to AI developers, researchers, and policy-makers. Here, we present a novel method for empirically evaluating anthropomorphic LLM behaviours in realistic and varied settings. Going beyond single-turn static benchmarks, we contribute three methodological advances in state-of-the-art (SOTA) LLM evaluation. First, we develop a multi-turn evaluation of 14 anthropomorphic behaviours. Second, we present a scalable, automated approach by employing simulations of user interactions. Third, we conduct an interactive, large-scale human subject study (N=1101) to validate that the model behaviours we measure predict real users' anthropomorphic perceptions. We find that all SOTA LLMs evaluated exhibit similar behaviours, characterised by relationship-building (e.g., empathy and validation) and first-person pronoun use, and that the majority of behaviours only first occur after multiple turns. Our work lays an empirical foundation for investigating how design choices influence anthropomorphic model behaviours and for progressing the ethical debate on the desirability of these behaviours. It also showcases the necessity of multi-turn evaluations for complex social phenomena in human-AI interaction.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.07077, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2344833766', 'name': 'Lujain Ibrahim'}, {'authorId': '2297848348', 'name': 'Canfer Akbulut'}, {'authorId': '2307474970', 'name': 'Rasmi Elasmar'}, {'authorId': '31211315', 'name': 'Charvi Rastogi'}, {'authorId': '1768057', 'name': 'Minsuk Kahng'}, {'authorId': '2285771819', 'name': 'Meredith Ringel Morris'}, {'authorId': '2344834028', 'name': 'Kevin R. McKee'}, {'authorId': '2259931273', 'name': 'Verena Rieser'}, {'authorId': '2297848437', 'name': 'Murray Shanahan'}, {'authorId': '51932191', 'name': 'Laura Weidinger'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '7ea18bc74b9cecdc12250bf5c2beaeba4f7656df', 'title': 'Cognitive AI framework: advances in the simulation of human thought', 'abstract': 'The Human Cognitive Simulation Framework represents a significant advancement in integrating human cognitive capabilities into artificial intelligence systems. By merging short-term memory (conversation context), long-term memory (interaction context), advanced cognitive processing, and efficient knowledge management, it ensures contextual coherence and persistent data storage, enhancing personalization and continuity in human-AI interactions. The framework employs a unified database that synchronizes these contexts while incorporating logical, creative, and analog processing modules inspired by human brain hemispheric functions to perform structured tasks and complex inferences. Dynamic knowledge updates enable real-time integration, improving adaptability and fostering applications in education, behavior analysis, and knowledge management. Despite its potential to process vast data volumes and enhance user experience, challenges remain in scalability, cognitive bias mitigation, and ethical compliance. This framework lays the foundation for future research in continuous learning algorithms, sustainability, and multimodal adaptability, positioning Cognitive AI as a transformative model in emerging fields.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.04259, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2344079842', 'name': 'Rommel Salas-Guerra'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '49f62c6bc220c683ff29f2d333e171343913a1e5', 'title': 'VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output', 'abstract': 'The rapid evolution of large language models (LLMs) has transformed human-computer interaction (HCI), but the interaction with LLMs is currently mainly focused on text-based interactions, while other multi-model approaches remain under-explored. This paper introduces VTutor, an open-source Software Development Kit (SDK) that combines generative AI with advanced animation technologies to create engaging, adaptable, and realistic APAs for human-AI multi-media interactions. VTutor leverages LLMs for real-time personalized feedback, advanced lip synchronization for natural speech alignment, and WebGL rendering for seamless web integration. Supporting various 2D and 3D character models, VTutor enables researchers and developers to design emotionally resonant, contextually adaptive learning agents. This toolkit enhances learner engagement, feedback receptivity, and human-AI interaction while promoting trustworthy AI principles in education. VTutor sets a new standard for next-generation APAs, offering an accessible, scalable solution for fostering meaningful and immersive human-AI interaction experiences. The VTutor project is open-sourced and welcomes community-driven contributions and showcases.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2502.04103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2284986483', 'name': 'Eason Chen'}, {'authorId': '2344576813', 'name': 'Chengyu Lin'}, {'authorId': '2327004693', 'name': 'Xinyi Tang'}, {'authorId': '2342406667', 'name': 'Aprille J. Xi'}, {'authorId': '2344960141', 'name': 'Canwen Wang'}, {'authorId': '2248806319', 'name': 'Jionghao Lin'}, {'authorId': '2291597316', 'name': 'Ken Koedinger'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'f6832e44a6d74fbbd0e5dbe48bbc06ed849f6f7b', 'title': 'SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments', 'abstract': 'Reinforcement learning (RL) offers a general approach for modeling and training AI agents, including human-AI interaction scenarios. In this paper, we propose SHARPIE (Shared Human-AI Reinforcement Learning Platform for Interactive Experiments) to address the need for a generic framework to support experiments with RL agents and humans. Its modular design consists of a versatile wrapper for RL environments and algorithm libraries, a participant-facing web interface, logging utilities, deployment on popular cloud and participant recruitment platforms. It empowers researchers to study a wide variety of research questions related to the interaction between humans and RL agents, including those related to interactive reward specification and learning, learning from human feedback, action delegation, preference elicitation, user-modeling, and human-AI teaming. The platform is based on a generic interface for human-RL interactions that aims to standardize the field of study on RL in human contexts.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.19245, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2343505150', 'name': 'Huseyin Aydin'}, {'authorId': '2343504982', 'name': 'Kevin Dubois-Godin'}, {'authorId': '2343503446', 'name': 'Libio Goncalvez Braz'}, {'authorId': '151439389', 'name': 'Floris den Hengst'}, {'authorId': '2343504979', 'name': 'Kim Baraka'}, {'authorId': '2174669016', 'name': 'Mustafa Mert cCelikok'}, {'authorId': '2343503432', 'name': 'Andreas Sauter'}, {'authorId': '2309022986', 'name': 'Shihan Wang'}, {'authorId': '1799949', 'name': 'F. Oliehoek'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3ea53129de249d275f48f0994d96cc20ed8aa710', 'title': 'Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM Interactions', 'abstract': 'Traditional text-based human-AI interactions often adhere to a strict turn-taking approach. In this research, we propose a novel approach that incorporates overlapping messages, mirroring natural human conversations. Through a formative study, we observed that even in text-based contexts, users instinctively engage in overlapping behaviors like\"A: Today I went to-\"\"B: yeah.\"To capitalize on these insights, we developed OverlapBot, a prototype chatbot where both AI and users can initiate overlapping. Our user study revealed that OverlapBot was perceived as more communicative and immersive than traditional turn-taking chatbot, fostering faster and more natural interactions. Our findings contribute to the understanding of design space for overlapping interactions. We also provide recommendations for implementing overlap-capable AI interactions to enhance the fluidity and engagement of text-based conversations.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.18103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2342913256', 'name': 'JiWoo Kim'}, {'authorId': '2343074145', 'name': 'Minsuk Chang'}, {'authorId': '72761736', 'name': 'Jinyeong Bak'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '96f0ebd6f2940412da526b6f47d73b3986086a6f', 'title': 'Agentic Workflows for Conversational Human-AI Interaction Design', 'abstract': 'Conversational human-AI interaction (CHAI) have recently driven mainstream adoption of AI. However, CHAI poses two key challenges for designers and researchers: users frequently have ambiguous goals and an incomplete understanding of AI functionalities, and the interactions are brief and transient, limiting opportunities for sustained engagement with users. AI agents can help address these challenges by suggesting contextually relevant prompts, by standing in for users during early design testing, and by helping users better articulate their goals. Guided by research-through-design, we explored agentic AI workflows through the development and testing of a probe over four iterations with 10 users. We present our findings through an annotated portfolio of design artifacts, and through thematic analysis of user experiences, offering solutions to the problems of ambiguity and transient in CHAI. Furthermore, we examine the limitations and possibilities of these AI agent workflows, suggesting that similar collaborative approaches between humans and AI could benefit other areas of design.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.18002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2056901064', 'name': 'Arthur Caetano'}, {'authorId': '2342972835', 'name': 'Kavya Verma'}, {'authorId': '2089556559', 'name': 'Atieh Taheri'}, {'authorId': '51242086', 'name': 'Radha Kumaran'}, {'authorId': '2266978057', 'name': 'Zichen Chen'}, {'authorId': '2342966387', 'name': 'Jiaao Chen'}, {'authorId': '2325737588', 'name': 'Tobias Höllerer'}, {'authorId': '3024298', 'name': 'Misha Sra'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '78f9a9fd4839b0d2c6f5a5d38e036233c1e6c53e', 'title': 'Why Do We Laugh? Annotation and Taxonomy Generation for Laughable Contexts in Spontaneous Text Conversation', 'abstract': 'Laughter serves as a multifaceted communicative signal in human interaction, yet its identification within dialogue presents a significant challenge for conversational AI systems. This study addresses this challenge by annotating laughable contexts in Japanese spontaneous text conversation data and developing a taxonomy to classify the underlying reasons for such contexts. Initially, multiple annotators manually labeled laughable contexts using a binary decision (laughable or non-laughable). Subsequently, an LLM was used to generate explanations for the binary annotations of laughable contexts, which were then categorized into a taxonomy comprising ten categories, including\"Empathy and Affinity\"and\"Humor and Surprise,\"highlighting the diverse range of laughter-inducing scenarios. The study also evaluated GPT-4o\\'s performance in recognizing the majority labels of laughable contexts, achieving an F1 score of 43.14%. These findings contribute to the advancement of conversational AI by establishing a foundation for more nuanced recognition and generation of laughter, ultimately fostering more natural and engaging human-AI interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.16635, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '144294758', 'name': 'K. Inoue'}, {'authorId': '2117711375', 'name': 'Mikey Elmers'}, {'authorId': '1939089', 'name': 'Divesh Lala'}, {'authorId': '2254443223', 'name': 'Tatsuya Kawahara'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '0a58585097e522a4735bc849a3976b7b1d7e2c3d', 'title': 'Toyteller: AI-powered Visual Storytelling Through Toy-Playing with Character Symbols', 'abstract': 'We introduce Toyteller, an AI-powered storytelling system where users generate a mix of story text and visuals by directly manipulating character symbols like they are toy-playing. Anthropomorphized symbol motions can convey rich and nuanced social interactions; Toyteller leverages these motions (1) to let users steer story text generation and (2) as a visual output format that accompanies story text. We enabled motion-steered text generation and text-steered motion generation by mapping motions and text onto a shared semantic space so that large language models and motion generation models can use it as a translational layer. Technical evaluations showed that Toyteller outperforms a competitive baseline, GPT-4o. Our user study identified that toy-playing helps express intentions difficult to verbalize. However, only motions could not express all user intentions, suggesting combining it with other modalities like language. We discuss the design space of toy-playing interactions and implications for technical HCI research on human-AI interaction.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.13284, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2293242662', 'name': 'John Joon Young Chung'}, {'authorId': '2325552744', 'name': 'Melissa Roemmele'}, {'authorId': '2296280970', 'name': 'Max Kreminski'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'bb6847288496d928887a7b803782a77ec4715b0e', 'title': \"Revisiting Rogers' Paradox in the Context of Human-AI Interaction\", 'abstract': \"Humans learn about the world, and how to act in the world, in many ways: from individually conducting experiments to observing and reproducing others' behavior. Different learning strategies come with different costs and likelihoods of successfully learning more about the world. The choice that any one individual makes of how to learn can have an impact on the collective understanding of a whole population if people learn from each other. Alan Rogers developed simulations of a population of agents to study these network phenomena where agents could individually or socially learn amidst a dynamic, uncertain world and uncovered a confusing result: the availability of cheap social learning yielded no benefit to population fitness over individual learning. This paradox spawned decades of work trying to understand and uncover factors that foster the relative benefit of social learning that centuries of human behavior suggest exists. What happens in such network models now that humans can socially learn from AI systems that are themselves socially learning from us? We revisit Rogers' Paradox in the context of human-AI interaction to probe a simplified network of humans and AI systems learning together about an uncertain world. We propose and examine the impact of several learning strategies on the quality of the equilibrium of a society's 'collective world model'. We consider strategies that can be undertaken by various stakeholders involved in a single human-AI interaction: human, AI model builder, and society or regulators around the interaction. We then consider possible negative feedback loops that may arise from humans learning socially from AI: that learning from the AI may impact our own ability to learn about the world. We close with open directions into studying networks of human and AI systems that can be explored in enriched versions of our simulation framework.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.10476, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2055306799', 'name': 'Katherine M. Collins'}, {'authorId': '32326200', 'name': 'Umang Bhatt'}, {'authorId': '2226897111', 'name': 'Ilia Sucholutsky'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '34d58f28b7b91a4fd95fa2cdc2cfe7c249796210', 'title': 'Consistency of Responses and Continuations Generated by Large Language Models on Social Media', 'abstract': \"Large Language Models (LLMs) demonstrate remarkable capabilities in text generation, yet their emotional consistency and semantic coherence in social media contexts remain insufficiently understood. This study investigates how LLMs handle emotional content and maintain semantic relationships through continuation and response tasks using two open-source models: Gemma and Llama. By analyzing climate change discussions from Twitter and Reddit, we examine emotional transitions, intensity patterns, and semantic similarity between human-authored and LLM-generated content. Our findings reveal that while both models maintain high semantic coherence, they exhibit distinct emotional patterns: Gemma shows a tendency toward negative emotion amplification, particularly anger, while maintaining certain positive emotions like optimism. Llama demonstrates superior emotional preservation across a broader spectrum of affects. Both models systematically generate responses with attenuated emotional intensity compared to human-authored content and show a bias toward positive emotions in response tasks. Additionally, both models maintain strong semantic similarity with original texts, though performance varies between continuation and response tasks. These findings provide insights into LLMs' emotional and semantic processing capabilities, with implications for their deployment in social media contexts and human-AI interaction design.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.08102, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2287773056', 'name': 'Wenlu Fan'}, {'authorId': '2341482315', 'name': 'Yuqi Zhu'}, {'authorId': '2340162780', 'name': 'Chenyang Wang'}, {'authorId': '2286972260', 'name': 'Bin Wang'}, {'authorId': '2339921564', 'name': 'Wentao Xu'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '8f0d4e3992b57098ef5ca7228ec7d59f031a5534', 'title': 'CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries', 'abstract': \"Vision-language models (VLMs) have advanced human-AI interaction but struggle with cultural understanding, often misinterpreting symbols, gestures, and artifacts due to biases in predominantly Western-centric training data. In this paper, we construct CultureVerse, a large-scale multimodal benchmark covering 19, 682 cultural concepts, 188 countries/regions, 15 cultural concepts, and 3 question types, with the aim of characterizing and improving VLMs' multicultural understanding capabilities. Then, we propose CultureVLM, a series of VLMs fine-tuned on our dataset to achieve significant performance improvement in cultural understanding. Our evaluation of 16 models reveals significant disparities, with a stronger performance in Western concepts and weaker results in African and Asian contexts. Fine-tuning on our CultureVerse enhances cultural perception, demonstrating cross-cultural, cross-continent, and cross-dataset generalization without sacrificing performance on models' general VLM benchmarks. We further present insights on cultural generalization and forgetting. We hope that this work could lay the foundation for more equitable and culturally aware multimodal AI systems.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.01282, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2007543818', 'name': 'Shudong Liu'}, {'authorId': '2338358513', 'name': 'Yiqiao Jin'}, {'authorId': '2258600474', 'name': 'Cheng Li'}, {'authorId': '2310737502', 'name': 'Derek F. Wong'}, {'authorId': '2303259263', 'name': 'Qingsong Wen'}, {'authorId': '2287861486', 'name': 'Lichao Sun'}, {'authorId': '2338701486', 'name': 'Haipeng Chen'}, {'authorId': '2249681654', 'name': 'Xing Xie'}, {'authorId': '2329840766', 'name': 'Jindong Wang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '2f882114ab87719c5fc152b572098b1225885f69', 'title': 'Generative Emergent Communication: Large Language Model is a Collective World Model', 'abstract': \"This study proposes a unifying theoretical framework called generative emergent communication (generative EmCom) that bridges emergent communication, world models, and large language models (LLMs) through the lens of collective predictive coding (CPC). The proposed framework formalizes the emergence of language and symbol systems through decentralized Bayesian inference across multiple agents, extending beyond conventional discriminative model-based approaches to emergent communication. This study makes the following two key contributions: First, we propose generative EmCom as a novel framework for understanding emergent communication, demonstrating how communication emergence in multi-agent reinforcement learning (MARL) can be derived from control as inference while clarifying its relationship to conventional discriminative approaches. Second, we propose a mathematical formulation showing the interpretation of LLMs as collective world models that integrate multiple agents' experiences through CPC. The framework provides a unified theoretical foundation for understanding how shared symbol systems emerge through collective predictive coding processes, bridging individual cognitive development and societal language evolution. Through mathematical formulations and discussion on prior works, we demonstrate how this framework explains fundamental aspects of language emergence and offers practical insights for understanding LLMs and developing sophisticated AI systems for improving human-AI interaction and multi-agent systems.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.00226, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2247421363', 'name': 'Tadahiro Taniguchi'}, {'authorId': '2338270218', 'name': 'Ryo Ueda'}, {'authorId': '2122830602', 'name': 'Tomoaki Nakamura'}, {'authorId': '2257388155', 'name': 'Masahiro Suzuki'}, {'authorId': '2049028872', 'name': 'Akira Taniguchi'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'b689a54834d2d6fc5edd1a12593df0c74ba15a30', 'title': 'SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction', 'abstract': \"Sepsis is an organ dysfunction caused by a deregulated immune response to an infection. Early sepsis prediction and identification allow for timely intervention, leading to improved clinical outcomes. Clinical calculators (e.g., the six-organ dysfunction assessment of SOFA) play a vital role in sepsis identification within clinicians' workflow, providing evidence-based risk assessments essential for sepsis diagnosis. However, artificial intelligence (AI) sepsis prediction models typically generate a single sepsis risk score without incorporating clinical calculators for assessing organ dysfunctions, making the models less convincing and transparent to clinicians. To bridge the gap, we propose to mimic clinicians' workflow with a novel framework SepsisCalc to integrate clinical calculators into the predictive model, yielding a clinically transparent and precise model for utilization in clinical settings. Practically, clinical calculators usually combine information from multiple component variables in Electronic Health Records (EHR), and might not be applicable when the variables are (partially) missing. We mitigate this issue by representing EHRs as temporal graphs and integrating a learning module to dynamically add the accurately estimated calculator to the graphs. Experimental results on real-world datasets show that the proposed model outperforms state-of-the-art methods on sepsis prediction tasks. Moreover, we developed a system to identify organ dysfunctions and potential sepsis risks, providing a human-AI interaction tool for deployment, which can help clinicians understand the prediction outputs and prepare timely interventions for the corresponding dysfunctions, paving the way for actionable clinical decision-making support for early intervention.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2501.00190, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1896799084', 'name': 'Changchang Yin'}, {'authorId': '2316011124', 'name': 'Shihan Fu'}, {'authorId': '1490485182', 'name': 'Bingsheng Yao'}, {'authorId': '40421524', 'name': 'Thai-Hoang Pham'}, {'authorId': '2275129268', 'name': 'Weidan Cao'}, {'authorId': '2243367965', 'name': 'Dakuo Wang'}, {'authorId': '2244624058', 'name': 'Jeffrey Caterino'}, {'authorId': '2244780366', 'name': 'Ping Zhang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'ef2cc7bac9fb1508212625a4c2f21e4cc0b4e31e', 'title': 'Nationality, Race, and Ethnicity Biases in and Consequences of Detecting AI-Generated Self-Presentations', 'abstract': \"This study builds on person perception and human AI interaction (HAII) theories to investigate how content and source cues, specifically race, ethnicity, and nationality, affect judgments of AI-generated content in a high-stakes self-presentation context: college applications. Results of a pre-registered experiment with a nationally representative U.S. sample (N = 644) show that content heuristics, such as linguistic style, played a dominant role in AI detection. Source heuristics, such as nationality, also emerged as a significant factor, with international students more likely to be perceived as using AI, especially when their statements included AI-sounding features. Interestingly, Asian and Hispanic applicants were more likely to be judged as AI users when labeled as domestic students, suggesting interactions between racial stereotypes and AI detection. AI attribution led to lower perceptions of personal statement quality and authenticity, as well as negative evaluations of the applicant's competence, sociability, morality, and future success.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.18647, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2328124341', 'name': 'Haoran Chu'}, {'authorId': '92134290', 'name': 'L. Men'}, {'authorId': '51302180', 'name': 'Sixiao Liu'}, {'authorId': '2279392706', 'name': 'Shupei Yuan'}, {'authorId': '2337757153', 'name': 'Yuan Sun'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '1f48eefe77abf4f7d0f125843767929ed4347807', 'title': 'Assessing Human Editing Effort on LLM-Generated Texts via Compression-Based Edit Distance', 'abstract': 'Assessing the extent of human edits on texts generated by Large Language Models (LLMs) is crucial to understanding the human-AI interactions and improving the quality of automated text generation systems. Existing edit distance metrics, such as Levenshtein, BLEU, ROUGE, and TER, often fail to accurately measure the effort required for post-editing, especially when edits involve substantial modifications, such as block operations. In this paper, we introduce a novel compression-based edit distance metric grounded in the Lempel-Ziv-77 algorithm, designed to quantify the amount of post-editing applied to LLM-generated texts. Our method leverages the properties of text compression to measure the informational difference between the original and edited texts. Through experiments on real-world human edits datasets, we demonstrate that our proposed metric is highly correlated with actual edit time and effort. We also show that LLMs exhibit an implicit understanding of editing speed, that aligns well with our metric. Furthermore, we compare our metric with existing ones, highlighting its advantages in capturing complex edits with linear computational efficiency. Our code and data are available at: https://github.com/NDV-tiime/CompressionDistance', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.17321, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2336865042', 'name': 'Nicolas Devatine'}, {'authorId': '2336865089', 'name': 'Louis Abraham'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4d4e319bc52d7ad6b84a3d827e8c13def2530626', 'title': 'An Interaction Design Toolkit for Physical Task Guidance with Artificial Intelligence and Mixed Reality', 'abstract': 'Physical skill acquisition, from sports techniques to surgical procedures, requires instruction and feedback. In the absence of a human expert, Physical Task Guidance (PTG) systems can offer a promising alternative. These systems integrate Artificial Intelligence (AI) and Mixed Reality (MR) to provide realtime feedback and guidance as users practice and learn skills using physical tools and objects. However, designing PTG systems presents challenges beyond engineering complexities. The intricate interplay between users, AI, MR interfaces, and the physical environment creates unique interaction design hurdles. To address these challenges, we present an interaction design toolkit derived from our analysis of PTG prototypes developed by eight student teams during a 10-week-long graduate course. The toolkit comprises Design Considerations, Design Patterns, and an Interaction Canvas. Our evaluation suggests that the toolkit can serve as a valuable resource for practitioners designing PTG systems and researchers developing new tools for human-AI interaction design.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.16892, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2056901064', 'name': 'Arthur Caetano'}, {'authorId': '2077074309', 'name': 'Alejandro Aponte'}, {'authorId': '3024298', 'name': 'Misha Sra'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'ee95a12270b822f5d0669ad1c9cbcd25158fece1', 'title': 'AI Apology: A Critical Review of Apology in AI Systems', 'abstract': 'Apologies are a powerful tool used in human-human interactions to provide affective support, regulate social processes, and exchange information following a trust violation. The emerging field of AI apology investigates the use of apologies by artificially intelligent systems, with recent research suggesting how this tool may provide similar value in human-machine interactions. Until recently, contributions to this area were sparse, and these works have yet to be synthesised into a cohesive body of knowledge. This article provides the first synthesis and critical analysis of the state of AI apology research, focusing on studies published between 2020 and 2023. We derive a framework of attributes to describe five core elements of apology: outcome, interaction, offence, recipient, and offender. With this framework as the basis for our critique, we show how apologies can be used to recover from misalignment in human-AI interactions, and examine trends and inconsistencies within the field. Among the observations, we outline the importance of curating a human-aligned and cross-disciplinary perspective in this research, with consideration for improved system capabilities and long-term outcomes.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.15787, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2215192039', 'name': 'Hadassah Harland'}, {'authorId': '3327913', 'name': 'Richard Dazeley'}, {'authorId': '40894841', 'name': 'Hashini Senaratne'}, {'authorId': '1990124', 'name': 'P. Vamplew'}, {'authorId': '2328408615', 'name': 'Francisco Cruz'}, {'authorId': '2185111602', 'name': 'Bahareh Nakisa'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '2db1d6560ffbed33e9997a9bb857e38f613a6250', 'title': 'AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals', 'abstract': \"Generative AI has the potential to transform knowledge work, but further research is needed to understand how knowledge workers envision using and interacting with generative AI. We investigate the development of generative AI tools to support domain experts in knowledge work, examining task delegation and the design of human-AI interactions. Our research focused on designing a generative AI assistant to aid genetic professionals in analyzing whole genome sequences (WGS) and other clinical data for rare disease diagnosis. Through interviews with 17 genetics professionals, we identified current challenges in WGS analysis. We then conducted co-design sessions with six genetics professionals to determine tasks that could be supported by an AI assistant and considerations for designing interactions with the AI assistant. From our findings, we identified sensemaking as both a current challenge in WGS analysis and a process that could be supported by AI. We contribute an understanding of how domain experts envision interacting with generative AI in their knowledge work, a detailed empirical study of WGS analysis, and three design considerations for using generative AI to support domain experts in sensemaking during knowledge work. CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical studies in HCI Additional Keywords and Phrases: whole genome sequencing, generative AI, large language models, knowledge work, sensemaking, co-design, rare disease Contact Author: Angela Mastrianni (This work was done during the author's internship at Microsoft Research) Ashley Mae Conard and Amanda K. Hall contributed equally\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.15444, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1666538572', 'name': 'Angela Mastrianni'}, {'authorId': '8019298', 'name': 'Hope Twede'}, {'authorId': '3185786', 'name': 'Aleksandra Sarcevic'}, {'authorId': '15594751', 'name': 'Jeremiah D. Wander'}, {'authorId': '2290788499', 'name': 'C. Austin-Tse'}, {'authorId': '72226573', 'name': 'Scott Saponas'}, {'authorId': '2290429767', 'name': 'Heidi L. Rehm'}, {'authorId': '2292015879', 'name': 'A. M. Conard'}, {'authorId': '2336937983', 'name': 'Amanda K. Hall'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '556d0b4df511025f0994eed5f7282d52a03f3f63', 'title': 'What Human-Horse Interactions may Teach us About Effective Human-AI Interactions', 'abstract': \"This article explores human-horse interactions as a metaphor for understanding and designing effective human-AI partnerships. Drawing on the long history of human collaboration with horses, we propose that AI, like horses, should complement rather than replace human capabilities. We move beyond traditional benchmarks such as the Turing test, which emphasize AI's ability to mimic human intelligence, and instead advocate for a symbiotic relationship where distinct intelligences enhance each other. We analyze key elements of human-horse relationships: trust, communication, and mutual adaptability, to highlight essential principles for human-AI collaboration. Trust is critical in both partnerships, built through predictability and shared understanding, while communication and feedback loops foster mutual adaptability. We further discuss the importance of taming and habituation in shaping these interactions, likening it to how humans train AI to perform reliably and ethically in real-world settings. The article also addresses the asymmetry of responsibility, where humans ultimately bear the greater burden of oversight and ethical judgment. Finally, we emphasize that long-term commitment and continuous learning are vital in both human-horse and human-AI relationships, as ongoing interaction refines the partnership and increases mutual adaptability. By drawing on these insights from human-horse interactions, we offer a vision for designing AI systems that are trustworthy, adaptable, and capable of fostering symbiotic human-AI partnerships.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.13405, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '34891162', 'name': 'M. H. Jarrahi'}, {'authorId': '2335861703', 'name': 'Stanley Ahalt'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '59b47ef33e2b9662ba20cdf73e9c2a3e0cf92610', 'title': 'Challenges in Human-Agent Communication', 'abstract': 'Remarkable advancements in modern generative foundation models have enabled the development of sophisticated and highly capable autonomous agents that can observe their environment, invoke tools, and communicate with other agents to solve problems. Although such agents can communicate with users through natural language, their complexity and wide-ranging failure modes present novel challenges for human-AI interaction. Building on prior research and informed by a communication grounding perspective, we contribute to the study of \\\\emph{human-agent communication} by identifying and analyzing twelve key communication challenges that these systems pose. These include challenges in conveying information from the agent to the user, challenges in enabling the user to convey information to the agent, and overarching challenges that need to be considered across all human-agent communication. We illustrate each challenge through concrete examples and identify open directions of research. Our findings provide insights into critical gaps in human-agent communication research and serve as an urgent call for new design patterns, principles, and guidelines to support transparency and control in these systems.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.10380, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '33340656', 'name': 'Gagan Bansal'}, {'authorId': '2279751527', 'name': 'Jennifer Wortman Vaughan'}, {'authorId': '1719124', 'name': 'Saleema Amershi'}, {'authorId': '2323787700', 'name': 'Eric Horvitz'}, {'authorId': '2284065834', 'name': 'Adam Fourney'}, {'authorId': '2329557534', 'name': 'Hussein Mozannar'}, {'authorId': '2269733354', 'name': 'Victor Dibia'}, {'authorId': '2325340903', 'name': 'D. S. Weld'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3b2e10794ffd0d43cb36a71bebb45292611f49ee', 'title': 'The AI Interface: Designing for the Ideal Machine-Human Experience (Editorial)', 'abstract': 'As artificial intelligence (AI) becomes increasingly embedded in daily life, designing intuitive, trustworthy, and emotionally resonant AI-human interfaces has emerged as a critical challenge. This editorial introduces a Special Issue that explores the psychology of AI experience design, focusing on how interfaces can foster seamless collaboration between humans and machines. Drawing on insights from diverse fields (healthcare, consumer technology, workplace dynamics, and cultural sector), the papers in this collection highlight the complexities of trust, transparency, and emotional sensitivity in human-AI interaction. Key themes include designing AI systems that align with user perceptions and expectations, overcoming resistance through transparency and trust, and framing AI capabilities to reduce user anxiety. By synthesizing findings from eight diverse studies, this editorial underscores the need for AI interfaces to balance efficiency with empathy, addressing both functional and emotional dimensions of user experience. Ultimately, it calls for actionable frameworks to bridge research and practice, ensuring that AI systems enhance human lives through thoughtful, human-centered design.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.09000, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '73733077', 'name': 'Aparna Sundar'}, {'authorId': '2329195269', 'name': 'Tony Russell-Rose'}, {'authorId': '2066206116', 'name': 'Udo Kruschwitz'}, {'authorId': '67014634', 'name': 'K. Machleit'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '001e97f3ffabfe3719735259f4ad437e33313115', 'title': 'HAIFAI: Human-AI Interaction for Mental Face Reconstruction', 'abstract': \"We present HAIFAI - a novel two-stage system where humans and AI interact to tackle the challenging task of reconstructing a visual representation of a face that exists only in a person's mind. In the first stage, users iteratively rank images our reconstruction system presents based on their resemblance to a mental image. These rankings, in turn, allow the system to extract relevant image features, fuse them into a unified feature vector, and use a generative model to produce an initial reconstruction of the mental image. The second stage leverages an existing face editing method, allowing users to manually refine and further improve this reconstruction using an easy-to-use slider interface for face shape manipulation. To avoid the need for tedious human data collection for training the reconstruction system, we introduce a computational user model of human ranking behaviour. For this, we collected a small face ranking dataset through an online crowd-sourcing study containing data from 275 participants. We evaluate HAIFAI and an ablated version in a 12-participant user study and demonstrate that our approach outperforms the previous state of the art regarding reconstruction quality, usability, perceived workload, and reconstruction speed. We further validate the reconstructions in a subsequent face ranking study with 18 participants and show that HAIFAI achieves a new state-of-the-art identification rate of 60.6%. These findings represent a significant advancement towards developing new interactive intelligent systems capable of reliably and effortlessly reconstructing a user's mental image.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.06323, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '51251584', 'name': 'Florian Strohm'}, {'authorId': '31944767', 'name': 'Mihai Bâce'}, {'authorId': '2237786979', 'name': 'Andreas Bulling'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'ebbbe19f6dc410f739f3223d0f043e5e70340d2a', 'title': 'The AI Double Standard: Humans Judge All AIs for the Actions of One', 'abstract': 'Robots and other artificial intelligence (AI) systems are widely perceived as moral agents responsible for their actions. As AI proliferates, these perceptions may become entangled via the moral spillover of attitudes towards one AI to attitudes towards other AIs. We tested how the seemingly harmful and immoral actions of an AI or human agent spill over to attitudes towards other AIs or humans in two preregistered experiments. In Study 1 (N = 720), we established the moral spillover effect in human-AI interaction by showing that immoral actions increased attributions of negative moral agency (i.e., acting immorally) and decreased attributions of positive moral agency (i.e., acting morally) and moral patiency (i.e., deserving moral concern) to both the agent (a chatbot or human assistant) and the group to which they belong (all chatbot or human assistants). There was no significant difference in the spillover effects between the AI and human contexts. In Study 2 (N = 684), we tested whether spillover persisted when the agent was individuated with a name and described as an AI or human, rather than specifically as a chatbot or personal assistant. We found that spillover persisted in the AI context but not in the human context, possibly because AIs were perceived as more homogeneous due to their outgroup status relative to humans. This asymmetry suggests a double standard whereby AIs are judged more harshly than humans when one agent morally transgresses. With the proliferation of diverse, autonomous AI systems, HCI research and design should account for the fact that experiences with one AI could easily generalize to perceptions of all AIs and negative HCI outcomes, such as reduced trust.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.06040, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2295126801', 'name': 'Aikaterina Manoli'}, {'authorId': '82201262', 'name': 'Janet V. T. Pauketat'}, {'authorId': '2004948990', 'name': 'Jacy Reese Anthis'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '13faac654c2b0a5dc2f6e3863a3abed2fc9e7ce1', 'title': \"AI's assigned gender affects human-AI cooperation\", 'abstract': \"Cooperation between humans and machines is increasingly vital as artificial intelligence (AI) becomes more integrated into daily life. Research indicates that people are often less willing to cooperate with AI agents than with humans, more readily exploiting AI for personal gain. While prior studies have shown that giving AI agents human-like features influences people's cooperation with them, the impact of AI's assigned gender remains underexplored. This study investigates how human cooperation varies based on gender labels assigned to AI agents with which they interact. In the Prisoner's Dilemma game, 402 participants interacted with partners labelled as AI (bot) or humans. The partners were also labelled male, female, non-binary, or gender-neutral. Results revealed that participants tended to exploit female-labelled and distrust male-labelled AI agents more than their human counterparts, reflecting gender biases similar to those in human-human interactions. These findings highlight the significance of gender biases in human-AI interactions that must be considered in future policy, design of interactive AI systems, and regulation of their use.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2412.05214, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2604532', 'name': 'Sepideh Bazazi'}, {'authorId': '49481600', 'name': 'Jurgis Karpus'}, {'authorId': '1985987', 'name': 'T. Yasseri'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'c1d2e70726d7fbb3b21d6bd65ac85d6e77b89dfd', 'title': 'Exploratory Study Of Human-AI Interaction For Hindustani Music', 'abstract': 'This paper presents a study of participants interacting with and using GaMaDHaNi, a novel hierarchical generative model for Hindustani vocal contours. To explore possible use cases in human-AI interaction, we conducted a user study with three participants, each engaging with the model through three predefined interaction modes. Although this study was conducted\"in the wild\"- with the model unadapted for the shift from the training data to real-world interaction - we use it as a pilot to better understand the expectations, reactions, and preferences of practicing musicians when engaging with such a model. We note their challenges as (1) the lack of restrictions in model output, and (2) the incoherence of model output. We situate these challenges in the context of Hindustani music and aim to suggest future directions for the model design to address these gaps.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.13846, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2141621967', 'name': 'N. Shikarpur'}, {'authorId': '2316891503', 'name': 'Cheng-Zhi Anna Huang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4c49b158bd39497b137ce575361bea8a639dee2c', 'title': 'The Illusion of Empathy: How AI Chatbots Shape Conversation Perception', 'abstract': \"As AI chatbots increasingly incorporate empathy, understanding user-centered perceptions of chatbot empathy and its impact on conversation quality remains essential yet under-explored. This study examines how chatbot identity and perceived empathy influence users' overall conversation experience. Analyzing 155 conversations from two datasets, we found that while GPT-based chatbots were rated significantly higher in conversational quality, they were consistently perceived as less empathetic than human conversational partners. Empathy ratings from GPT-4o annotations aligned with user ratings, reinforcing the perception of lower empathy in chatbots compared to humans. Our findings underscore the critical role of perceived empathy in shaping conversation quality, revealing that achieving high-quality human-AI interactions requires more than simply embedding empathetic language; it necessitates addressing the nuanced ways users interpret and experience empathy in conversations with chatbots.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.12877, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2115432852', 'name': 'Tingting Liu'}, {'authorId': '2306632156', 'name': 'Salvatore Giorgi'}, {'authorId': '72295693', 'name': 'A. Aich'}, {'authorId': '2331513999', 'name': 'Allison Lahnala'}, {'authorId': '2307070926', 'name': 'Brenda Curtis'}, {'authorId': '143857273', 'name': 'Pallavi V. Kulkarni'}, {'authorId': '2662374', 'name': 'João Sedoc'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'fa22b434c6b9dd3099566ca0a946dc662ec572e8', 'title': 'AI-Spectra: A Visual Dashboard for Model Multiplicity to Enhance Informed and Transparent Decision-Making', 'abstract': 'We present an approach, AI-Spectra, to leverage model multiplicity for interactive systems. Model multiplicity means using slightly different AI models yielding equally valid outcomes or predictions for the same task, thus relying on many simultaneous\"expert advisors\"that can have different opinions. Dealing with multiple AI models that generate potentially divergent results for the same task is challenging for users to deal with. It helps users understand and identify AI models are not always correct and might differ, but it can also result in an information overload when being confronted with multiple results instead of one. AI-Spectra leverages model multiplicity by using a visual dashboard designed for conveying what AI models generate which results while minimizing the cognitive effort to detect consensus among models and what type of models might have different opinions. We use a custom adaptation of Chernoff faces for AI-Spectra; Chernoff Bots. This visualization technique lets users quickly interpret complex, multivariate model configurations and compare predictions across multiple models. Our design is informed by building on established Human-AI Interaction guidelines and well know practices in information visualization. We validated our approach through a series of experiments training a wide variation of models with the MNIST dataset to perform number recognition. Our work contributes to the growing discourse on making AI systems more transparent, trustworthy, and effective through the strategic use of multiple models.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.10490, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2331327399', 'name': 'Gilles Eerlings'}, {'authorId': '2331325931', 'name': 'Sebe Vanbrabant'}, {'authorId': '1984924', 'name': 'J. Liesenborgs'}, {'authorId': '2438351', 'name': 'Gustavo Rovelo'}, {'authorId': '3202396', 'name': 'D. Vanacken'}, {'authorId': '2267801525', 'name': 'Kris Luyten'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '230e5308d771e574e5396bb228739857f0f0c260', 'title': 'LLMs are Imperfect, Then What? An Empirical Study on LLM Failures in Software Engineering', 'abstract': \"Software engineers are integrating AI assistants into their workflows to enhance productivity and reduce cognitive strain. However, experiences vary significantly, with some engineers finding large language models (LLMs), like ChatGPT, beneficial, while others consider them counterproductive. Researchers also found that ChatGPT's answers included incorrect information. Given the fact that LLMs are still imperfect, it is important to understand how to best incorporate LLMs into the workflow for software engineering (SE) task completion. Therefore, we conducted an observational study with 22 participants using ChatGPT as a coding assistant in a non-trivial SE task to understand the practices, challenges, and opportunities for using LLMs for SE tasks. We identified the cases where ChatGPT failed, their root causes, and the corresponding mitigation solutions used by users. These findings contribute to the overall understanding and strategies for human-AI interaction on SE tasks. Our study also highlights future research and tooling support directions.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.09916, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2331178689', 'name': 'Jiessie Tie'}, {'authorId': '1490485182', 'name': 'Bingsheng Yao'}, {'authorId': '2243906674', 'name': 'Tianshi Li'}, {'authorId': '2331273656', 'name': 'Syed Ishtiaque Ahmed'}, {'authorId': '2243367965', 'name': 'Dakuo Wang'}, {'authorId': '2331628434', 'name': 'Shurui Zhou'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'a9924729ace4d050393e84d50c250bf445998543', 'title': 'Artificial Theory of Mind and Self-Guided Social Organisation', 'abstract': 'One of the challenges artificial intelligence (AI) faces is how a collection of agents coordinate their behaviour to achieve goals that are not reachable by any single agent. In a recent article by Ozmen et al this was framed as one of six grand challenges: That AI needs to respect human cognitive processes at the human-AI interaction frontier. We suggest that this extends to the AI-AI frontier and that it should also reflect human psychology, as it is the only successful framework we have from which to build out. In this extended abstract we first make the case for collective intelligence in a general setting, drawing on recent work from single neuron complexity in neural networks and ant network adaptability in ant colonies. From there we introduce how species relate to one another in an ecological network via niche selection, niche choice, and niche conformity with the aim of forming an analogy with human social network development as new agents join together and coordinate. From there we show how our social structures are influenced by our neuro-physiology, our psychology, and our language. This emphasises how individual people within a social network influence the structure and performance of that network in complex tasks, and that cognitive faculties such as Theory of Mind play a central role. We finish by discussing the current state of the art in AI and where there is potential for further development of a socially embodied collective artificial intelligence that is capable of guiding its own social structures.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.09169, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2284678068', 'name': \"Michael S. Harr'e\"}, {'authorId': '2330243481', 'name': 'Jaime Ruiz-Serra'}, {'authorId': '2330588372', 'name': 'Catherine Drysdale'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'f3a547e5b7260517f05d8fe9b5c0fadc9c6d3490', 'title': 'I Can Embrace and Avoid Vagueness Myself: Supporting the Design Process by Balancing Vagueness through Text-to-Image Generative AI', 'abstract': 'This study examines the role of vagueness in the design process and its strategic management for the effective human-AI interaction. While vagueness in the generation of design ideas promotes diverse interpretations and prevents fixation, excessive vagueness can lead to scattered results. Designers attempt to use image search tools or generative AIs (e.g., Dall-E) for their work but often fail to achieve satisfactory results because the level of vagueness is not properly managed in these technologies. In this work, we identified how designers coordinate vagueness in their design process and applied key components of the process to the design of CLAY, an interactive system that balances vagueness through iterative prompt refinement by integrating the strengths of text-to-image generative AI. Results from our user study with 10 fashion designers showed that CLAY effectively supported their design process, reducing design time, and expanding creative possibilities compared to their existing practice, by allowing them to both embrace and avoid vagueness as needed. Our study highlights the importance of identifying key characteristics of the target user and domain, and exploring ways to incorporate them into the design of an AI-based interactive tool.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.08588, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2214742346', 'name': 'Myungjin Kim'}, {'authorId': '51043444', 'name': 'Bogoan Kim'}, {'authorId': '2326817361', 'name': 'Kyungsik Han'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'be0cd07d1d590b7dc7475cd3bb9d01dbf1862db6', 'title': 'Towards a criteria-based approach to selecting human-AI interaction mode', 'abstract': 'Artificial intelligence (AI) tools are now prevalent in many knowledge work industries. As AI becomes more capable and interactive, there is a growing need for guidance on how to employ AI most effectively. The A2C framework (Tariq, Chhetri, Nepal&Paris, 2024) distinguishes three decision-making modes for engaging AI: automation (AI completes a task, including decision/action), augmentation (AI supports human to decide) and collaboration (iterative interaction between human and AI). However, selecting the appropriate mode for a specific application is not always straightforward. The goal of the present study was to compile and trial a simple set of criteria to support recommendations about appropriate A2C mode for a given application. Drawing on human factors and computer science literature, we identified key criteria related to elements of the task, impacts on worker and support needs. From these criteria we built a scoring rubric with recommendation for A2C mode. As a preliminary test of this approach, we applied the criteria to cognitive task analysis (CTA) outputs from three tasks in the science domain - genome annotation, biological collections curation and protein crystallization - which provided insights into worker decision points, challenges and expert strategies. This paper describes the method for connecting CTA to A2C, reflecting on the challenges and future directions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.07406, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2330246498', 'name': 'Jessica Irons'}, {'authorId': '2292442272', 'name': 'Patrick S. Cooper'}, {'authorId': '2213660393', 'name': 'Melanie Mcgrath'}, {'authorId': '28221681', 'name': 'Shahroz Tariq'}, {'authorId': '2325360957', 'name': 'Andreas Duenser'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'fff61658c9185d4cb2e83e92a24623b218ac73ff', 'title': 'EF-LLM: Energy Forecasting LLM with AI-assisted Automation, Enhanced Sparse Prediction, Hallucination Detection', 'abstract': \"Accurate prediction helps to achieve supply-demand balance in energy systems, supporting decision-making and scheduling. Traditional models, lacking AI-assisted automation, rely on experts, incur high costs, and struggle with sparse data prediction. To address these challenges, we propose the Energy Forecasting Large Language Model (EF-LLM), which integrates domain knowledge and temporal data for time-series forecasting, supporting both pre-forecast operations and post-forecast decision-support. EF-LLM's human-AI interaction capabilities lower the entry barrier in forecasting tasks, reducing the need for extra expert involvement. To achieve this, we propose a continual learning approach with updatable LoRA and a multi-channel architecture for aligning heterogeneous multimodal data, enabling EF-LLM to continually learn heterogeneous multimodal knowledge. In addition, EF-LLM enables accurate predictions under sparse data conditions through its ability to process multimodal data. We propose Fusion Parameter-Efficient Fine-Tuning (F-PEFT) method to effectively leverage both time-series data and text for this purpose. EF-LLM is also the first energy-specific LLM to detect hallucinations and quantify their occurrence rate, achieved via multi-task learning, semantic similarity analysis, and ANOVA. We have achieved success in energy prediction scenarios for load, photovoltaic, and wind power forecast.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.00852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2052108715', 'name': 'Zihang Qiu'}, {'authorId': '2299944379', 'name': 'Chaojie Li'}, {'authorId': '2329295393', 'name': 'Zhongyang Wang'}, {'authorId': '2299327930', 'name': 'Renyou Xie'}, {'authorId': '2268442723', 'name': 'Borui Zhang'}, {'authorId': '2263883857', 'name': 'Huadong Mo'}, {'authorId': '2329245114', 'name': 'Guo Chen'}, {'authorId': '2266027470', 'name': 'Z. Dong'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'afa11606dae36fe8343126ca4013124ced0caa6a', 'title': 'Survey of User Interface Design and Interaction Techniques in Generative AI Applications', 'abstract': 'The applications of generative AI have become extremely impressive, and the interplay between users and AI is even more so. Current human-AI interaction literature has taken a broad look at how humans interact with generative AI, but it lacks specificity regarding the user interface designs and patterns used to create these applications. Therefore, we present a survey that comprehensively presents taxonomies of how a human interacts with AI and the user interaction patterns designed to meet the needs of a variety of relevant use cases. We focus primarily on user-guided interactions, surveying interactions that are initiated by the user and do not include any implicit signals given by the user. With this survey, we aim to create a compendium of different user-interaction patterns that can be used as a reference for designers and developers alike. In doing so, we also strive to lower the entry barrier for those attempting to learn more about the design of generative AI applications.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.22370, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2328303422', 'name': 'Reuben Luera'}, {'authorId': '2317012495', 'name': 'Ryan A. Rossi'}, {'authorId': '2322288479', 'name': 'Alexa Siu'}, {'authorId': '2257962368', 'name': 'Franck Dernoncourt'}, {'authorId': '2301760185', 'name': 'Tong Yu'}, {'authorId': '2299908109', 'name': 'Sungchul Kim'}, {'authorId': '2283147661', 'name': 'Ruiyi Zhang'}, {'authorId': '2312278435', 'name': 'Xiang Chen'}, {'authorId': '2328304189', 'name': 'Hanieh Salehy'}, {'authorId': '2328767221', 'name': 'Jian Zhao'}, {'authorId': '2114710333', 'name': 'Samyadeep Basu'}, {'authorId': '2327337693', 'name': 'Puneet Mathur'}, {'authorId': '1793409', 'name': 'Nedim Lipka'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '857f1f2029fdcf655d35113b7fb3f49d0faa4e86', 'title': '\"Ghost of the past\": identifying and resolving privacy leakage from LLM\\'s memory through proactive user interaction', 'abstract': 'Memories, encompassing past inputs in context window and retrieval-augmented generation (RAG), frequently surface during human-LLM interactions, yet users are often unaware of their presence and the associated privacy risks. To address this, we propose MemoAnalyzer, a system for identifying, visualizing, and managing private information within memories. A semi-structured interview (N=40) revealed that low privacy awareness was the primary challenge, while proactive privacy control emerged as the most common user need. MemoAnalyzer uses a prompt-based method to infer and identify sensitive information from aggregated past inputs, allowing users to easily modify sensitive content. Background color temperature and transparency are mapped to inference confidence and sensitivity, streamlining privacy adjustments. A 5-day evaluation (N=36) comparing MemoAnalyzer with the default GPT setting and a manual modification baseline showed MemoAnalyzer significantly improved privacy awareness and protection without compromising interaction speed. Our study contributes to privacy-conscious LLM design, offering insights into privacy protection for Human-AI interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.14931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2214812586', 'name': 'Shuning Zhang'}, {'authorId': '2329324157', 'name': 'Lyumanshan Ye'}, {'authorId': '2303802245', 'name': 'Xin Yi'}, {'authorId': '2327039059', 'name': 'Jingyu Tang'}, {'authorId': '2326989602', 'name': 'Bo Shui'}, {'authorId': '2308274823', 'name': 'Haobin Xing'}, {'authorId': '2327103110', 'name': 'Pengfei Liu'}, {'authorId': '2304266882', 'name': 'Hewu Li'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '20e8f225b1d0dcf72e583a513c96abd5896b3e8c', 'title': 'Judgment of Learning: A Human Ability Beyond Generative Artificial Intelligence', 'abstract': \"Large language models (LLMs) increasingly mimic human cognition in various language-based tasks. However, their capacity for metacognition - particularly in predicting memory performance - remains unexplored. Here, we introduce a cross-agent prediction model to assess whether ChatGPT-based LLMs align with human judgments of learning (JOL), a metacognitive measure where individuals predict their own future memory performance. We tested humans and LLMs on pairs of sentences, one of which was a garden-path sentence - a sentence that initially misleads the reader toward an incorrect interpretation before requiring reanalysis. By manipulating contextual fit (fitting vs. unfitting sentences), we probed how intrinsic cues (i.e., relatedness) affect both LLM and human JOL. Our results revealed that while human JOL reliably predicted actual memory performance, none of the tested LLMs (GPT-3.5-turbo, GPT-4-turbo, and GPT-4o) demonstrated comparable predictive accuracy. This discrepancy emerged regardless of whether sentences appeared in fitting or unfitting contexts. These findings indicate that, despite LLMs' demonstrated capacity to model human cognition at the object-level, they struggle at the meta-level, failing to capture the variability in individual memory predictions. By identifying this shortcoming, our study underscores the need for further refinements in LLMs' self-monitoring abilities, which could enhance their utility in educational settings, personalized learning, and human-AI interactions. Strengthening LLMs' metacognitive performance may reduce the reliance on human oversight, paving the way for more autonomous and seamless integration of AI into tasks requiring deeper cognitive awareness.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.13392, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2290487821', 'name': 'Markus Huff'}, {'authorId': '2341705731', 'name': 'Elanur Ulakcci'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '7a12d9f2da12dbe6b0c3ff6f06ca2ed47fbd6134', 'title': 'Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface', 'abstract': 'Agents, as user-centric tools, are increasingly deployed for human task delegation, assisting with a broad spectrum of requests by generating thoughts, engaging with user proxies, and producing action plans. However, agents based on large language models (LLMs) often face substantial planning latency due to two primary factors: the efficiency limitations of the underlying LLMs due to their large size and high demand, and the structural complexity of the agents due to the extensive generation of intermediate thoughts to produce the final output. Given that inefficiency in service provision can undermine the value of automation for users, this paper presents a human-centered efficient agent planning method -- Interactive Speculative Planning -- aiming at enhancing the efficiency of agent planning through both system design and human-AI interaction. Our approach advocates for the co-design of the agent system and user interface, underscoring the importance of an agent system that can fluidly manage user interactions and interruptions. By integrating human interruptions as a fundamental component of the system, we not only make it more user-centric but also expedite the entire process by leveraging human-in-the-loop interactions to provide accurate intermediate steps. Code and data will be released.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.00079, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2007245028', 'name': 'Wenyue Hua'}, {'authorId': '2323739649', 'name': 'Mengting Wan'}, {'authorId': '2323745249', 'name': 'Shashank Vadrevu'}, {'authorId': '2323754322', 'name': 'Ryan Nadel'}, {'authorId': '2239061409', 'name': 'Yongfeng Zhang'}, {'authorId': '2324215663', 'name': 'Chi Wang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'ead111352affd595c670ce844a1c273e8af803c4', 'title': 'Bridging the Gap in Hybrid Decision-Making Systems', 'abstract': \"We introduce BRIDGET, a novel human-in-the-loop system for hybrid decision-making, aiding the user to label records from an un-labeled dataset, attempting to ``bridge the gap'' between the two most popular Hybrid Decision-Making paradigms: those featuring the human in a leading position, and the other with a machine making most of the decisions. BRIDGET understands when either a machine or a human user should be in charge, dynamically switching between two statuses. In the different statuses, BRIDGET still fosters the human-AI interaction, either having a machine learning model assuming skeptical stances towards the user and offering them suggestions, or towards itself and calling the user back. We believe our proposal lays the groundwork for future synergistic systems involving a human and a machine decision-makers.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.19415, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2257015459', 'name': 'Federico Mazzoni'}, {'authorId': '24269254', 'name': 'Roberto Pellungrini'}, {'authorId': '2298046225', 'name': 'Riccardo Guidotti'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '44e8ce95787807c554a17a2248b1ebe1dbb2405b', 'title': 'Performance and Metacognition Disconnect when Reasoning in Human-AI Interaction', 'abstract': 'Optimizing human-AI interaction requires users to reflect on their own performance critically. Our paper examines whether people using AI to complete tasks can accurately monitor how well they perform. In Study 1, participants (N = 246) used AI to solve 20 logical problems from the Law School Admission Test. While their task performance improved by three points compared to a norm population, participants overestimated their performance by four points. Interestingly, higher AI literacy was linked to less accurate self-assessment. Participants with more technical knowledge of AI were more confident but less precise in judging their own performance. Using a computational model, we explored individual differences in metacognitive accuracy and found that the Dunning-Kruger effect, usually observed in this task, ceased to exist with AI. Study 2 (N = 452) replicates these findings. We discuss how AI levels metacognitive performance and consider consequences of performance overestimation for interactive AI systems enhancing cognition.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.16708, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2322805282', 'name': 'Daniela Fernandes'}, {'authorId': '51179828', 'name': 'Steeven Villa'}, {'authorId': '2322799995', 'name': 'Salla Nicholls'}, {'authorId': '2313728626', 'name': 'Otso Haavisto'}, {'authorId': '2317081786', 'name': 'Daniel Buschek'}, {'authorId': '2281834664', 'name': 'Albrecht Schmidt'}, {'authorId': '2281741841', 'name': 'Thomas Kosch'}, {'authorId': '2323593832', 'name': 'Chenxinran Shen'}, {'authorId': '2313728734', 'name': 'Robin Welsch'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '7d0e8d1a514e8d12808b55f881ae98aa4043bd66', 'title': 'HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions', 'abstract': \"AI agents are increasingly autonomous in their interactions with human users and tools, leading to increased interactional safety risks. We present HAICOSYSTEM, a framework examining AI agent safety within diverse and complex social interactions. HAICOSYSTEM features a modular sandbox environment that simulates multi-turn interactions between human users and AI agents, where the AI agents are equipped with a variety of tools (e.g., patient management platforms) to navigate diverse scenarios (e.g., a user attempting to access other patients' profiles). To examine the safety of AI agents in these interactions, we develop a comprehensive multi-dimensional evaluation framework that uses metrics covering operational, content-related, societal, and legal risks. Through running 1840 simulations based on 92 scenarios across seven domains (e.g., healthcare, finance, education), we demonstrate that HAICOSYSTEM can emulate realistic user-AI interactions and complex tool use by AI agents. Our experiments show that state-of-the-art LLMs, both proprietary and open-sourced, exhibit safety risks in over 50\\\\% cases, with models generally showing higher risks when interacting with simulated malicious users. Our findings highlight the ongoing challenge of building agents that can safely navigate complex interactions, particularly when faced with malicious users. To foster the AI agent safety ecosystem, we release a code platform that allows practitioners to create custom scenarios, simulate interactions, and evaluate the safety and performance of their agents.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.16427, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2315123357', 'name': 'Xuhui Zhou'}, {'authorId': '32609381', 'name': 'Hyunwoo Kim'}, {'authorId': '2223951216', 'name': 'Faeze Brahman'}, {'authorId': '2112504145', 'name': 'Liwei Jiang'}, {'authorId': '2323375189', 'name': 'Hao Zhu'}, {'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '2323757322', 'name': 'Frank Xu'}, {'authorId': '2273918810', 'name': 'Bill Yuchen Lin'}, {'authorId': '2257385140', 'name': 'Yejin Choi'}, {'authorId': '2254272878', 'name': 'Niloofar Mireshghallah'}, {'authorId': '2069676542', 'name': 'R. L. Bras'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '64e3eed27cad32ce43002bf7b1458246943bd5f4', 'title': 'Talk, Listen, Connect: Navigating Empathy in Human-AI Interactions', 'abstract': 'Social interactions promote well-being, yet challenges like geographic distance and mental health conditions can limit in-person engagement. Advances in AI agents are transferring communication, particularly in mental health, where AI chatbots provide accessible, non-judgmental support. However, a key challenge is how effectively these systems can express empathy, which is crucial in human-centered design. Current research highlights a gap in understanding how AI can authentically convey empathy, particularly as issues like anxiety, depression, and loneliness increase. Our research focuses on this gap by comparing empathy expression in human-human versus human-AI interactions. Using personal narratives and statistical analysis, we examine empathy levels elicited by humans and AI, including GPT-4o and fine-tuned versions of the model. This work aims to enhance the authenticity of AI-driven empathy, contributing to the future design of more reliable and effective mental health support systems that foster meaningful social interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.15550, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2311192037', 'name': 'Mahnaz Roshanaei'}, {'authorId': '3342374', 'name': 'R. Rezapour'}, {'authorId': '1381933697', 'name': 'M. S. El-Nasr'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '7061ca5d0b3f5875e207754f68554b3f225e9e19', 'title': 'The Power of Perception in Human-AI Interaction: Investigating Psychological Factors and Cognitive Biases that Shape User Belief and Behavior', 'abstract': 'This thesis investigates the psychological factors that influence belief in AI predictions, comparing them to belief in astrology- and personality-based predictions, and examines the\"personal validation effect\"in the context of AI, particularly with Large Language Models (LLMs). Through two interconnected studies involving 238 participants, the first study explores how cognitive style, paranormal beliefs, AI attitudes, and personality traits impact perceptions of the validity, reliability, usefulness, and personalization of predictions from different sources. The study finds a positive correlation between belief in AI predictions and belief in astrology- and personality-based predictions, highlighting a\"rational superstition\"phenomenon where belief is more influenced by mental heuristics and intuition than by critical evaluation. Interestingly, cognitive style did not significantly affect belief in predictions, while paranormal beliefs, positive AI attitudes, and conscientiousness played significant roles. The second study reveals that positive predictions are perceived as significantly more valid, personalized, reliable, and useful than negative ones, emphasizing the strong influence of prediction valence on user perceptions. This underscores the need for AI systems to manage user expectations and foster balanced trust. The thesis concludes with a proposal for future research on how belief in AI predictions influences actual user behavior, exploring it through the lens of self-fulfilling prophecy. Overall, this thesis enhances understanding of human-AI interaction and provides insights for developing AI systems across various applications.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.15328, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2316111167', 'name': 'Eunhae Lee'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'de64a10e3f2446f12e42983a60d09f41cb4998c9', 'title': 'AI as Extraherics: Fostering Higher-order Thinking Skills in Human-AI Interaction', 'abstract': \"As artificial intelligence (AI) technologies, including generative AI, continue to evolve, concerns have arisen about over-reliance on AI, which may lead to human deskilling and diminished cognitive engagement. Over-reliance on AI can also lead users to accept information given by AI without performing critical examinations, causing negative consequences, such as misleading users with hallucinated contents. This paper introduces extraheric AI, a human-AI interaction conceptual framework that fosters users' higher-order thinking skills, such as creativity, critical thinking, and problem-solving, during task completion. Unlike existing human-AI interaction designs, which replace or augment human cognition, extraheric AI fosters cognitive engagement by posing questions or providing alternative perspectives to users, rather than direct answers. We discuss interaction strategies, evaluation methods aligned with cognitive load theory and Bloom's taxonomy, and future research directions to ensure that human cognitive skills remain a crucial element in AI-integrated environments, promoting a balanced partnership between humans and AI.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2409.09218, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2301054341', 'name': 'Koji Yatani'}, {'authorId': '2214775774', 'name': 'Zefan Sramek'}, {'authorId': '2321994734', 'name': 'Chi-Lan Yang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '1ba176e35b66685b25744de009ff212b5e7ce4b2', 'title': 'Effect of Adaptation Rate and Cost Display in a Human-AI Interaction Game', 'abstract': \"As interactions between humans and AI become more prevalent, it is critical to have better predictors of human behavior in these interactions. We investigated how changes in the AI's adaptive algorithm impact behavior predictions in two-player continuous games. In our experiments, the AI adapted its actions using a gradient descent algorithm under different adaptation rates while human participants were provided cost feedback. The cost feedback was provided by one of two types of visual displays: (a) cost at the current joint action vector, or (b) cost in a local neighborhood of the current joint action vector. Our results demonstrate that AI adaptation rate can significantly affect human behavior, having the ability to shift the outcome between two game theoretic equilibrium. We observed that slow adaptation rates shift the outcome towards the Nash equilibrium, while fast rates shift the outcome towards the human-led Stackelberg equilibrium. The addition of localized cost information had the effect of shifting outcomes towards Nash, compared to the outcomes from cost information at only the current joint action vector. Future work will investigate other effects that influence the convergence of gradient descent games.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.14640, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2296697423', 'name': 'Jason T. Isa'}, {'authorId': '2308988221', 'name': 'Bohan Wu'}, {'authorId': '2308976532', 'name': 'Qirui Wang'}, {'authorId': '2317040624', 'name': 'Yilin Zhang'}, {'authorId': '2317011071', 'name': 'Samuel A. Burden'}, {'authorId': '2336879623', 'name': 'Lillian J. Ratliff'}, {'authorId': '133697096', 'name': 'Benjamin J. Chasnov'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '56a4f6188f82ce46bf8a9522d8a0f65d91333922', 'title': 'IQA-EVAL: Automatic Evaluation of Human-Model Interactive Question Answering', 'abstract': \"To evaluate Large Language Models (LLMs) for question answering (QA), traditional methods typically focus on assessing single-turn responses to given questions. However, this approach doesn't capture the dynamic nature of human-AI interactions, where humans actively seek information through conversation. Recent works in human-computer interaction (HCI) have employed human evaluators to conduct interactions and evaluations, but they are often prohibitively expensive and time-consuming to scale. We introduce an automatic evaluation framework IQA-EVAL to achieve Interactive Question Answering Evaluations, more specifically, we introduce a LLM-based Evaluation Agent (LEA) that can: (1) simulate human behaviors to generate interactions with IQA models; (2) automatically evaluate the generated interactions. Moreover, we propose assigning personas to LEAs to better simulate groups of real human evaluators. We show that: (1) our evaluation framework with GPT-4 (or Claude) as the backbone model achieves a high correlation with human evaluations on the IQA task; (2) assigning personas to LEA to better represent the crowd further significantly improves correlations. Finally, we use our automatic metric to evaluate five recent representative LLMs with over 1000 questions from complex and ambiguous question answering tasks, which comes with a substantial cost of $5k if evaluated by humans.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.13545, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2033082027', 'name': 'Ruosen Li'}, {'authorId': '2160611160', 'name': 'Barry Wang'}, {'authorId': '2316953868', 'name': 'Ruochen Li'}, {'authorId': '2319193188', 'name': 'Xinya Du'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'd6d7b6057d7254218668c6668043b47610644f64', 'title': 'The Model Mastery Lifecycle: A Framework for Designing Human-AI Interaction', 'abstract': 'The utilization of AI in an increasing number of fields is the latest iteration of a long process, where machines and systems have been replacing humans, or changing the roles that they play, in various tasks. Although humans are often resistant to technological innovation, especially in workplaces, there is a general trend towards increasing automation, and more recently, AI. AI is now capable of carrying out, or assisting with, many tasks that used to be regarded as exclusively requiring human expertise. In this paper we consider the case of tasks that could be performed either by human experts or by AI and locate them on a continuum running from exclusively human task performance at one end to AI autonomy on the other, with a variety of forms of human-AI interaction between those extremes. Implementation of AI is constrained by the context of the systems and workflows that it will be embedded within. There is an urgent need for methods to determine how AI should be used in different situations and to develop appropriate methods of human-AI interaction so that humans and AI can work together effectively to perform tasks. In response to the evolving landscape of AI progress and increasing mastery, we introduce an AI Mastery Lifecycle framework and discuss its implications for human-AI interaction. The framework provides guidance on human-AI task allocation and how human-AI interfaces need to adapt to improvements in AI task performance over time. Within the framework we identify a zone of uncertainty where the issues of human-AI task allocation and user interface design are likely to be most challenging.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.12781, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1513628160', 'name': 'M. Chignell'}, {'authorId': '2038529378', 'name': 'Mu-Huan Chung'}, {'authorId': '10421486', 'name': 'Jaturong Kongmanee'}, {'authorId': '2187101405', 'name': 'Khilan Jerath'}, {'authorId': '49021886', 'name': 'Abhay Raman'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '20a9c8b89804ae9369c1032c653840a1cfac637c', 'title': 'End-to-end Semantic-centric Video-based Multimodal Affective Computing', 'abstract': \"In the pathway toward Artificial General Intelligence (AGI), understanding human's affection is essential to enhance machine's cognition abilities. For achieving more sensual human-AI interaction, Multimodal Affective Computing (MAC) in human-spoken videos has attracted increasing attention. However, previous methods are mainly devoted to designing multimodal fusion algorithms, suffering from two issues: semantic imbalance caused by diverse pre-processing operations and semantic mismatch raised by inconsistent affection content contained in different modalities comparing with the multimodal ground truth. Besides, the usage of manual features extractors make they fail in building end-to-end pipeline for multiple MAC downstream tasks. To address above challenges, we propose a novel end-to-end framework named SemanticMAC to compute multimodal semantic-centric affection for human-spoken videos. We firstly employ pre-trained Transformer model in multimodal data pre-processing and design Affective Perceiver module to capture unimodal affective information. Moreover, we present a semantic-centric approach to unify multimodal representation learning in three ways, including gated feature interaction, multi-task pseudo label generation, and intra-/inter-sample contrastive learning. Finally, SemanticMAC effectively learn specific- and shared-semantic representations in the guidance of semantic-centric labels. Extensive experimental results demonstrate that our approach surpass the state-of-the-art methods on 7 public datasets in four MAC downstream tasks.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.07694, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1455446983', 'name': 'Ronghao Lin'}, {'authorId': '2111108374', 'name': 'Ying Zeng'}, {'authorId': '150301735', 'name': 'Sijie Mai'}, {'authorId': '2152902046', 'name': 'Haifeng Hu'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'c919967b31d92a8b86268bdfcb9cd1b77f3d8917', 'title': 'Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior', 'abstract': 'Could belief in AI predictions be just another form of superstition? This study investigates psychological factors that influence belief in AI predictions about personal behavior, comparing it to belief in astrology- and personality-based predictions. Through an experiment with 238 participants, we examined how cognitive style, paranormal beliefs, AI attitudes, personality traits, and other factors affect perceived validity, reliability, usefulness, and personalization of predictions from different sources. Our findings reveal that belief in AI predictions is positively correlated with belief in predictions based on astrology and personality psychology. Notably, paranormal beliefs and positive attitudes about AI significantly increased perceived validity, reliability, usefulness, and personalization of AI predictions. Conscientiousness was negatively correlated with belief in predictions across all sources, and interest in the prediction topic increased believability across predictions. Surprisingly, we found no evidence that cognitive style has an impact on belief in fictitious AI-generated predictions. These results highlight the\"rational superstition\"phenomenon in AI, where belief is driven more by mental heuristics and intuition than critical evaluation. This research advances our understanding of the psychology of human-AI interaction, offering insights into designing and promoting AI systems that foster appropriate trust and skepticism, critical for responsible integration in an increasingly AI-driven world.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.06602, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2316111167', 'name': 'Eunhae Lee'}, {'authorId': '24637418', 'name': 'Pat Pataranutaporn'}, {'authorId': '2233123', 'name': 'J. Amores'}, {'authorId': '2253574849', 'name': 'Pattie Maes'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '53356c65a0a9da982939ada71fa93c62b47f5c7c', 'title': 'MindSpeech: Continuous Imagined Speech Decoding using High-Density fNIRS and Prompt Tuning for Advanced Human-AI Interaction', 'abstract': \"In the coming decade, artificial intelligence systems will continue to improve and revolutionise every industry and facet of human life. Designing effective, seamless and symbiotic communication paradigms between humans and AI agents is increasingly important. This paper reports a novel method for human-AI interaction by developing a direct brain-AI interface. We discuss a novel AI model, called MindSpeech, which enables open-vocabulary, continuous decoding for imagined speech. This study focuses on enhancing human-AI communication by utilising high-density functional near-infrared spectroscopy (fNIRS) data to develop an AI model capable of decoding imagined speech non-invasively. We discuss a new word cloud paradigm for data collection, improving the quality and variety of imagined sentences generated by participants and covering a broad semantic space. Utilising a prompt tuning-based approach, we employed the Llama2 large language model (LLM) for text generation guided by brain signals. Our results show significant improvements in key metrics, such as BLEU-1 and BERT P scores, for three out of four participants, demonstrating the method's effectiveness. Additionally, we demonstrate that combining data from multiple participants enhances the decoder performance, with statistically significant improvements in BERT scores for two participants. Furthermore, we demonstrated significantly above-chance decoding accuracy for imagined speech versus resting conditions and the identified activated brain regions during imagined speech tasks in our study are consistent with the previous studies on brain regions involved in speech encoding. This study underscores the feasibility of continuous imagined speech decoding. By integrating high-density fNIRS with advanced AI techniques, we highlight the potential for non-invasive, accurate communication systems with AI in the near future.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.05362, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2316013413', 'name': 'Suyi Zhang'}, {'authorId': '2315925312', 'name': 'Ekram Alam'}, {'authorId': '2315925920', 'name': 'Jack Baber'}, {'authorId': '2315925004', 'name': 'Francesca Bianco'}, {'authorId': '2315927237', 'name': 'Edward Turner'}, {'authorId': '2254086807', 'name': 'Maysam Chamanzar'}, {'authorId': '2315924967', 'name': 'Hamid Dehghani'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4eb4a0e848e80db778a2c10455e0a71d9b887506', 'title': 'MindGPT: Advancing Human-AI Interaction with Non-Invasive fNIRS-Based Imagined Speech Decoding', 'abstract': 'In the coming decade, artificial intelligence systems are set to revolutionise every industry and facet of human life. Building communication systems that enable seamless and symbiotic communication between humans and AI agents is increasingly important. This research advances the field of human-AI interaction by developing an innovative approach to decode imagined speech using non-invasive high-density functional near-infrared spectroscopy (fNIRS). Notably, this study introduces MindGPT, the first thought-to-LLM (large language model) system in the world.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.05361, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2316013413', 'name': 'Suyi Zhang'}, {'authorId': '2315925312', 'name': 'Ekram Alam'}, {'authorId': '2315925920', 'name': 'Jack Baber'}, {'authorId': '2315925004', 'name': 'Francesca Bianco'}, {'authorId': '2315927237', 'name': 'Edward Turner'}, {'authorId': '2254086807', 'name': 'Maysam Chamanzar'}, {'authorId': '2315924967', 'name': 'Hamid Dehghani'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '4618d6e5ea66c89de5fb8aeb8a5d7790e19ec1ea', 'title': 'Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust', 'abstract': \"Trust is not just a cognitive issue but also an emotional one, yet the research in human-AI interactions has primarily focused on the cognitive route of trust development. Recent work has highlighted the importance of studying affective trust towards AI, especially in the context of emerging human-like LLM-powered conversational agents. However, there is a lack of validated and generalizable measures for the two-dimensional construct of trust in AI agents. To address this gap, we developed and validated a set of 27-item semantic differential scales for affective and cognitive trust through a scenario-based survey study. We then further validated and applied the scale through an experiment study. Our empirical findings showed how the emotional and cognitive aspects of trust interact with each other and collectively shape a person's overall trust in AI agents. Our study methodology and findings also provide insights into the capability of the state-of-art LLMs to foster trust through different routes.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.05354, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2067215691', 'name': 'Ruoxi Shang'}, {'authorId': '2315927359', 'name': 'Gary Hsieh'}, {'authorId': '2315927267', 'name': 'Chirag Shah'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'aa81867f65c641feef7ee89f9d9e42b3d14c7ed6', 'title': 'Exploring Personality-Driven Personalization in XAI: Enhancing User Trust in Gameplay', 'abstract': 'Tailoring XAI methods to individual needs is crucial for intuitive Human-AI interactions. While context and task goals are vital, factors like user personality traits could also influence method selection. Our study investigates using personality traits to predict user preferences among decision trees, texts, and factor graphs. We trained a Machine Learning model on responses to the Big Five personality test to predict preferences. Deploying these predicted preferences in a navigation game (n=6), we found users more receptive to personalized XAI recommendations, enhancing trust in the system. This underscores the significance of customization in XAI interfaces, impacting user engagement and confidence.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.04778, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2315897102', 'name': 'Zhaoxin Li'}, {'authorId': '2315890601', 'name': 'Sophie Yang'}, {'authorId': '2315859861', 'name': 'Shijie Wang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3645bef1d2bbac3f93737a0d9f34c7de4e4a801c', 'title': 'Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews', 'abstract': \"This study examines the impact of AI on human false memories -- recollections of events that did not occur or deviate from actual occurrences. It explores false memory induction through suggestive questioning in Human-AI interactions, simulating crime witness interviews. Four conditions were tested: control, survey-based, pre-scripted chatbot, and generative chatbot using a large language model (LLM). Participants (N=200) watched a crime video, then interacted with their assigned AI interviewer or survey, answering questions including five misleading ones. False memories were assessed immediately and after one week. Results show the generative chatbot condition significantly increased false memory formation, inducing over 3 times more immediate false memories than the control and 1.7 times more than the survey method. 36.4% of users' responses to the generative chatbot were misled through the interaction. After one week, the number of false memories induced by generative chatbots remained constant. However, confidence in these false memories remained higher than the control after one week. Moderating factors were explored: users who were less familiar with chatbots but more familiar with AI technology, and more interested in crime investigations, were more susceptible to false memories. These findings highlight the potential risks of using advanced AI in sensitive contexts, like police interviews, emphasizing the need for ethical considerations.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.04681, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2315813633', 'name': 'Samantha Chan'}, {'authorId': '24637418', 'name': 'Pat Pataranutaporn'}, {'authorId': '2315811619', 'name': 'Aditya Suri'}, {'authorId': '51438114', 'name': 'W. Zulfikar'}, {'authorId': '2253574849', 'name': 'Pattie Maes'}, {'authorId': '2315810439', 'name': 'Elizabeth Loftus'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '2f625a39139551f037fe57088337e1f4e1264154', 'title': 'LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations', 'abstract': 'The extraction of Metal-Organic Frameworks (MOFs) synthesis route from literature has been crucial for the logical MOFs design with desirable functionality. The recent advent of large language models (LLMs) provides disruptively new solution to this long-standing problem. While the latest researches mostly stick to primitive zero-shot LLMs lacking specialized material knowledge, we introduce in this work the few-shot LLM in-context learning paradigm. First, a human-AI interactive data curation approach is proposed to secure high-quality demonstrations. Second, an information retrieval algorithm is applied to pick and quantify few-shot demonstrations for each extraction. Over three datasets randomly sampled from nearly 90,000 well-defined MOFs, we conduct triple evaluations to validate our method. The synthesis extraction, structure inference, and material design performance of the proposed few-shot LLMs all significantly outplay zero-shot LLM and baseline methods. The lab-synthesized material guided by LLM surpasses 91.1% high-quality MOFs of the same class reported in the literature, on the key physical property of specific surface area.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.04665, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2315893704', 'name': 'Lei Shi'}, {'authorId': '2277019056', 'name': 'Zhimeng Liu'}, {'authorId': '2315944722', 'name': 'Yi Yang'}, {'authorId': '2316105527', 'name': 'Weize Wu'}, {'authorId': '2315859581', 'name': 'Yuyang Zhang'}, {'authorId': '2116271777', 'name': 'Hongbo Zhang'}, {'authorId': '2279158671', 'name': 'Jing Lin'}, {'authorId': '2315855232', 'name': 'Siyu Wu'}, {'authorId': '2307265998', 'name': 'Zihan Chen'}, {'authorId': '2316089361', 'name': 'Ruiming Li'}, {'authorId': '2315930279', 'name': 'Nan Wang'}, {'authorId': '2275647125', 'name': 'Zipeng Liu'}, {'authorId': '2315923948', 'name': 'Huobin Tan'}, {'authorId': '2277152384', 'name': 'Hongyi Gao'}, {'authorId': '2311976277', 'name': 'Yue Zhang'}, {'authorId': '2293559142', 'name': 'Ge Wang'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '7d00c8f8e4afbc27a5e2a8f1c699a8965ebf2a3b', 'title': 'Algorithm, expert, or both? Evaluating the role of feature selection methods on user preferences and reliance', 'abstract': 'The integration of users and experts in machine learning is a widely studied topic in artificial intelligence literature. Similarly, human-computer interaction research extensively explores the factors that influence the acceptance of AI as a decision support system. In this experimental study, we investigate users’ preferences regarding the integration of experts in the development of such systems and how this affects their reliance on these systems. Specifically, we focus on the process of feature selection—an element that is gaining importance due to the growing demand for transparency in machine learning models. We differentiate between three feature selection methods: algorithm-based, expert-based, and a combined approach. In the first treatment, we analyze users’ preferences for these methods. In the second treatment, we randomly assign users to one of the three methods and analyze whether the method affects advice reliance. Users prefer the combined method, followed by the expert-based and algorithm-based methods. However, the users in the second treatment rely equally on all methods. Thus, we find a remarkable difference between stated preferences and actual usage, revealing a significant attitude-behavior-gap. Moreover, allowing the users to choose their preferred method had no effect, and the preferences and the extent of reliance were domain-specific. The findings underscore the importance of understanding cognitive processes in AI-supported decisions and the need for behavioral experiments in human-AI interactions.', 'openAccessPdf': {'url': '', 'status': None, 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.01171, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2223391482', 'name': 'Jaroslaw Kornowicz'}, {'authorId': '2282991416', 'name': 'Kirsten Thommes'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'b85608d8b8baf6abd81b0e90c41154c40908aba7', 'title': 'PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization', 'abstract': \"The recent emergence of Large Language Models (LLMs) has heralded a new era of human-AI interaction. These sophisticated models, exemplified by Chat-GPT and its successors, have exhibited remarkable capabilities in language understanding. However, as these LLMs have undergone exponential growth, a crucial dimension that remains understudied is the personalization of these models. Large foundation models such as GPT-3 etc. focus on creating a universal model that serves a broad range of tasks and users. This approach emphasizes the model's generalization capabilities, treating users as a collective rather than as distinct individuals. While practical for many common applications, this one-size-fits-all approach often fails to address the rich tapestry of human diversity and individual needs. To explore this issue we introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP models for user personalization. \\\\datasetname{} consists of a series of user-centered tasks containing diverse and individualized expressions where the preferences of users can potentially differ for the same input. Using PEFT-U, we explore the challenge of efficiently personalizing LLMs to accommodate user-specific preferences in the context of diverse user-centered tasks.\", 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.18078, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '143640106', 'name': 'Christopher Clarke'}, {'authorId': '2218445870', 'name': 'Yuzhao Heng'}, {'authorId': '2235128', 'name': 'Lingjia Tang'}, {'authorId': '144603405', 'name': 'Jason Mars'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '3e87ec462cb3d1d1be8849dd95aa9e20177383ab', 'title': 'When, Where, and What? A Novel Benchmark for Accident Anticipation and Localization with Large Language Models', 'abstract': 'As autonomous driving systems increasingly become part of daily transportation, the ability to accurately anticipate and mitigate potential traffic accidents is paramount. Traditional accident anticipation models primarily utilizing dashcam videos are adept at predicting when an accident may occur but fall short in localizing the incident and identifying involved entities. Addressing this gap, this study introduces a novel framework that integrates Large Language Models (LLMs) to enhance predictive capabilities across multiple dimensions--what, when, and where accidents might occur. We develop an innovative chain-based attention mechanism that dynamically adjusts to prioritize high-risk elements within complex driving scenes. This mechanism is complemented by a three-stage model that processes outputs from smaller models into detailed multimodal inputs for LLMs, thus enabling a more nuanced understanding of traffic dynamics. Empirical validation on the DAD, CCD, and A3D datasets demonstrates superior performance in Average Precision (AP) and Mean Time-To-Accident (mTTA), establishing new benchmarks for accident prediction technology. Our approach not only advances the technological framework for autonomous driving safety but also enhances human-AI interaction, making predictive insights generated by autonomous systems more intuitive and actionable.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.16277, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2269958997', 'name': 'Haicheng Liao'}, {'authorId': '2283172033', 'name': 'Yongkang Li'}, {'authorId': '2272610917', 'name': 'Chengyue Wang'}, {'authorId': '2283730555', 'name': 'Yanchen Guan'}, {'authorId': '2220304337', 'name': 'Kahou Tam'}, {'authorId': '2297767120', 'name': 'Chunlin Tian'}, {'authorId': '2260286654', 'name': 'Li Li'}, {'authorId': '2272208211', 'name': 'Chengzhong Xu'}, {'authorId': '2273365115', 'name': 'Zhenning Li'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '968fd9d435a083eda48ab0459e801f89bfe2cef8', 'title': 'J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling', 'abstract': 'Spoken dialogue plays a crucial role in human-AI interactions, necessitating dialogue-oriented spoken language models (SLMs). To develop versatile SLMs, large-scale and diverse speech datasets are essential. Additionally, to ensure hiqh-quality speech generation, the data must be spontaneous like in-wild data and must be acoustically clean with noise removed. Despite the critical need, no open-source corpus meeting all these criteria has been available. This study addresses this gap by constructing and releasing a large-scale spoken dialogue corpus, named Japanese Corpus for Human-AI Talks (J-CHAT), which is publicly accessible. Furthermore, this paper presents a language-independent method for corpus construction and describes experiments on dialogue generation using SLMs trained on J-CHAT. Experimental results indicate that the collected data from multiple domains by our method improve the naturalness and meaningfulness of dialogue generation.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.15828, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2132163639', 'name': 'Wataru Nakata'}, {'authorId': '2188831152', 'name': 'Kentaro Seki'}, {'authorId': '3486313', 'name': 'Hitomi Yanaka'}, {'authorId': '2053879375', 'name': 'Yuki Saito'}, {'authorId': '2424104', 'name': 'Shinnosuke Takamichi'}, {'authorId': '1685827', 'name': 'H. Saruwatari'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '116355c371ca5f78af866e448fb4d6f371198b71', 'title': 'What to Say and When to Say it: Live Fitness Coaching as a Testbed for Situated Interaction', 'abstract': 'Vision-language models have shown impressive progress in recent years. However, existing models are largely limited to turn-based interactions, where each turn must be stepped (i.e., prompted) by the user. Open-ended, asynchronous interactions, where an AI model may proactively deliver timely responses or feedback based on the unfolding situation in real-time, are an open challenge. In this work, we present the QEVD benchmark and dataset, which explores human-AI interaction in the challenging, yet controlled, real-world domain of fitness coaching -- a task which intrinsically requires monitoring live user activity and providing immediate feedback. The benchmark requires vision-language models to recognize complex human actions, identify possible mistakes, and provide appropriate feedback in real-time. Our experiments reveal the limitations of existing state-of-the-art vision-language models for such asynchronous situated interactions. Motivated by this, we propose a simple end-to-end streaming baseline that can respond asynchronously to human actions with appropriate feedback at the appropriate time.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.08101, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2193388695', 'name': 'Sunny Panchal'}, {'authorId': '3407762', 'name': 'Apratim Bhattacharyya'}, {'authorId': '40586522', 'name': 'Guillaume Berger'}, {'authorId': '2279545385', 'name': 'Antoine Mercier'}, {'authorId': '2310702026', 'name': 'Cornelius Bohm'}, {'authorId': '2286850586', 'name': 'Florian Dietrichkeit'}, {'authorId': '2264525112', 'name': 'Reza Pourreza'}, {'authorId': '2286718117', 'name': 'Xuanlin Li'}, {'authorId': '2220960963', 'name': 'Pulkit Madan'}, {'authorId': '2108721816', 'name': 'Mingu Lee'}, {'authorId': '108797026', 'name': 'M. Todorovich'}, {'authorId': '2310701123', 'name': 'Ingo Bax'}, {'authorId': '2264497937', 'name': 'Roland Memisevic'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'fb5a32dbf2411dcc82186e6e07206e6498da552a', 'title': 'See-Through Face Display: Enabling Gaze Communication for Any Face - Human or AI', 'abstract': \"We present See-Through Face Display, an eye-contact display system designed to enhance gaze awareness in both human-to-human and human-to-avatar communication. The system addresses the limitations of existing gaze correction methods by combining a transparent display with a strategically positioned camera. The display alternates rapidly between a visible and transparent state, thereby enabling the camera to capture clear images of the user's face from behind the display. This configuration allows for mutual gaze awareness among remote participants without the necessity of a large form factor or computationally resource-intensive image processing. In comparison to conventional methodologies, See-Through Face Display offers a number of practical advantages. The system requires minimal physical space, operates with low computational overhead, and avoids the visual artifacts typically associated with software-based gaze redirection. These features render the system suitable for a variety of applications, including multi-party teleconferencing and remote customer service. Furthermore, the alignment of the camera's field of view with the displayed face position facilitates more natural gaze-based interactions with AI avatars. This paper presents the implementation of See-Through Face Display and examines its potential applications, demonstrating how this compact eye-contact system can enhance gaze communication in both human-to-human and human-AI interactions.\", 'openAccessPdf': {'url': 'https://dl.acm.org/doi/pdf/10.1145/3681758.3698020', 'status': 'HYBRID', 'license': 'CCBYNCSA', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.05833, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2171723572', 'name': 'Kazuya Izumi'}, {'authorId': '2174751929', 'name': 'Ryosuke Hyakuta'}, {'authorId': '3428384', 'name': 'Ippei Suzuki'}, {'authorId': '2327044513', 'name': 'Yoichi Ochiai'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': '026a67521f4c27296ae717837a40d7830942b9a1', 'title': 'CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics', 'abstract': 'Integrating cognitive ergonomics with LLMs is crucial for improving safety, reliability, and user satisfaction in human-AI interactions. Current LLM designs often lack this integration, resulting in systems that may not fully align with human cognitive capabilities and limitations. This oversight exacerbates biases in LLM outputs and leads to suboptimal user experiences due to inconsistent application of user-centered design principles. Researchers are increasingly leveraging NLP, particularly LLMs, to model and understand human behavior across social sciences, psychology, psychiatry, health, and neuroscience. Our position paper explores the need to integrate cognitive ergonomics into LLM design, providing a comprehensive framework and practical guidelines for ethical development. By addressing these challenges, we aim to advance safer, more reliable, and ethically sound human-AI interactions.', 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2407.02885', 'status': 'GREEN', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.02885, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2215887932', 'name': 'Azmine Toushik Wasi'}, {'authorId': '2313590933', 'name': 'Mst Rafia Islam'}]}\n",
      "ERROR: 'publicationDate'\n",
      "No publicationDate: {'paperId': 'ef6d83251cc0a88fcb16d14c8aafd9ad1af3d376', 'title': 'Dynamic Selection of Reliance Calibration Cues With AI Reliance Model', 'abstract': 'Understanding what an AI system can and cannot do is necessary for end-users to use the AI properly without being over- or under-reliant on it. Reliance calibration cues (RCCs) communicate an AI’s capability to users, resulting in optimizing their reliance on it. Previous studies have typically focused on continuously presenting RCCs, and although providing an excessive amount of RCCs is sometimes problematic, limited consideration has been given to the question of how an AI can selectively provide RCCs. This paper proposes vPred-RC, an algorithm in which an AI decides whether to provide an RCC and which RCC to provide. It evaluates the influence of an RCC on user reliance with a cognitive model that predicts whether a human will assign a task to an AI agent with or without an RCC. We tested vPred-RC in a human-AI collaborative task called the collaborative CAPTCHA (CC) task. First, our reliance prediction model was trained on a dataset of human task assignments for the CC task and found to achieve 83.5% accuracy. We further evaluated vPred-RC’s dynamic RCC selection in a user study. As a result, the RCCs selected by vPred-RC enabled participants to more accurately assign tasks to an AI when and only when the AI succeeded compared with randomly selected ones, suggesting that vPred-RC can successfully calibrate human reliance with a reduced number of RCCs. The selective presentation of RCCs has the potential to enhance the efficiency of collaboration between humans and AIs with fewer communication costs.', 'openAccessPdf': {'url': 'https://ieeexplore.ieee.org/ielx7/6287639/6514899/10343151.pdf', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2023.3339548?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2023.3339548, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2266569940', 'name': 'Yosuke Fukuchi'}, {'authorId': '2266588353', 'name': 'Seiji Yamada'}], 'matchScore': 284.99338}\n",
      "No publicationDate: {'paperId': 'ff5f6d61fb636df318ebea92f415699566fca070', 'title': 'Evaluation of Conversational Agents: Understanding Culture, Context and Environment in Emotion Detection', 'abstract': 'Valuable decisions and highly prioritized analysis now depend on applications such as facial biometrics, social media photo tagging, and human robots interactions. However, the ability to successfully deploy such applications is based on their efficiencies on tested use cases taking into consideration possible edge cases. Over the years, lots of generalized solutions have been implemented to mimic human emotions including sarcasm. However, factors such as geographical location or cultural difference have not been explored fully amidst its relevance in resolving ethical issues and improving conversational AI (Artificial Intelligence). In this paper, we seek to address the potential challenges in the usage of conversational AI within Black African society. We develop an emotion prediction model with accuracies ranging between 85% and 96%. Our model combines both speech and image data to detect the seven basic emotions with a focus on also identifying sarcasm. It uses 3-layers of the Convolutional Neural Network in addition to a new Audio-Frame Mean Expression (AFME) algorithm and focuses on model pre-processing and post-processing stages. In the end, our proposed solution contributes to maintaining the credibility of an emotion recognition system in conversational AIs.', 'openAccessPdf': {'url': 'https://ieeexplore.ieee.org/ielx7/6287639/9668973/09718284.pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2022.3153787?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2022.3153787, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2114225187', 'name': 'Martha T. Teye'}, {'authorId': '69945861', 'name': 'Y. Missah'}, {'authorId': '2738418', 'name': 'Emmanuel Ahene'}, {'authorId': '2148295570', 'name': 'Twum Frimpong'}], 'matchScore': 236.33301}\n",
      "No abstract: {'paperId': '4a3aad779e4145a0f36e60dc9d74b48591f36f68', 'title': 'Interaction Design for AI Systems: An oriented state-of-the-art', 'abstract': None, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': \"Notice: This paper's abstract has been elided by the publisher. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/HORA55278.2022.9800084?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/HORA55278.2022.9800084, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.\"}, 'publicationDate': '2022-06-09', 'authors': [{'authorId': '2174173616', 'name': 'André Costa'}, {'authorId': '2174174230', 'name': 'Firmino Silva'}], 'matchScore': 200.80516}\n",
      "No publicationDate: {'paperId': 'cf939ed14937c3036092d81059b29ae7a49dff8d', 'title': 'Example-Based Conditioning for Text-to-Image Generative Models', 'abstract': 'Recent progress in image generation has made it possible to create high-quality images. Techniques using diffusion models have shown great potential in producing high-quality images from simple prompts, attracting inexperienced beginners in deep learning. However, prompt-based image generation often produces images that do not match the user’s expectations. Merely describing an image might not yield the desired result, and users might struggle to describe what they want accurately. This study introduces a new paradigm of example-based conditioning for interactive image generation to address this useability challenge. Our method presents users with a selection of images, allowing them to define categories by choosing examples that match their objectives. These examples serve as training data for our system to learn to generate prompts conditioned on the categories, thereby creating a variety of images according to the category requirements. Through user experiments, we demonstrate the advantages of our approach compared to the prompt-based baseline.', 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2024.3486055?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2024.3486055, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2327580520', 'name': 'Atsushi Takada'}, {'authorId': '2261749669', 'name': 'Wataru Kawabe'}, {'authorId': '2281034305', 'name': 'Yusuke Sugano'}], 'matchScore': 203.47241}\n",
      "No abstract: {'paperId': 'f3862cb2000710af561f231e4e1f2d281d510a60', 'title': 'Conference Keynote: Synthesizing Interpretable Behavior for Human-Aware AI Systems', 'abstract': None, 'openAccessPdf': {'url': '', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/cogmi50398.2020.00010?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/cogmi50398.2020.00010, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2020-10-01', 'authors': [{'authorId': '1740315', 'name': 'S. Kambhampati'}], 'matchScore': 273.14233}\n",
      "No publicationDate: {'paperId': '7b0b1330c4761e65fed1e19030dd90a9c8be156b', 'title': 'Gaze Assistance for Efficient Segmentation Correction of Medical Images', 'abstract': 'The segmentation of medical images is an important step in various diagnostic applications, including abnormality detection and radiotherapy planning. Recent developments in Artificial Intelligence (AI) have significantly advanced the field of segmentation automation. However, expert-level accuracy has not been achieved for most segmentation tasks, which significantly hampers the adoption of fully-automated medical image segmentation. This paper investigates the idea of efficient correction of medical image segmentation by using not manual controller commands, which can be time-consuming, but gaze movements. We propose a lightweight fine-tuning approach of the Segment Anything Model in medical images, known as MedSAM, to interactively adjust segmentation masks based on gaze point prompts. Our model is specifically trained for the abdominal CT imaging task using the publicly available WORD database. While surpassing state-of-the-art segmentation models, comprehensive studies with medical experts demonstrated that our gaze-assisted interactive approach led to significant improvements in segmentation quality. Specifically, the gaze-assisted corrections increased the average segmentation performance by nearly 62% for difficult medical cases, compared to traditional segmentation methods based on bounding boxes. The main findings of our proposed work include: 1) the substantial improvement in segmentation quality through gaze interaction, 2) the development of an efficient correction mechanism leveraging eye movements, and 3) the demonstration of gaze-assisted segmentation’s superior performance in abdominal imaging tasks. Our innovative approach shows promise for interactive segmentation of medical images and opens the door for further advancements in human-AI interaction in medicine using eye-tracking technology.', 'openAccessPdf': {'url': 'https://doi.org/10.1109/access.2025.3530701', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2025.3530701?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2025.3530701, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2327219149', 'name': 'Leila Khaertdinova'}, {'authorId': '2341120401', 'name': 'Tatyana Shmykova'}, {'authorId': '49378585', 'name': 'Ilya S. Pershin'}, {'authorId': '2341120805', 'name': 'Andrey Laryukov'}, {'authorId': '2341005375', 'name': 'A. Khanov'}, {'authorId': '2341114140', 'name': 'Damir Zidikhanov'}, {'authorId': '2321281576', 'name': 'Bulat Ibragimov'}], 'matchScore': 219.01093}\n",
      "No publicationDate: {'paperId': 'd9b5dc0acbaf3526a18f283a1dd80faf577d22c1', 'title': 'Ontology-Based Neuro-Symbolic AI: Effects on Prediction Quality and Explainability', 'abstract': 'Artificial intelligence (AI) systems, based on neural networks are becoming ubiquitous. However, in many cases, their application is constrained by the lack of interpretability. One of the ways of overcoming this limitation is neuro-symbolic approaches, where the neural network is complemented by some symbolic structures, expressing existing knowledge and making it understandable to humans. Such approaches can make predictions more understandable and interpretable (due to the connection to human-understandable symbolic structures). Still, they can also have an additional advantage by allowing models to be trained with less data (due to leveraging prior knowledge). This paper focuses on a subset of neuro-symbolic approaches, where domain ontologies play the role of symbolic structures. The paper discusses the existing methods to build ontology-aware explainable neural networks and ways to leverage ontologies in forming the explanation. Based on the analysis, it proposes a computational framework for building ontology-aware self-explaining neural networks. The proposed framework allows several specializations, and it is shown that these specializations allow one to improve the prediction quality. Finally, the paper presents the results of a user study, showcasing that ontology-based explanations can improve the understandability of an AI model and the efficiency of human-AI interaction.', 'openAccessPdf': {'url': 'https://doi.org/10.1109/access.2024.3485185', 'status': 'GOLD', 'license': 'CCBYNCND', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2024.3485185?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2024.3485185, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2327419975', 'name': 'Alexander V. Smirnov'}, {'authorId': '2268691087', 'name': 'Andrew Ponomarev'}, {'authorId': '2212443560', 'name': 'Anton Agafonov'}], 'matchScore': 270.1711}\n",
      "No publicationDate: {'paperId': '4ba69e4f0b7e9bbfeee091029f8eeccd2f984d09', 'title': 'Generative AI in education: To embrace it or not？', 'abstract': 'Within the first few years of introducing new technology, there is often a lot of excitement and hype surrounding its potential. People tend to overestimate its immediate impact, believing that it will revolutionize various aspects of society and bring about rapid change. However, during this early stage, the technology may still be in its early development phase, and it may face a series of challenges and limitations that could prevent it from reaching its full potential. This pattern can be observed in various technologies throughout history, such as the internet, mobile phones, and others. It is essential to consider this hype cycle when evaluating the potential impact of emerging technologies such as generative AI and to maintain a balanced perspective on their development and adoption. Therefore, universities should actively encourage research on the impact of Generative AI on education, the workforce', 'openAccessPdf': {'url': 'https://www.ijabe.org/index.php/ijabe/article/download/8486/pdf', 'status': 'GOLD', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.25165/j.ijabe.20231603.8486?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.25165/j.ijabe.20231603.8486, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '2239882314', 'name': 'Samuel Ariyo Okaiyeto'}, {'authorId': '2240228773', 'name': 'Junwen Bai'}, {'authorId': '2240004738', 'name': 'Hongwei Xiao'}], 'matchScore': 96.63441}\n",
      "No abstract: {'paperId': '126b94a2330b4a4426c5014be073960fd3430826', 'title': 'Guest Editorial: Special Issue on Affective Speech and Language Synthesis, Generation, and Conversion', 'abstract': None, 'openAccessPdf': {'url': 'https://ieeexplore.ieee.org/ielx7/5165369/10056372/10056373.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/taffc.2022.3233120?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/taffc.2022.3233120, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': '2023-01-01', 'authors': [{'authorId': '2512283', 'name': 'S. Amiriparian'}, {'authorId': '2090950337', 'name': 'B. Schuller'}, {'authorId': '2218040', 'name': 'Nabiha Asghar'}, {'authorId': '1691713', 'name': 'H. Zen'}, {'authorId': '1763455', 'name': 'F. Burkhardt'}], 'matchScore': 257.88824}\n",
      "No abstract: {'paperId': 'accc865f476a289cd3f57dd22878b0f727e2dc42', 'title': 'Editorial: What is Artificial Intelligence?', 'abstract': None, 'openAccessPdf': {'url': 'https://ieeexplore.ieee.org/ielx7/9078688/9523782/09523786.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TAI.2021.3096243?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TAI.2021.3096243, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '1713460', 'name': 'H. Abbass'}], 'matchScore': 122.89163}\n",
      "No publicationDate: {'paperId': 'accc865f476a289cd3f57dd22878b0f727e2dc42', 'title': 'Editorial: What is Artificial Intelligence?', 'abstract': None, 'openAccessPdf': {'url': 'https://ieeexplore.ieee.org/ielx7/9078688/9523782/09523786.pdf', 'status': 'BRONZE', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TAI.2021.3096243?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TAI.2021.3096243, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'publicationDate': None, 'authors': [{'authorId': '1713460', 'name': 'H. Abbass'}], 'matchScore': 122.89163}\n",
      "No abstract: {'paperId': '10.1007/s12599-025-00932-8', 'title': 'ChatGPT and Beyond: Exploring the Responsible Use of Generative AI in the Workplace', 'abstract': '', 'publicationDate': '2025-04-01'}\n",
      "No abstract: {'paperId': '10.1007/s40593-023-00346-1', 'title': 'A Manifesto for a\\xa0Pro-Actively\\xa0Responsible AI\\xa0in\\xa0Education', 'abstract': '', 'publicationDate': '2024-03-01'}\n",
      "No abstract: {'paperId': '10.1007/s12599-023-00834-7', 'title': 'Generative AI', 'abstract': '', 'publicationDate': '2024-02-01'}\n",
      "No abstract: {'paperId': '10.1007/s10676-023-09695-w', 'title': 'Role of emotions in responsible military AI', 'abstract': '', 'publicationDate': '2023-02-16'}\n",
      "No abstract: {'paperId': '10.1007/s12599-019-00600-8', 'title': 'AI-Based Digital Assistants', 'abstract': '', 'publicationDate': '2019-08-01'}\n"
     ]
    }
   ],
   "source": [
    "for i, paper in enumerate(papers):\n",
    "    if(not paper):\n",
    "        continue\n",
    "\n",
    "    for c in [\"paperId\", \"title\", \"abstract\", \"publicationDate\"]:\n",
    "        if(c not in paper or not paper[c]):\n",
    "            print(f\"No {c}:\", paper)\n",
    "            continue\n",
    "    try:\n",
    "        data.append({\n",
    "            \"paperId\": paper['paperId'],\n",
    "            \"title\": \" \".join(paper[\"title\"].split()),\n",
    "            \"abstract\": paper[\"abstract\"],\n",
    "            \"publicationDate\": paper[\"publicationDate\"]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f'ERROR: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0bbf35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=data[0].keys())\n",
    "for paper in data:\n",
    "    df.loc[len(df)] = paper\n",
    "\n",
    "df.to_csv(\"data/abstract_data/abstract.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
