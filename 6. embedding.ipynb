{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import functions.llm as llm\n",
    "from openai.lib._parsing._completions import type_to_response_format_param\n",
    "import pandas as pd\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = \"\"\n",
    "# with open('graph-relation.json', 'r') as f:\n",
    "#     G = json.loads(f.read())\n",
    "    \n",
    "# ids = [*set([ node['id'] for node in G['nodes']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"text-embedding-3-large\"\n",
    "\n",
    "def gen_body(text):\n",
    "    return { \"model\": model, \"input\": text }\n",
    "\n",
    "def wrap(id, body):\n",
    "    return {\n",
    "        \"custom_id\": id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/embeddings\",\n",
    "        \"body\": body,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch():\n",
    "#     reqs =  [ wrap(id, gen_body(id)) for id in ids ]\n",
    "#     # return [ x for xs in reqs for x in xs ]\n",
    "#     return reqs\n",
    "# \n",
    "# with open(f\"ids-{model}.jsonl\", 'a') as f:\n",
    "#     f.write(f\"{\"\\n\".join([json.dumps(i) for i in batch()])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_path = 'data/embeddings/req.jsonl'\n",
    "llm.gen_batch_jsonl(req_path, [ wrap(id, gen_body(id)) for id in ids ])\n",
    "\n",
    "# batch_input_file = client.files.create(\n",
    "#     file=open(f\"ids.jsonl\", \"rb\"),\n",
    "#     purpose=\"batch\"\n",
    "# )\n",
    "# print(f\"id: {batch_input_file.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = llm.gen_batch(client, req_path, metadata=\"Atlas of Human-AI Interaction [Embedding]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"File ID: {batch['batch_file']}\")\n",
    "print(f\"Batch ID: {batch['batch_object']}\")\n",
    "\n",
    "fetch.save(f\"File ID: {batch['batch_file']} \\nBatch ID: {batch['batch_object']}\", \"data/triplets/req_file_id.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.retrieve(batch['batch_object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"embeddings.jsonl\", \"w\") as f:\n",
    "    f.write(client.files.content(r.output_file_id).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"id\", \"embedding\"])\n",
    "\n",
    "with open(\"embeddings.jsonl\", \"r\") as f:\n",
    "    for i in f:\n",
    "        l = json.loads(i)\n",
    "        df.loc[len(df)] = [l['custom_id'], l['response']['body']['data'][0]['embedding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"embeddings.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
